{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-X0j84lOK4e"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Gen AI Experiments](https://img.shields.io/badge/Gen%20AI%20Experiments-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://github.com/buildfastwithai/gen-ai-experiments)\n",
        "[![Gen AI Experiments GitHub](https://img.shields.io/github/stars/buildfastwithai/gen-ai-experiments?style=for-the-badge&logo=github&color=gold)](http://github.com/buildfastwithai/gen-ai-experiments)\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1XXSxmmbzlYHjIVZImjadJZ20JW268v6E?usp=sharing)\n",
        "\n",
        "## Master Generative AI in 8 Weeks\n",
        "**What You'll Learn:**\n",
        "- Master cutting-edge AI tools & frameworks\n",
        "- 6 weeks of hands-on, project-based learning\n",
        "- Weekly live mentorship sessions\n",
        "\n",
        "Learn by building. Get expert mentorship and work on real AI projects.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOnLeGQDR3oC"
      },
      "source": [
        "# DeepEval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68H8IVfEQTYD"
      },
      "source": [
        "\n",
        "\n",
        "It is an open-source evaluation framework for assessing LLM models across multiple dimensions, including factual consistency, faithfulness, and relevance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQgNolryRzet"
      },
      "source": [
        "## Setting Up DeepEval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz3c5Ab1SToP"
      },
      "source": [
        "### Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "x-2vOa1wNE16",
        "outputId": "b60dd611-ed07-4929-a5af-833c155670be"
      },
      "outputs": [],
      "source": [
        "!pip install deepeval openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HS_mYnYSdJF"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "80k1RYSDSGuw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from deepeval import evaluate\n",
        "from deepeval.test_case import LLMTestCase\n",
        "from deepeval.metrics import AnswerRelevancyMetric\n",
        "from deepeval.metrics import GEval\n",
        "from deepeval.test_case import LLMTestCaseParams, LLMTestCase\n",
        "from deepeval.dataset import EvaluationDataset\n",
        "from openai import OpenAI\n",
        "from deepeval.metrics import HallucinationMetric\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03xQIuZWS947"
      },
      "source": [
        "### SetUp OpenAI Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "RW2UUwdiSpWA"
      },
      "outputs": [],
      "source": [
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = api_key\n",
        "client = OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIqegLLoTKul"
      },
      "source": [
        "### Simple Chat SetUp  \n",
        "Model : `gpt-4o`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "id": "ByF97Th_S7ut"
      },
      "outputs": [],
      "source": [
        "prompt = \"Explain Stock Market\"\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    max_tokens=100\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0e5DOgmU2-P"
      },
      "source": [
        "### LLM Generated Response  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "FJWnDFMkU1My"
      },
      "outputs": [],
      "source": [
        "generated_response = response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is6oGhoIUUTo"
      },
      "source": [
        "## Pass Actual Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "3LGA3jmwUGUw"
      },
      "outputs": [],
      "source": [
        "actual_answer =\"\"\"The stock market is a marketplace where investors trade sharesâ€”units of ownership in publicly listed companies.\n",
        "Prices move based on supply and demand, influenced by company performance, economic indicators, and market sentiment.\n",
        "It enables companies to raise capital for growth while offering investors opportunities for profit, though it carries inherent risks.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1r4Fv-KVDAN"
      },
      "source": [
        "## Define Test Case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "r9F9eYvyUx5q"
      },
      "outputs": [],
      "source": [
        "test_case = LLMTestCase(\n",
        "    input=prompt,\n",
        "    actual_output=generated_response ,\n",
        "    expected_output=actual_answer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7Z8C1kLYLzd"
      },
      "source": [
        "## **Answer Relevancy :**\n",
        "\n",
        "* This Metric compares the actual_output of LLM application to the provided input.\n",
        "* How well the generated response aligns with the intended answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808,
          "referenced_widgets": [
            "dff09efc312f49bb8a7b0b599d464fc6",
            "5a3cfcccbea940b59d4d69f9d3a6257f"
          ]
        },
        "collapsed": true,
        "id": "I7xdgeYzX5dR",
        "outputId": "9c4d4892-b296-4f6b-8ac8-c813d1c7b9a5"
      },
      "outputs": [],
      "source": [
        "relevancy_metric = AnswerRelevancyMetric(threshold=0.5 , model=\"gpt-4o\")\n",
        "results = evaluate([test_case], metrics=[AnswerRelevancyMetric()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CZX7o23bRyQ"
      },
      "source": [
        "## GEval Metric\n",
        "Evaluate LLM responses based on custom criteria like accuracy, completeness, and coherence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "PMKiIrwnYinx"
      },
      "outputs": [],
      "source": [
        "criteria = \"\"\"Coherence (1-5) - the collective quality of all sentences. We align this dimension with\n",
        "the DUC quality question of structure and coherence whereby the summary should be\n",
        "well-structured and well-organized. The summary should not just be a heap of related information, but should build from sentence to sentence to a coherent body of information about a topic.\"\"\"\n",
        "\n",
        "coherence_metric = GEval(\n",
        "    name=\"Coherence\",\n",
        "    criteria=criteria,\n",
        "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGldL9L5e_Cd"
      },
      "source": [
        "### Test Case With  LLM-Generated Responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "pudSYGK8cJrT"
      },
      "outputs": [],
      "source": [
        "test_case_1 = LLMTestCase(input=\"Explain stock market \", actual_output=\"The stock market is basically a big game where people swap company pieces for fun.\" , expected_output=actual_answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1GCd_qRf7Oc"
      },
      "source": [
        "### Use G-Eval metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54,
          "referenced_widgets": [
            "183b177b371c41f2add5595b8fcec2fb",
            "52cf3ddbe3ce46afa761d74530a25c62"
          ]
        },
        "id": "6QVgUV_Sf5D4",
        "outputId": "ed155390-9c10-4c7d-d983-7121eeec4405"
      },
      "outputs": [],
      "source": [
        "coherence_metric.measure(test_case_1)\n",
        "print(coherence_metric.score, coherence_metric.reason)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub8IP6ZFjLCv"
      },
      "source": [
        "Score : 0.2 -> GEval identified inaccurate analogy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAXlyQx4jeF7"
      },
      "source": [
        "## Hallucination: Detecting False Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "1Qt8xnS1gIyA"
      },
      "outputs": [],
      "source": [
        "context = [\n",
        "    \"Google was founded in September 1998 \",\n",
        "    \" Google has become an integral part of our daily lives, serving as the go-to source for information, historical research, entertainment, and communication\",\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "a0nvDoGajqZY"
      },
      "outputs": [],
      "source": [
        "# AI Modelâ€™s Response (Potential Hallucination)\n",
        "actual_output = \"Google was founded in august 1998 and initially focused on robotics\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861,
          "referenced_widgets": [
            "ded2de8c53e145e3a23e87dff96bda99",
            "d179461711fd4efd84420a87f1df5895"
          ]
        },
        "id": "ktfs5MRpjtl8",
        "outputId": "287209ad-6e66-4e82-ee89-c0571fac0f9c"
      },
      "outputs": [],
      "source": [
        "# Define the test case\n",
        "test_case = LLMTestCase(\n",
        "    input=\"When was Google founded and what was its focus?\",\n",
        "    actual_output=actual_output,\n",
        "    context=context\n",
        ")\n",
        "\n",
        "# Define the hallucination metric\n",
        "metric = HallucinationMetric(threshold=0.3)\n",
        "\n",
        "# Evaluate the response\n",
        "evaluate(test_cases=[test_case], metrics=[metric])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "183b177b371c41f2add5595b8fcec2fb": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_52cf3ddbe3ce46afa761d74530a25c62",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">â ‡</span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”</span> âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Coherence [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4.1, strict=False, async_mode=True)...</span>\n</pre>\n",
                  "text/plain": "\u001b[38;2;106;0;255mâ ‡\u001b[0m \u001b[38;5;237mâ”\u001b[0m âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mCoherence [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4.1, strict=False, async_mode=True)...\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "52cf3ddbe3ce46afa761d74530a25c62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a3cfcccbea940b59d4d69f9d3a6257f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d179461711fd4efd84420a87f1df5895": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ded2de8c53e145e3a23e87dff96bda99": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_d179461711fd4efd84420a87f1df5895",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluating 1 test case(s) in parallel <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:03</span>\n    ğŸ¯ Evaluating test case #0        <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:03</span>\n</pre>\n",
                  "text/plain": "Evaluating 1 test case(s) in parallel \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:03\u001b[0m\n    ğŸ¯ Evaluating test case #0        \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:03\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "dff09efc312f49bb8a7b0b599d464fc6": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_5a3cfcccbea940b59d4d69f9d3a6257f",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluating 1 test case(s) in parallel <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:05</span>\n    ğŸ¯ Evaluating test case #0        <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #00e5ff; text-decoration-color: #00e5ff\">  0%</span> <span style=\"color: #5703ff; text-decoration-color: #5703ff\">0:00:05</span>\n</pre>\n",
                  "text/plain": "Evaluating 1 test case(s) in parallel \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:05\u001b[0m\n    ğŸ¯ Evaluating test case #0        \u001b[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[38;2;0;229;255m  0%\u001b[0m \u001b[38;2;87;3;255m0:00:05\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
