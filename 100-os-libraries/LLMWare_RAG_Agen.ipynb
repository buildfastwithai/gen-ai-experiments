{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Build Fast with AI](https://img.shields.io/badge/BuildFastWithAI-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://www.buildfastwithai.com/genai-course)\n",
        "[![EduChain GitHub](https://img.shields.io/github/stars/satvik314/educhain?style=for-the-badge&logo=github&color=gold)](https://github.com/satvik314/educhain)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Oydh20fn4PDKxDBr_c1QhhoWH7g98ZFu?usp=sharing)\n",
        "## Master Generative AI in 6 Weeks\n",
        "**What You'll Learn:**\n",
        "- Build with Latest LLMs\n",
        "- Create Custom AI Apps\n",
        "- Learn from Industry Experts\n",
        "- Join Innovation Community\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "*Empowering the Next Generation of AI Innovators"
      ],
      "metadata": {
        "id": "evRwds4ta1S2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ LLMWare: Open-Source AI Framework  \n",
        "\n",
        "LLMWare is a powerful open-source framework for building enterprise AI applications using **small, specialized language models**. It enables seamless **Retrieval-Augmented Generation (RAG)** and **multi-step agent workflows**, making AI-driven automation more efficient and scalable.  \n",
        "\n",
        "üîó **Official Docs:** [LLMWare Documentation](https://llmware-ai.github.io/llmware/getting_started)  \n",
        "\n",
        "\n",
        "\n",
        "## ‚ú® Key Features  \n",
        "\n",
        "üîπ **üß† Model Hub** ‚Äì Access **50+ specialized models** like **SLIM, DRAGON, BLING, Industry-BERT** for tasks such as **QA, summarization, and classification**.  \n",
        "\n",
        "üîπ **üìÇ Smart Data Handling** ‚Äì Supports **parsing, text chunking, indexing, embedding, and retrieval** to manage unstructured data effortlessly.  \n",
        "\n",
        "üîπ **‚ö° Efficient Inference** ‚Äì Provides **prompt management, function calling, and fact-checking** for high-quality AI responses.  \n",
        "\n",
        "üîπ **üîó Enterprise Integration** ‚Äì Easily connect to **SQL databases and other enterprise data sources** for seamless AI-powered solutions."
      ],
      "metadata": {
        "id": "b40AZHbia1KM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üì¶ Install LLMWare**"
      ],
      "metadata": {
        "id": "ocUGVknUa1Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install llmware"
      ],
      "metadata": {
        "id": "vFx94QsAQPEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üòä Sentiment Analysis**"
      ],
      "metadata": {
        "id": "qe2FK7nucB-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llmware.agents import LLMfx\n",
        "\n",
        "earnings_transcripts = [\n",
        "    \"This is one of the best quarters we can remember for the industrial sector with significant growth across the \"\n",
        "    \"board in new order volume, as well as price increases in excess of inflation.  We continue to see very strong \"\n",
        "    \"demand, especially in Asia and Europe. Accordingly, we remain bullish on the tier 1 suppliers and would be \"\n",
        "    \"accumulating more stock on any dips. \",\n",
        "\n",
        "    \"Not the worst results, but overall we view as negative signals on the direction of the economy, and the likely \"\n",
        "    \"short-term trajectory for the telecom sector, and especially larger market leaders, including AT&T, Comcast, and\"\n",
        "    \"Deutsche Telekom.\",\n",
        "\n",
        "    \"This quarter was a disaster for Tesla, with falling order volume, increased costs and supply, and negative \"\n",
        "    \"guidance for future growth forecasts in 2024 and beyond.\",\n",
        "\n",
        "    \"On balance, this was an average result, with earnings in line with expectations and no big surprises to either \"\n",
        "    \"the positive or the negative.\"\n",
        "    ]"
      ],
      "metadata": {
        "id": "QI9yukcyU4y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_one_sentiment_classification(text):\n",
        "\n",
        "    agent = LLMfx(verbose=True)\n",
        "    agent.load_tool(\"sentiment\")\n",
        "    sentiment = agent.sentiment(text)\n",
        "\n",
        "    #   look at the output\n",
        "    print(\"sentiment: \", sentiment)\n",
        "    for keys, values in sentiment.items():\n",
        "        print(f\"{keys}-{values}\")"
      ],
      "metadata": {
        "id": "B-LZvyYwVB3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìë Batch Sentiment Analysis for Earnings Transcripts**"
      ],
      "metadata": {
        "id": "dqpZaH35cDx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def review_batch_earning_transcripts():\n",
        "\n",
        "    \"\"\" This example highlights how to review multiple earnings transcripts and iterate through a batch\n",
        "    using the load_work mechanism. \"\"\"\n",
        "\n",
        "    agent = LLMfx()\n",
        "    agent.load_tool(\"sentiment\")\n",
        "\n",
        "\n",
        "    agent.load_work(earnings_transcripts)\n",
        "\n",
        "    while True:\n",
        "        output = agent.sentiment()\n",
        "        if not agent.increment_work_iteration():\n",
        "            break\n",
        "\n",
        "    response_output = agent.response_list\n",
        "\n",
        "    agent.clear_work()\n",
        "    agent.clear_state()\n",
        "\n",
        "    return response_output"
      ],
      "metadata": {
        "id": "n6_AVopZVJtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üöÄ Running Sentiment Analysis**"
      ],
      "metadata": {
        "id": "xtfFrw6ncElg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    sentiment = get_one_sentiment_classification(earnings_transcripts[0])"
      ],
      "metadata": {
        "id": "jlNCx98yVVLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìÑ Document Summarization with Topic-Based Queries**"
      ],
      "metadata": {
        "id": "Q7NEnIaIcHr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_summarize_document(example=\"jd salinger\"):\n",
        "\n",
        "    sample_files_path = Setup().load_sample_files(over_write=False)\n",
        "\n",
        "    topic = None\n",
        "    query = None\n",
        "    fp = None\n",
        "    fn = None\n",
        "\n",
        "    if example not in [\"jd salinger\", \"employment terms\", \"just the comp\", \"un resolutions\"]:\n",
        "        print (\"not found example\")\n",
        "        return []\n",
        "\n",
        "    if example == \"jd salinger\":\n",
        "        fp = os.path.join(sample_files_path, \"SmallLibrary\")\n",
        "        fn = \"Jd-Salinger-Biography.docx\"\n",
        "        topic = \"jd salinger\"\n",
        "        query = None\n",
        "\n",
        "    if example == \"employment terms\":\n",
        "        fp = os.path.join(sample_files_path, \"Agreements\")\n",
        "        fn = \"Athena EXECUTIVE EMPLOYMENT AGREEMENT.pdf\"\n",
        "        topic = \"executive compensation terms\"\n",
        "        query = None\n",
        "\n",
        "    if example == \"just the comp\":\n",
        "        fp = os.path.join(sample_files_path, \"Agreements\")\n",
        "        fn = \"Athena EXECUTIVE EMPLOYMENT AGREEMENT.pdf\"\n",
        "        topic = \"executive compensation terms\"\n",
        "        query = \"base salary\"\n",
        "\n",
        "    if example == \"un resolutions\":\n",
        "        fp = os.path.join(sample_files_path, \"SmallLibrary\")\n",
        "        fn = \"N2126108.pdf\"\n",
        "        topic = \"key points\"\n",
        "        query = None\n",
        "\n",
        "\n",
        "    kp = Prompt().summarize_document_fc(fp, fn, topic=topic, query=query, text_only=True, max_batch_cap=15)\n",
        "\n",
        "    print(f\"\\nDocument summary completed - {len(kp)} Points\")\n",
        "    for i, points in enumerate(kp):\n",
        "        print(i, points)\n",
        "\n",
        "    return 0"
      ],
      "metadata": {
        "id": "FSBIfzkzVYPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìÉ Running Document Summarization**"
      ],
      "metadata": {
        "id": "S--NuoKucGN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(f\"\\nExample: Summarize Documents\\n\")\n",
        "\n",
        "\n",
        "    summary_direct = test_summarize_document(example=\"employment terms\")"
      ],
      "metadata": {
        "id": "8dTNPIp1Wv_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ü§ñ Loading & Running AI Model Inference**"
      ],
      "metadata": {
        "id": "x0rcQ2dKcJIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llmware.models import ModelCatalog\n",
        "from llmware.prompts import Prompt\n",
        "\n",
        "models = ModelCatalog().list_all_models()\n",
        "\n",
        "my_model = ModelCatalog().load_model(\"llmware/bling-phi-3-gguf\")\n",
        "output = my_model.inference(\"what is the future of AI?\")"
      ],
      "metadata": {
        "id": "13z8oH16W6K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_q8tj0hZblC",
        "outputId": "d650bb41-f8cf-4e2f-b25d-b71fbb0363c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'llm_response': \"The future of Artificial Intelligence (AI) will continue to evolve and expand, with advancements in machine learning algorithms, natural language processing, computer vision, and robotics. The potential applications are vast, ranging from healthcare and finance to transportation and entertainment. However, it's important to consider ethical implications and ensure responsible development and deployment of AI technologies.\", 'usage': {'input': 16, 'output': 84, 'total': 100, 'metric': 'tokens', 'processing_time': 1.9655685424804688}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìú Listing Available Generative Models**"
      ],
      "metadata": {
        "id": "Xw5EidiGcKxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_generative_models = ModelCatalog().list_generative_local_models()\n",
        "print(\"\\n\\nModel Catalog - load model with ModelCatalog().load_model(model_name)\")\n",
        "for i, model in enumerate(all_generative_models):\n",
        "\n",
        "    model_name = model[\"model_name\"]\n",
        "    model_family = model[\"model_family\"]\n",
        "\n",
        "    print(\"model: \", i, model)"
      ],
      "metadata": {
        "id": "YevfdeZBbJl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üîç Sentiment Analysis with SLIM Model**"
      ],
      "metadata": {
        "id": "hjFx3nTHcM81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ModelCatalog().load_model(\"slim-sentiment-tool\")\n",
        "response = model.function_call(\"That was the worst earnings call ever - what a disaster.\")\n",
        "\n",
        "print(\"\\nresponse: \", response)\n",
        "print(\"llm_response: \", response['llm_response'])\n",
        "print(\"sentiment: \", response['llm_response']['sentiment'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voFRKO4IaTT8",
        "outputId": "32d86e95-ed29-40cb-bab7-9b865b1e9eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "response:  {'llm_response': {'sentiment': ['negative']}, 'usage': {'input': 32, 'output': 8, 'total': 40, 'metric': 'tokens', 'processing_time': 0.9573299884796143, 'type': 'dict'}, 'logits': [[(29966, 0.028), (529, 0.018), (13, 0.016), (29892, 0.009), (29918, 0.008), (334, 0.005), (29896, 0.005), (3695, 0.005), (29974, 0.004), (2012, 0.004)], [(18616, 0.999), (1066, 0.0), (22198, 0.0), (19688, 0.0), (17821, 0.0), (1990, 0.0), (29879, 0.0), (4881, 0.0), (23149, 0.0), (10052, 0.0)], [(2073, 1.0), (663, 0.0), (6174, 0.0), (358, 0.0), (882, 0.0), (1947, 0.0), (19933, 0.0), (2556, 0.0), (7862, 0.0), (749, 0.0)], [(2396, 1.0), (29918, 0.0), (2033, 0.0), (10827, 0.0), (29915, 0.0), (22099, 0.0), (29374, 0.0), (6177, 0.0), (7418, 0.0), (6998, 0.0)], [(6024, 1.0), (1839, 0.0), (11117, 0.0), (518, 0.0), (525, 0.0), (21069, 0.0), (12801, 0.0), (6796, 0.0), (18959, 0.0), (6702, 0.0)], [(22198, 0.956), (1066, 0.03), (17821, 0.012), (10052, 0.0), (12313, 0.0), (2218, 0.0), (29879, 0.0), (574, 0.0), (9695, 0.0), (29881, 0.0)], [(2033, 1.0), (10827, 0.0), (29918, 0.0), (1495, 0.0), (29915, 0.0), (16215, 0.0), (742, 0.0), (11287, 0.0), (4286, 0.0), (13359, 0.0)], [(29913, 1.0), (16040, 0.0), (500, 0.0), (17428, 0.0), (10162, 0.0), (29962, 0.0), (8117, 0.0), (29958, 0.0), (829, 0.0), (10114, 0.0)], [(2, 0.999), (13, 0.001), (529, 0.0), (29966, 0.0), (1533, 0.0), (6660, 0.0), (29871, 0.0), (18252, 0.0), (259, 0.0), (10341, 0.0)]], 'output_tokens': [10998, 18616, 2073, 2396, 6024, 22198, 2033, 29913, 2]}\n",
            "llm_response:  {'sentiment': ['negative']}\n",
            "sentiment:  ['negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìä Data Extraction & Tool Testing**"
      ],
      "metadata": {
        "id": "uCTt2SAjcNeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_passage = (\"\"\"Here‚Äôs what Costco reported for its fiscal second quarter of 2024 compared with what Wall Street \"\n",
        "                was expecting, based on a survey of analysts by LSEG, formerly known as Refinitiv: Earnings \"\n",
        "                per share 3.62 expected.  Revenue: 59.16 billion expected In the three-month period that ended Feb. 18, Costco‚Äôs net income rose to $1.74 billion, or\n",
        "1.47 billion, or $3.30 per share, a year earlier.\"\"\")\n",
        "\n",
        "model = ModelCatalog().load_model(\"slim-extract-tool\")\n",
        "\n",
        "response = model.function_call(text_passage,function=\"extract\",params=[\"revenue\"])\n",
        "\n",
        "print(\"\\nextract response: \", response)\n",
        "\n",
        "\n",
        "\n",
        "ModelCatalog().tool_test_run(\"slim-topics-tool\")\n",
        "ModelCatalog().tool_test_run(\"slim-tags-tool\")\n",
        "ModelCatalog().tool_test_run(\"slim-emotions-tool\")\n",
        "ModelCatalog().tool_test_run(\"slim-summary-tool\")\n",
        "ModelCatalog().tool_test_run(\"slim-xsum-tool\")\n",
        "ModelCatalog().tool_test_run(\"slim-boolean-tool\")"
      ],
      "metadata": {
        "id": "_EOhncUZbWAA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}