{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Build Fast with AI](https://img.shields.io/badge/BuildFastWithAI-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://www.buildfastwithai.com/genai-course)\n",
        "[![EduChain GitHub](https://img.shields.io/github/stars/satvik314/educhain?style=for-the-badge&logo=github&color=gold)](https://github.com/satvik314/educhain)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1QTURJgbm1_Z_CQW3suD0tRP3mrNgqt70#scrollTo=oIWrv9IYY2OT)\n",
        "## Master Generative AI in 6 Weeks\n",
        "**What You'll Learn:**\n",
        "- Build with Latest LLMs\n",
        "- Create Custom AI Apps\n",
        "- Learn from Industry Experts\n",
        "- Join Innovation Community\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "*Empowering the Next Generation of AI Innovators"
      ],
      "metadata": {
        "id": "141R99Q_Ne1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ› ï¸âœ¨ **DSPy (Data Science Prompting)**  \n",
        "DSPy is the framework for programmingâ€”rather than promptingâ€”language models. It allows you to iterate fast on building modular AI systems and offers algorithms for optimizing their prompts and weights, whether you're building simple classifiers, sophisticated RAG pipelines, or Agent loops.\n"
      ],
      "metadata": {
        "id": "oIWrv9IYY2OT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup and Installation\n",
        "\n",
        "Install Required Libraries\n"
      ],
      "metadata": {
        "id": "dKbV2gY_Ywui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install httpx==0.27.2 dspy faiss-cpu"
      ],
      "metadata": {
        "id": "UycN-6j6NJPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Configure OpenAI API"
      ],
      "metadata": {
        "id": "IQBx0gIjNl1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "OPENAIKEY=os.getenv('OPENAI_API_KEY')\n"
      ],
      "metadata": {
        "id": "NaxdYC0VFO_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setting Up DSPY"
      ],
      "metadata": {
        "id": "JLAW1SS6TvPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dspy\n",
        "lm = dspy.OpenAI(model='gpt-4o', api_key=OPENAIKEY, model_type='chat', max_tokens = 500)\n",
        "dspy.settings.configure(lm=lm)"
      ],
      "metadata": {
        "id": "qsTnPqGzGpAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“‚ Loading the Dataset\n",
        "In this step, the HotPotQA dataset is loaded with specified sizes for training and development sets. The dataset is further processed to include 'question' inputs for each example, preparing it for training and evaluation tasks.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wn_htXyxaeW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dspy.datasets import HotPotQA\n",
        "\n",
        "# Load the dataset.\n",
        "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)\n",
        "\n",
        "trainset = [x.with_inputs('question') for x in dataset.train]\n",
        "devset = [x.with_inputs('question') for x in dataset.dev]"
      ],
      "metadata": {
        "id": "EPX0NKz-JT1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ” Inspecting a Training Example"
      ],
      "metadata": {
        "id": "CtMkYbT_bF-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_example = trainset[0]\n",
        "print(train_example)\n",
        "print(f\"Question: {train_example.question}\")\n",
        "print(f\"Answer: {train_example.answer}\")"
      ],
      "metadata": {
        "id": "pQKE1YkjJccs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ› ï¸ Defining the BasicQA Signature"
      ],
      "metadata": {
        "id": "kCAEgXrNbKq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicQA(dspy.Signature):\n",
        "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
        "\n",
        "    question = dspy.InputField()\n",
        "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
      ],
      "metadata": {
        "id": "x_v_t7NAM4Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ¤– Creating the BasicQABot Module"
      ],
      "metadata": {
        "id": "a_N0lG3BbTId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicQABot(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.generate = dspy.Predict(BasicQA)\n",
        "\n",
        "    def forward(self,question):\n",
        "        prediction = self.generate(question = question)\n",
        "        return dspy.Prediction(answer = prediction.answer)"
      ],
      "metadata": {
        "id": "HRrTN-dDM_Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ§  Querying the QA Bot"
      ],
      "metadata": {
        "id": "j_FFgBihbq1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    qa_bot = BasicQABot()\n",
        "    pred = qa_bot.forward(\"In the 10th Century A.D. Ealhswith had a son called Ã†thelweard by which English king?\")\n",
        "    print(pred.answer)"
      ],
      "metadata": {
        "id": "4ecTAjbLNCDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Retrieval-Augmented Generation (RAG)\n",
        "quick example of basic question answering with and without retrieval-augmented generation (RAG) in DSPy."
      ],
      "metadata": {
        "id": "HweJrNt9J9SP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Configuring the DSPy environment."
      ],
      "metadata": {
        "id": "czbhJKcqKTJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dspy\n",
        "\n",
        "lm = dspy.LM('openai/gpt-4o-mini')\n",
        "dspy.configure(lm=lm)"
      ],
      "metadata": {
        "id": "k_2x6wlIKWwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Simple QA Chain"
      ],
      "metadata": {
        "id": "k7T58s0_Nzg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa = dspy.Predict('question: str -> response: str')\n",
        "response = qa(question=\"what are high memory and low memory on linux?\")\n",
        "\n",
        "print(response.response)"
      ],
      "metadata": {
        "id": "K_3U5-GXLAE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Inspect History\n"
      ],
      "metadata": {
        "id": "pHlXpiTcNtlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dspy.inspect_history(n=1)"
      ],
      "metadata": {
        "id": "_est6HTELFQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Chain Of Thought Module"
      ],
      "metadata": {
        "id": "5SBeLh5ZOFac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot = dspy.ChainOfThought('question -> response')\n",
        "cot(question=\"should curly braces appear on their own line?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvT0w_eQLIVW",
        "outputId": "38ea84c3-bd58-4d1b-94be-9a8ba56c8288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction(\n",
              "    reasoning='The placement of curly braces on their own line depends on the coding style and conventions being followed. In some programming languages and style guides, such as the Allman style, opening curly braces are placed on a new line, which can enhance readability. In contrast, other styles, like K&R style, place the opening brace on the same line as the control statement, which can save vertical space. Ultimately, it is a matter of personal or team preference, and consistency within a codebase is key.',\n",
              "    response=\"Curly braces can either appear on their own line or on the same line as the preceding statement, depending on the coding style you choose to follow. It's important to maintain consistency throughout your codebase.\"\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Manipulating Examples in DSPy."
      ],
      "metadata": {
        "id": "luefxiBxMTAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Let's load a dataset of questions and their (pretty long) gold answers."
      ],
      "metadata": {
        "id": "_yVzcueqMcDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ujson\n",
        "from dspy.utils import download\n",
        "\n",
        "# Download question--answer pairs from the RAG-QA Arena \"Tech\" dataset.\n",
        "download(\"https://huggingface.co/dspy/cache/resolve/main/ragqa_arena_tech_examples.jsonl\")\n",
        "\n",
        "with open(\"ragqa_arena_tech_examples.jsonl\") as f:\n",
        "    data = [ujson.loads(line) for line in f]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB2QHX12MYW-",
        "outputId": "3f56fabb-1492-4145-9a61-ff8eea743c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'ragqa_arena_tech_examples.jsonl'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect one datapoint.\n"
      ],
      "metadata": {
        "id": "NXaoojtvNhrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqY2qXZfMix6",
        "outputId": "621cf8aa-5028-485e-cfa4-f40303ee94bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'why igp is used in mpls?',\n",
              " 'response': \"An IGP exchanges routing prefixes between gateways/routers.  \\nWithout a routing protocol, you'd have to configure each route on every router and you'd have no dynamic updates when routes change because of link failures. \\nFuthermore, within an MPLS network, an IGP is vital for advertising the internal topology and ensuring connectivity for MP-BGP inside the network.\",\n",
              " 'gold_doc_ids': [2822, 2823]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's pick an `example` here from the data.\n"
      ],
      "metadata": {
        "id": "HUH7hR5rNlBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [dspy.Example(**d).with_inputs('question') for d in data]\n",
        "\n",
        "# Let's pick an `example` here from the data.\n",
        "example = data[2]\n",
        "example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1KMP-KUMo3f",
        "outputId": "535ddf4e-beb9-4fa3-f5aa-6e2490a10e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Example({'question': 'why are my text messages coming up as maybe?', 'response': 'This is part of the Proactivity features new with iOS 9: It looks at info in emails to see if anyone with this number sent you an email and if it finds the phone number associated with a contact from your email, it will show you \"Maybe\". \\n\\nHowever, it has been suggested there is a bug in iOS 11.2 that can result in \"Maybe\" being displayed even when \"Find Contacts in Other Apps\" is disabled.', 'gold_doc_ids': [3956, 3957, 8034]}) (input_keys={'question'})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Now, let's divide the data into: Train Set"
      ],
      "metadata": {
        "id": "ti-4mUGwMw29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.Random(0).shuffle(data)\n",
        "trainset, devset, testset = data[:200], data[200:500], data[500:1000]\n",
        "\n",
        "len(trainset), len(devset), len(testset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1Te8uUqM1z6",
        "outputId": "6e58501d-f8f2-444e-881a-8a3e88528669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 300, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation in DSPy."
      ],
      "metadata": {
        "id": "Ywk_SjCmNBBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dspy.evaluate import SemanticF1\n",
        "\n",
        "# Instantiate the metric.\n",
        "metric = SemanticF1(decompositional=True)\n",
        "\n",
        "# Produce a prediction from our `cot` module, using the `example` above as input.\n",
        "pred = cot(**example.inputs())\n",
        "\n",
        "# Compute the metric score for the prediction.\n",
        "score = metric(example, pred)\n",
        "\n",
        "print(f\"Question: \\t {example.question}\\n\")\n",
        "print(f\"Gold Response: \\t {example.response}\\n\")\n",
        "print(f\"Predicted Response: \\t {pred.response}\\n\")\n",
        "print(f\"Semantic F1 Score: {score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yna4dsKzNFRM",
        "outputId": "61a3e6f4-241c-4fea-99ab-bfab645a2972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: \t why are my text messages coming up as maybe?\n",
            "\n",
            "Gold Response: \t This is part of the Proactivity features new with iOS 9: It looks at info in emails to see if anyone with this number sent you an email and if it finds the phone number associated with a contact from your email, it will show you \"Maybe\". \n",
            "\n",
            "However, it has been suggested there is a bug in iOS 11.2 that can result in \"Maybe\" being displayed even when \"Find Contacts in Other Apps\" is disabled.\n",
            "\n",
            "Predicted Response: \t Your text messages are showing up as \"maybe\" because the recipient's phone or messaging app is indicating that the sender is not recognized or saved in their contacts. This feature helps users identify messages from unknown numbers. To avoid this, you can ask the recipient to save your number in their contacts.\n",
            "\n",
            "Semantic F1 Score: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Inspect History"
      ],
      "metadata": {
        "id": "BM4h2CsVNaRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dspy.inspect_history(n=1)"
      ],
      "metadata": {
        "id": "GaWAFtitNKfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For evaluation, you could use the metric above in a simple loop and just average the score. But for nice parallelism and utilities, we can rely on dspy.Evaluate.\n"
      ],
      "metadata": {
        "id": "bCJfy5RMNTV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an evaluator that we can re-use.\n",
        "evaluate = dspy.Evaluate(devset=devset, metric=metric, num_threads=24,\n",
        "                         display_progress=True, display_table=2)\n",
        "\n",
        "# Evaluate the Chain-of-Thought program.\n",
        "evaluate(cot)"
      ],
      "metadata": {
        "id": "9XRyq665NV7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Math Reasoning"
      ],
      "metadata": {
        "id": "YLf1tghSPuL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fetching The Dataset"
      ],
      "metadata": {
        "id": "ZZSHP6OpVO5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install git+https://github.com/hendrycks/math.git"
      ],
      "metadata": {
        "id": "jDsSkmGlVOeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setting UP DSPY"
      ],
      "metadata": {
        "id": "47QmsuIaUcLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dspy\n",
        "\n",
        "gpt4o_mini = dspy.LM('openai/gpt-4o-mini', max_tokens=2000)\n",
        "gpt4o = dspy.LM('openai/gpt-4o', max_tokens=2000)\n",
        "dspy.configure(lm=gpt4o_mini)  # we'll use gpt-4o-mini as the default LM, unless otherwise specified"
      ],
      "metadata": {
        "id": "WtfXkolvPvHg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load some data examples from the MATH benchmark."
      ],
      "metadata": {
        "id": "RugDGajFUmWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dspy.datasets import MATH\n",
        "\n",
        "dataset = MATH(subset='algebra')\n",
        "print(len(dataset.train), len(dataset.dev))"
      ],
      "metadata": {
        "id": "fVbwUD3QU0BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Inspect one example from the training set."
      ],
      "metadata": {
        "id": "tP_FvIVRVdSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = dataset.train[0]\n",
        "print(\"Question:\", example.question)\n",
        "print(\"Answer:\", example.answer)"
      ],
      "metadata": {
        "id": "5IlDCb_qVedb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Chain of Thought Module"
      ],
      "metadata": {
        "id": "cWK4-5WyVp-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "module = dspy.ChainOfThought(\"question -> answer\")\n",
        "module(question=example.question)"
      ],
      "metadata": {
        "id": "eBFTJ5oSVknW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###set up an evaluator for the zero-shot module"
      ],
      "metadata": {
        "id": "4bMma-xWV1Aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "THREADS = 24\n",
        "kwargs = dict(num_threads=THREADS, display_progress=True, display_table=5)\n",
        "evaluate = dspy.Evaluate(devset=dataset.dev, metric=dataset.metric, **kwargs)\n",
        "\n",
        "evaluate(module)"
      ],
      "metadata": {
        "id": "um5OPyOSV2Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Optimize Module"
      ],
      "metadata": {
        "id": "p21dCftfWoZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = dict(num_threads=THREADS, teacher_settings=dict(lm=gpt4o), prompt_model=gpt4o_mini)\n",
        "optimizer = dspy.MIPROv2(metric=dataset.metric, auto=\"medium\", **kwargs)\n",
        "\n",
        "kwargs = dict(requires_permission_to_run=False, max_bootstrapped_demos=4, max_labeled_demos=4)\n",
        "optimized_module = optimizer.compile(module, trainset=dataset.train, **kwargs)"
      ],
      "metadata": {
        "id": "Oe4k8qzsZsNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(optimized_module)"
      ],
      "metadata": {
        "id": "SAHe18DIZuGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Inspect History"
      ],
      "metadata": {
        "id": "OQV2BVoqW6t8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dspy.inspect_history()"
      ],
      "metadata": {
        "id": "UhQFYp2DZpmu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}