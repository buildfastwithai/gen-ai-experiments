{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Build Fast with AI](https://img.shields.io/badge/BuildFastWithAI-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://www.buildfastwithai.com/genai-course)\n",
        "[![EduChain GitHub](https://img.shields.io/github/stars/satvik314/educhain?style=for-the-badge&logo=github&color=gold)](https://github.com/satvik314/educhain)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/drive/1m64PXi6DUHjHoJHArxPmhe99hx9K7hiR?usp=sharing)\n",
        "## Master Generative AI in 6 Weeks\n",
        "**What You'll Learn:**\n",
        "- Build with Latest LLMs\n",
        "- Create Custom AI Apps\n",
        "- Learn from Industry Experts\n",
        "- Join Innovation Community\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "*Empowering the Next Generation of AI Innovators"
      ],
      "metadata": {
        "id": "eDVleQA53eMW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua84lfEraujG"
      },
      "source": [
        "# Data Analysis with PandasAI\n",
        "\n",
        "This notebook demonstrates how to leverage PandasAI for intelligent data analysis by combining pandas DataFrames with natural language queries using OpenAI's LLM. The examples show basic usage with sales data, but can be extended to more complex analyses.\n",
        "\n",
        "Table of Contents:\n",
        "\n",
        "1. Installation and Setup\n",
        "2. Creating a Smart DataFrame\n",
        "3. Basic Data Analysis with Natural Language\n",
        "4. Advanced Queries and Visualizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "To get started, we need to install the last version of PandasAI."
      ],
      "metadata": {
        "id": "meb8WrBp4bLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU pandasai pandas\n"
      ],
      "metadata": {
        "id": "Itf3xc-bQ5G2"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up PandasAI With BambooLLM üêº\n",
        "#### Useful Documentation Links\n",
        "\n",
        "- [PandasAI Documentation](https://github.com/gventuri/pandas-ai)  \n",
        "\n",
        "Since PandasAI is powered by a LLM, you should import the LLM you'd like to use for your use case.\n",
        "\n",
        "By default, if no LLM is provided, it will use BambooLLM.\n",
        "\n",
        "You can get your free API key signing up at https://pandabi.ai (you can also configure it in your .env file)"
      ],
      "metadata": {
        "id": "4Yvr-EhP4rmw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "-N3xAZXJaujI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from pandasai import SmartDataframe\n",
        "from pandasai.llm import BambooLLM\n",
        "\n",
        "os.environ['PANDASAI_API_KEY'] = userdata.get('PANDASAI_API_KEY')\n",
        "\n",
        "llm = BambooLLM()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zegRWOMdaujI"
      },
      "source": [
        "### Creating a Smart Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "QdP1Q-lQaujI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandasai import SmartDataframe\n",
        "\n",
        "# Create sample data\n",
        "sales_data = pd.DataFrame({\n",
        "    \"country\": [\"United States\", \"United Kingdom\", \"France\", \"Germany\"],\n",
        "    \"sales\": [5000, 3200, 2900, 4100]\n",
        "})\n",
        "\n",
        "# Convert to SmartDataframe\n",
        "sdf = SmartDataframe(sales_data, config={\"llm\": llm})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sales_data"
      ],
      "metadata": {
        "id": "kXQUi7-giV3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_data.loc[sales_data['sales'].idxmax(), 'country']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wEXTm3nBio6R",
        "outputId": "eb5ea77c-dc7a-4de0-b420-6806241297de"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'United States'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4WIIx_faujJ",
        "outputId": "3ae5e2c3-7e4c-43a8-d77f-784e93fa9bfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The country with the highest sales is United States.\n"
          ]
        }
      ],
      "source": [
        "# Query your data\n",
        "response = sdf.chat('Which country has the highest sales?')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SyS141DaujJ",
        "outputId": "3b56e7f0-29ca-4ff2-faf3-19b685609679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15200\n"
          ]
        }
      ],
      "source": [
        "response = sdf.chat('What are the total sales?')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDq5txwRaujJ"
      },
      "source": [
        "### Analyzing Titanic Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "fT8tzKRSaujJ"
      },
      "outputs": [],
      "source": [
        "# Load and analyze Titanic dataset\n",
        "titanic_df = pd.read_csv('/content/train.csv')\n",
        "titanic_smart = SmartDataframe(titanic_df, config={\"llm\": llm})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df"
      ],
      "metadata": {
        "id": "ZWqCjqd9j4pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_smart"
      ],
      "metadata": {
        "id": "LhUMlQp7j9JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Trying Different Queries."
      ],
      "metadata": {
        "id": "wjJINjZH2cy8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3S2Y6RvzaujJ"
      },
      "outputs": [],
      "source": [
        "print(\"Query 1: Basic passenger count\")\n",
        "response = titanic_smart.chat(\"How many total passengers were on the Titanic?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41WGs1XBaujJ"
      },
      "outputs": [],
      "source": [
        "print(\"\\nQuery 2.1: Age distribution\")\n",
        "response = titanic_smart.chat(\"What was the age distribution of passengers? Show me the average, minimum and maximum ages.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTIJ9MsZaujK"
      },
      "outputs": [],
      "source": [
        "print(\"\\nQuery 2.2: Age distribution Chart\")\n",
        "response = titanic_smart.chat(\"What was the age distribution of passengers? Show me a bar chart.\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRdjrntfaujK"
      },
      "outputs": [],
      "source": [
        "print(\"\\nQuery 3: Class analysis - Multi-Query\")\n",
        "response = titanic_smart.chat(\"How many passengers were in each passenger class (1st, 2nd, 3rd) and what was the survival rate for each class?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7duyERWdaujK"
      },
      "outputs": [],
      "source": [
        "print(\"\\nQuery 4: Complex Fare Analysis\")\n",
        "response = titanic_smart.chat(\"What was the relationship between ticket fare prices and survival rates? Break it down by passenger class and show any notable patterns.Give me multi line graph with different y-axis\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFKGlFhVaujK"
      },
      "outputs": [],
      "source": [
        "print(\"\\nQuery 5: Complex demographic analysis\")\n",
        "response = titanic_smart.chat(\"Compare the survival rates between different age groups, gender and passenger classes combined. Focus on identifying which demographic groups had the highest and lowest survival rates. Give a intuitive bar chart.\")\n",
        "\n",
        "print(response)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "genai-bootcamp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
