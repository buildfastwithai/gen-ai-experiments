{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Gen AI Experiments](https://img.shields.io/badge/Gen%20AI%20Experiments-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://github.com/buildfastwithai/gen-ai-experiments)\n",
        "[![Gen AI Experiments GitHub](https://img.shields.io/github/stars/buildfastwithai/gen-ai-experiments?style=for-the-badge&logo=github&color=gold)](http://github.com/buildfastwithai/gen-ai-experiments)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/19sikoDyy33tPnO3ioZGt3L57myW4JJNt?usp=sharing)\n",
        "\n",
        "## Master Generative AI in 8 Weeks\n",
        "**What You'll Learn:**\n",
        "- Master cutting-edge AI tools & frameworks\n",
        "- 6 weeks of hands-on, project-based learning\n",
        "- Weekly live mentorship sessions\n",
        "- No coding experience required\n",
        "- Join Innovation Community\n",
        "\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "overview"
      },
      "source": [
        "# üöÄ Qwen3 Coder Next - Complete Testing Notebook\n",
        "\n",
        "## Model Overview\n",
        "\n",
        "**Qwen3-Coder-Next** is an open-weight causal language model specifically optimized for **coding agents** and **local development workflows**. Built by Alibaba's Qwen team, it represents a breakthrough in efficient coding model design.\n",
        "\n",
        "### Key Specifications\n",
        "\n",
        "| Specification | Value |\n",
        "|--------------|-------|\n",
        "| **Architecture** | Sparse Mixture of Experts (MoE) with Hybrid Attention |\n",
        "| **Total Parameters** | 80B |\n",
        "| **Active Parameters** | ~3B (per token) |\n",
        "| **Context Window** | 256K tokens |\n",
        "| **Memory Requirements** | 46GB RAM/VRAM (or 85GB for 8-bit quantization) |\n",
        "| **Base Model** | Qwen3-Next-80B-A3B-Base |\n",
        "| **License** | Open Weight |\n",
        "\n",
        "### üåü Key Capabilities\n",
        "\n",
        "1. **Agentic Coding Optimized**: Built for long-horizon reasoning, intricate tool usage, and recovery from execution failures\n",
        "2. **Efficient MoE Design**: Only 3B parameters active per token - comparable to models with 10-20x higher active compute\n",
        "3. **256K Context Window**: Native support for massive context\n",
        "4. **Tool Calling**: Native support for function calling and tool use\n",
        "5. **Non-Thinking Mode**: No `<think></think>` blocks - streamlined for production coding agents\n",
        "6. **CLI/IDE Integration**: Seamless integration with Claude Code, Qwen Code, and various scaffold templates\n",
        "\n",
        "### Cost-Efficiency Advantage\n",
        "\n",
        "The sparse MoE architecture means this model:\n",
        "- Runs efficiently on consumer hardware\n",
        "- Provides exceptional performance per compute dollar\n",
        "- Ideal for always-on agent deployment\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section1"
      },
      "source": [
        "## üì¶ Section 1: Installation & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "setup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ec99b1-d609-4d85-e465-d3679758d6e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Setup complete!\n",
            "üìç Using model: qwen/qwen3-coder-next\n",
            "üåê Provider: OpenRouter\n",
            "üèóÔ∏è Architecture: 80B params (3B active per token)\n",
            "üìè Context Window: 256K tokens\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and setup client\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Initialize OpenRouter client for Qwen3 Coder Next\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=userdata.get(\"OPENROUTER_API_KEY\")\n",
        ")\n",
        "\n",
        "# Model identifier for Qwen3 Coder Next\n",
        "MODEL_NAME = \"qwen/qwen3-coder-next\"\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n",
        "print(f\"üìç Using model: {MODEL_NAME}\")\n",
        "print(f\"üåê Provider: OpenRouter\")\n",
        "print(f\"üèóÔ∏è Architecture: 80B params (3B active per token)\")\n",
        "print(f\"üìè Context Window: 256K tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section2"
      },
      "source": [
        "---\n",
        "\n",
        "## üéØ Section 2: Basic Usage - Hello World"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hello_world",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2321a2b6-d20c-4495-8613-b2b311adc714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Response:\n",
            "Hello! I'm Qwen3 Coder Next, an advanced coding assistant specifically designed to help with programming and software development tasks. Here's what makes me special:\n",
            "\n",
            "‚úÖ **Deep coding expertise** - I'm trained on vast amounts of code across 80+ programming languages (Python, JavaScript, Java, C++, Go, Rust, etc.)\n",
            "\n",
            "‚úÖ **Agentic workflow optimization** - I excel at breaking down complex projects into manageable steps, planning implementations, and executing multi-step tasks autonomously\n",
            "\n",
            "‚úÖ **Real-world problem solving** - Beyond syntax, I understand architectural patterns, best practices, and can help with debugging, refactoring, testing, and system design\n",
            "\n",
            "‚úÖ **Context-aware assistance** - I maintain conversation context to provide coherent, progressive help whether you're starting a new project or debugging a tricky issue\n",
            "\n",
            "‚úÖ **Practical tool integration** - I can work with terminals, file systems, and development environments to actually implement solutions\n",
            "\n",
            "I'm here to make your coding faster, more efficient, and less frustrating‚Äîwhether you need a quick snippet or help architecting a complete application. What would you like to build or fix today? üöÄ\n",
            "\n",
            "‚è±Ô∏è Response time: 3.81s\n",
            "üìä Tokens - Prompt: 52, Completion: 233\n"
          ]
        }
      ],
      "source": [
        "# Basic \"Hello World\" test\n",
        "start_time = time.time()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are Qwen3 Coder Next, an expert coding assistant optimized for agentic workflows and development tasks.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Hello! Introduce yourself briefly and tell me what makes you special for coding tasks.\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "\n",
        "print(\"ü§ñ Response:\")\n",
        "print(response.choices[0].message.content)\n",
        "print(f\"\\n‚è±Ô∏è Response time: {elapsed:.2f}s\")\n",
        "\n",
        "# Display usage stats if available\n",
        "if response.usage:\n",
        "    print(f\"üìä Tokens - Prompt: {response.usage.prompt_tokens}, Completion: {response.usage.completion_tokens}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section3"
      },
      "source": [
        "---\n",
        "\n",
        "## üß† Section 3: Agentic Coding Capabilities\n",
        "\n",
        "Qwen3 Coder Next is specifically trained for agentic coding patterns - let's test its ability to reason through complex coding tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "agentic_debug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0a9657-9e5b-4952-876d-434cecdc1303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Agentic Debugging Response:\n",
            "==================================================\n",
            "## Problem Analysis\n",
            "\n",
            "The issue in your code is that you're using `requests.get()` inside an async function. The `requests` library is **synchronous and blocking**, which means:\n",
            "\n",
            "1. When `requests.get()` is called, it blocks the entire event loop until the HTTP request completes\n",
            "2. Even though you're using `asyncio.gather()`, the requests still execute sequentially because the event loop can't switch between tasks while one is blocking\n",
            "3. This defeats the entire purpose of using async/await for concurrent I/O operations\n",
            "\n",
            "## Solution\n",
            "\n",
            "You need to use an **async HTTP client library** like `aiohttp` or `httpx` that supports asynchronous operations.\n",
            "\n",
            "Here's the corrected code using `aiohttp`:\n",
            "\n",
            "```python\n",
            "import asyncio\n",
            "import aiohttp\n",
            "\n",
            "async def fetch_data(session, url):\n",
            "    async with session.get(url) as response:\n",
            "        return await response.json()\n",
            "\n",
            "async def main():\n",
            "    urls = ['https://api.example.com/1', 'https://api.example.com/2']\n",
            "    \n",
            "    async with aiohttp.ClientSession() as session:\n",
            "        # Now the requests will run concurrently\n",
            "        results = await asyncio.gather(*[fetch_data(session, url) for url in urls])\n",
            "        return results\n",
            "\n",
            "# Run the async main function\n",
            "data = asyncio.run(main())\n",
            "```\n",
            "\n",
            "## Key Changes\n",
            "\n",
            "1. **Replaced `requests` with `aiohttp`**: `aiohttp` is an async HTTP client that doesn't block the event loop\n",
            "2. **Used a shared session**: `aiohttp.ClientSession()` should be reused across requests for connection pooling efficiency\n",
            "3. **Proper async context management**: Used `async with` for the session and response objects\n",
            "4. **Async JSON parsing**: Used `await response.json()` instead of `response.json()`\n",
            "\n",
            "## Alternative with httpx\n",
            "\n",
            "If you prefer `httpx`, here's the equivalent code:\n",
            "\n",
            "```python\n",
            "import asyncio\n",
            "import httpx\n",
            "\n",
            "async def fetch_data(url):\n",
            "    async with httpx.AsyncClient() as client:\n",
            "        response = await client.get(url)\n",
            "        return response.json()\n",
            "\n",
            "async def main():\n",
            "    urls = ['https://api.example.com/1', 'https://api.example.com/2']\n",
            "    results = await asyncio.gather(*[fetch_data(url) for url in urls])\n",
            "    return results\n",
            "\n",
            "data = asyncio.run(main())\n",
            "```\n",
            "\n",
            "Both solutions will now execute the HTTP requests concurrently, as intended with `asyncio.gather()`.\n"
          ]
        }
      ],
      "source": [
        "# Test agentic debugging - simulating a coding agent workflow\n",
        "agentic_response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a coding agent. Analyze the error, identify the root cause, and provide a fix.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"I ran this code and got an error:\n",
        "\n",
        "```python\n",
        "import asyncio\n",
        "\n",
        "async def fetch_data(url):\n",
        "    response = requests.get(url)\n",
        "    return response.json()\n",
        "\n",
        "async def main():\n",
        "    urls = ['https://api.example.com/1', 'https://api.example.com/2']\n",
        "    results = await asyncio.gather(*[fetch_data(url) for url in urls])\n",
        "    return results\n",
        "\n",
        "data = asyncio.run(main())\n",
        "```\n",
        "\n",
        "Error: The async gather seems to run sequentially, not in parallel. Also the code is blocking.\n",
        "\n",
        "Analyze this issue and provide the corrected code.\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.3,\n",
        "    max_tokens=2000\n",
        ")\n",
        "\n",
        "print(\"üîß Agentic Debugging Response:\")\n",
        "print(\"=\"*50)\n",
        "print(agentic_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "agentic_multi_step",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e51c6d7f-2143-4e75-dd98-aa2d20a80d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Code Refactoring:\n",
            "==================================================\n",
            "Here's a production-ready refactored version of your code with best practices applied:\n",
            "\n",
            "```python\n",
            "from typing import Any, Dict, List, Optional\n",
            "\n",
            "\n",
            "def process_active_adult_users(data: List[Dict[str, Any]]) -> List[Dict[str, str]]:\n",
            "    \"\"\"\n",
            "    Filter and extract contact information for active adult users.\n",
            "\n",
            "    Args:\n",
            "        data: A list of user dictionaries, each containing keys like 'type',\n",
            "              'age', 'active', 'name', and 'email'.\n",
            "\n",
            "    Returns:\n",
            "        A list of dictionaries with 'name' and 'email' for users who:\n",
            "        - Have type == 'user'\n",
            "        - Are older than 18 years\n",
            "        - Are marked as active\n",
            "\n",
            "    Raises:\n",
            "        TypeError: If data is not a list or contains non-dict items.\n",
            "        KeyError: If required keys are missing from user dictionaries.\n",
            "        ValueError: If age is not a numeric value.\n",
            "    \"\"\"\n",
            "    # Guard clause: validate input type\n",
            "    if not isinstance(data, list):\n",
            "        raise TypeError(f\"Expected list, got {type(data).__name__}\")\n",
            "\n",
            "    result: List[Dict[str, str]] = []\n",
            "\n",
            "    for item in data:\n",
            "        # Skip non-dict items\n",
            "        if not isinstance(item, dict):\n",
            "            continue\n",
            "\n",
            "        # Guard clause: skip non-user items\n",
            "        if item.get(\"type\") != \"user\":\n",
            "            continue\n",
            "\n",
            "        # Extract and validate required fields with early error handling\n",
            "        try:\n",
            "            age = item[\"age\"]\n",
            "            if not isinstance(age, (int, float)):\n",
            "                raise ValueError(f\"Age must be numeric, got {type(age).__name__}\")\n",
            "            \n",
            "            # Check adult status and active status\n",
            "            if age <= 18 or not item.get(\"active\", False):\n",
            "                continue\n",
            "\n",
            "            # Extract contact info\n",
            "            result.append({\n",
            "                \"name\": item[\"name\"],\n",
            "                \"email\": item[\"email\"]\n",
            "            })\n",
            "        except KeyError as e:\n",
            "            # Log warning or handle missing keys appropriately\n",
            "            # For production, consider logging here\n",
            "            continue  # Skip malformed entries\n",
            "\n",
            "    return result\n",
            "```\n",
            "\n",
            "**Key improvements:**\n",
            "\n",
            "1. **Type hints**: Added comprehensive type annotations for parameters and return types\n",
            "2. **Docstrings**: Added detailed Google-style docstring with Args, Returns, and Raises sections\n",
            "3. **Error handling**: \n",
            "   - Input validation with appropriate exceptions\n",
            "   - Graceful handling of missing keys with try/except\n",
            "   - Type checking for age values\n",
            "4. **Early returns/guard clauses**: \n",
            "   - Input validation at the start\n",
            "   - Skip non-dict items early\n",
            "   - Skip non-user items early\n",
            "   - Skip non-active/non-adult users early\n",
            "5. **More Pythonic patterns**:\n",
            "   - Used `item.get(\"active\", False)` for safe boolean checking\n",
            "   - Used `continue` instead of nested conditionals\n",
            "   - Used dictionary comprehension alternative (see below)\n",
            "   - Used `isinstance()` for type checking\n",
            "\n",
            "**Alternative with list comprehension (even more Pythonic):**\n",
            "\n",
            "```python\n",
            "def process_active_adult_users(data: List[Dict[str, Any]]) -> List[Dict[str, str]]:\n",
            "    \"\"\"... (same docstring) ...\"\"\"\n",
            "    if not isinstance(data, list):\n",
            "        raise TypeError(f\"Expected list, got {type(data).__name__}\")\n",
            "\n",
            "    return [\n",
            "        {\"name\": item[\"name\"], \"email\": item[\"email\"]}\n",
            "        for item in data\n",
            "        if isinstance(item, dict)\n",
            "        and item.get(\"type\") == \"user\"\n",
            "        and isinstance(item.get(\"age\"), (int, float))\n",
            "        and item[\"age\"] > 18\n",
            "        and item.get(\"active\", False)\n",
            "    ]\n",
            "```\n",
            "\n",
            "**Production considerations:**\n",
            "- The first version provides more detailed error handling and logging opportunities\n",
            "- The second version is more concise but less explicit about error handling\n",
            "- Consider adding logging for malformed entries in production\n",
            "- You might want to make the field names configurable via parameters\n",
            "- For very large datasets, consider using generators instead of lists\n"
          ]
        }
      ],
      "source": [
        "# Test multi-step reasoning for code refactoring\n",
        "refactor_response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"Refactor this Python code to be production-ready. Apply best practices:\n",
        "\n",
        "```python\n",
        "def process(data):\n",
        "    result = []\n",
        "    for item in data:\n",
        "        if item['type'] == 'user':\n",
        "            if item['age'] > 18:\n",
        "                if item['active'] == True:\n",
        "                    result.append({'name': item['name'], 'email': item['email']})\n",
        "    return result\n",
        "```\n",
        "\n",
        "Include:\n",
        "1. Type hints\n",
        "2. Docstrings\n",
        "3. Error handling\n",
        "4. Early returns / guard clauses\n",
        "5. More pythonic patterns\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.3,\n",
        "    max_tokens=1500\n",
        ")\n",
        "\n",
        "print(\"üîÑ Code Refactoring:\")\n",
        "print(\"=\"*50)\n",
        "print(refactor_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section4"
      },
      "source": [
        "---\n",
        "\n",
        "## üîß Section 4: Tool Calling / Function Calling\n",
        "\n",
        "Qwen3 Coder Next supports native tool calling, essential for building coding agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "define_tools",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a46b7d-f558-4bad-d3f0-199b2868f123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã Defined Coding Agent Tools:\n",
            "  ‚Ä¢ execute_code: Execute Python code in a sandboxed environment and return the output\n",
            "  ‚Ä¢ read_file: Read contents of a file from the filesystem\n",
            "  ‚Ä¢ write_file: Write content to a file\n",
            "  ‚Ä¢ run_terminal_command: Execute a terminal/shell command\n",
            "  ‚Ä¢ search_codebase: Search for patterns or text in the codebase\n"
          ]
        }
      ],
      "source": [
        "# Define coding-focused tools\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"execute_code\",\n",
        "            \"description\": \"Execute Python code in a sandboxed environment and return the output\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"code\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Python code to execute\"\n",
        "                    },\n",
        "                    \"timeout\": {\n",
        "                        \"type\": \"integer\",\n",
        "                        \"description\": \"Maximum execution time in seconds\",\n",
        "                        \"default\": 30\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"code\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"read_file\",\n",
        "            \"description\": \"Read contents of a file from the filesystem\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"path\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Path to the file to read\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"path\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"write_file\",\n",
        "            \"description\": \"Write content to a file\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"path\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Path to the file to write\"\n",
        "                    },\n",
        "                    \"content\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Content to write to the file\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"path\", \"content\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"run_terminal_command\",\n",
        "            \"description\": \"Execute a terminal/shell command\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"command\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Shell command to execute\"\n",
        "                    },\n",
        "                    \"cwd\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Working directory for the command\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"command\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"search_codebase\",\n",
        "            \"description\": \"Search for patterns or text in the codebase\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"query\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Search query or regex pattern\"\n",
        "                    },\n",
        "                    \"file_pattern\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"File pattern to filter (e.g., '*.py')\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"query\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"üìã Defined Coding Agent Tools:\")\n",
        "for tool in tools:\n",
        "    print(f\"  ‚Ä¢ {tool['function']['name']}: {tool['function']['description']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tool_calling_test",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "492a5f6b-c20a-4b30-fa15-4c9f1a4bfa82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üõ†Ô∏è Tool Call Response:\n",
            "==================================================\n",
            "\n",
            "üìû Model requested 1 tool call(s):\n",
            "\n",
            "  Tool Call 1:\n",
            "    Function: write_file\n",
            "    Arguments: {\n",
            "      \"content\": \"def fibonacci(n):\\n    if n <= 0:\\n        return []\\n    elif n == 1:\\n        return [0]\\n    elif n == 2:\\n        return [0, 1]\\n    \\n    fib = [0, 1]\\n    for i in range(2, n):\\n        fib.append(fib[i-1] + fib[i-2])\\n    return fib\\n\\nif __name__ == \\\"__main__\\\":\\n    n = 10\\n    result = fibonacci(n)\\n    print(f\\\"Fibonacci sequence up to n={n}: {result}\\\")\\n\",\n",
            "      \"path\": \"fibonacci.py\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Test tool calling with a coding task\n",
        "tool_response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a coding agent. Use the available tools to complete tasks.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Create a Python script that calculates the fibonacci sequence up to n=10, save it to 'fibonacci.py', then run it to verify it works.\"\n",
        "        }\n",
        "    ],\n",
        "    tools=tools,\n",
        "    tool_choice=\"auto\"\n",
        ")\n",
        "\n",
        "print(\"üõ†Ô∏è Tool Call Response:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "message = tool_response.choices[0].message\n",
        "\n",
        "if message.tool_calls:\n",
        "    print(f\"\\nüìû Model requested {len(message.tool_calls)} tool call(s):\")\n",
        "    for i, tool_call in enumerate(message.tool_calls, 1):\n",
        "        print(f\"\\n  Tool Call {i}:\")\n",
        "        print(f\"    Function: {tool_call.function.name}\")\n",
        "        try:\n",
        "            args = json.loads(tool_call.function.arguments)\n",
        "            print(f\"    Arguments: {json.dumps(args, indent=6)}\")\n",
        "        except:\n",
        "            print(f\"    Arguments: {tool_call.function.arguments}\")\n",
        "else:\n",
        "    print(\"Response:\", message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "parallel_tool_calling",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48dbf96-3f87-4a8d-ae12-d606430ead68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÄ Parallel Tool Calling Test:\n",
            "==================================================\n",
            "\n",
            "‚úÖ Model requested 3 parallel tool calls:\n",
            "\n",
            "  [1] read_file\n",
            "      path: config.yaml\n",
            "\n",
            "  [2] search_codebase\n",
            "      query: TODO\n",
            "\n",
            "  [3] run_terminal_command\n",
            "      command: pip show pytest\n"
          ]
        }
      ],
      "source": [
        "# Test parallel tool calling\n",
        "parallel_response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"I need to: 1) Read the config.yaml file, 2) Search for all TODO comments in the codebase, and 3) Check if pytest is installed. Do all of these.\"\n",
        "        }\n",
        "    ],\n",
        "    tools=tools,\n",
        "    tool_choice=\"auto\"\n",
        ")\n",
        "\n",
        "print(\"üîÄ Parallel Tool Calling Test:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "message = parallel_response.choices[0].message\n",
        "\n",
        "if message.tool_calls:\n",
        "    print(f\"\\n‚úÖ Model requested {len(message.tool_calls)} parallel tool calls:\")\n",
        "    for i, tool_call in enumerate(message.tool_calls, 1):\n",
        "        print(f\"\\n  [{i}] {tool_call.function.name}\")\n",
        "        try:\n",
        "            args = json.loads(tool_call.function.arguments)\n",
        "            for key, value in args.items():\n",
        "                print(f\"      {key}: {value}\")\n",
        "        except:\n",
        "            print(f\"      {tool_call.function.arguments}\")\n",
        "else:\n",
        "    print(\"Response:\", message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section5"
      },
      "source": [
        "---\n",
        "\n",
        "## üíª Section 5: Advanced Coding Capabilities\n",
        "\n",
        "Testing Qwen3 Coder Next's advanced code generation and understanding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "code_generation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d08316-3a77-467e-8700-68e44bf66e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíª Advanced Code Generation:\n",
            "==================================================\n",
            "Here's a comprehensive async HTTP client wrapper using `aiohttp` that implements all the requested features:\n",
            "\n",
            "```python\n",
            "\"\"\"\n",
            "Async HTTP Client Wrapper with advanced features.\n",
            "\n",
            "This module provides a robust async HTTP client with connection pooling,\n",
            "automatic retries with exponential backoff, request timeout handling,\n",
            "response caching with TTL, rate limiting, and comprehensive error handling.\n",
            "\"\"\"\n",
            "\n",
            "import asyncio\n",
            "import functools\n",
            "import hashlib\n",
            "import json\n",
            "import logging\n",
            "import time\n",
            "import weakref\n",
            "from dataclasses import dataclass\n",
            "from datetime import datetime, timedelta\n",
            "from enum import Enum\n",
            "from typing import (\n",
            "    Any,\n",
            "    Callable,\n",
            "    Dict,\n",
            "    List,\n",
            "    Optional,\n",
            "    Tuple,\n",
            "    Type,\n",
            "    Union,\n",
            "    cast,\n",
            ")\n",
            "\n",
            "import aiohttp\n",
            "from aiohttp import ClientTimeout, ClientError, ClientResponse\n",
            "from aiohttp.client_exceptions import (\n",
            "    ClientConnectorError,\n",
            "    ClientResponseError,\n",
            "    ClientPayloadError,\n",
            "    ServerTimeoutError,\n",
            "    ServerDisconnectedError,\n",
            "    ClientOSError,\n",
            ")\n",
            "from cachetools import TTLCache\n",
            "from cachetools.keys import hashkey\n",
            "\n",
            "# Configure logging\n",
            "logger = logging.getLogger(__name__)\n",
            "\n",
            "\n",
            "class RetryableError(Exception):\n",
            "    \"\"\"Base exception for retryable errors.\"\"\"\n",
            "    pass\n",
            "\n",
            "\n",
            "class NonRetryableError(Exception):\n",
            "    \"\"\"Base exception for non-retryable errors.\"\"\"\n",
            "    pass\n",
            "\n",
            "\n",
            "class TimeoutError(NonRetryableError):\n",
            "    \"\"\"Request timeout error.\"\"\"\n",
            "    pass\n",
            "\n",
            "\n",
            "class RateLimitError(RetryableError):\n",
            "    \"\"\"Rate limit exceeded error.\"\"\"\n",
            "    pass\n",
            "\n",
            "\n",
            "class ServerError(RetryableError):\n",
            "    \"\"\"Server error (5xx).\"\"\"\n",
            "    pass\n",
            "\n",
            "\n",
            "class ClientError(NonRetryableError):\n",
            "    \"\"\"Client error (4xx, except 429).\"\"\"\n",
            "    pass\n",
            "\n",
            "\n",
            "class NetworkError(RetryableError):\n",
            "    \"\"\"Network-related error.\"\"\"\n",
            "    pass\n",
            "\n",
            "\n",
            "@dataclass\n",
            "class RequestConfig:\n",
            "    \"\"\"Configuration for a single request.\"\"\"\n",
            "    timeout: float = 30.0\n",
            "    max_retries: int = 3\n",
            "    retry_delay: float = 1.0\n",
            "    retry_multiplier: float = 2.0\n",
            "    retry_jitter: float = 0.1\n",
            "    cache_ttl: float = 300.0  # 5 minutes default TTL\n",
            "    cache_enabled: bool = True\n",
            "    rate_limit_key: Optional[str] = None\n",
            "\n",
            "\n",
            "class HTTPMethod(Enum):\n",
            "    \"\"\"HTTP methods supported by the client.\"\"\"\n",
            "    GET = \"GET\"\n",
            "    POST = \"POST\"\n",
            "    PUT = \"PUT\"\n",
            "    DELETE = \"DELETE\"\n",
            "    PATCH = \"PATCH\"\n",
            "    HEAD = \"HEAD\"\n",
            "    OPTIONS = \"OPTIONS\"\n",
            "\n",
            "\n",
            "class HTTPClient:\n",
            "    \"\"\"\n",
            "    Async HTTP client wrapper with advanced features.\n",
            "    \n",
            "    Features:\n",
            "    - Connection pooling via aiohttp.ClientSession\n",
            "    - Automatic retry with exponential backoff\n",
            "    - Request timeout handling\n",
            "    - Response caching with TTL\n",
            "    - Rate limiting per key\n",
            "    - Comprehensive error handling with custom exceptions\n",
            "    \n",
            "    Example:\n",
            "        >>> async def example():\n",
            "        ...     async with HTTPClient() as client:\n",
            "        ...         response = await client.get(\"https://api.example.com/data\")\n",
            "        ...         print(response.json())\n",
            "    \"\"\"\n",
            "    \n",
            "    def __init__(\n",
            "        self,\n",
            "        base_url: str = \"\",\n",
            "        headers: Optional[Dict[str, str]] = None,\n",
            "        timeout: float = 30.0,\n",
            "        max_connections: int = 100,\n",
            "        max_connections_per_host: int = 10,\n",
            "        retry_config: Optional[Dict[str, Any]] = None,\n",
            "        cache_max_size: int = 1000,\n",
            "        cache_ttl: float = 300.0,\n",
            "        rate_limits: Optional[Dict[str, Tuple[int, float]]] = None,\n",
            "    ):\n",
            "        \"\"\"\n",
            "        Initialize the HTTP client.\n",
            "        \n",
            "        Args:\n",
            "            base_url: Base URL for all requests\n",
            "            headers: Default headers to include in all requests\n",
            "            timeout: Default timeout in seconds\n",
            "            max_connections: Maximum number of connections in the pool\n",
            "            max_connections_per_host: Maximum connections per host\n",
            "            retry_config: Configuration for retry behavior\n",
            "            cache_max_size: Maximum number of cached responses\n",
            "            cache_ttl: Default TTL for cached responses in seconds\n",
            "            rate_limits: Rate limits as {key: (requests, window_seconds)}\n",
            "        \"\"\"\n",
            "        self.base_url = base_url.rstrip(\"/\")\n",
            "        self.default_headers = headers or {}\n",
            "        self.default_timeout = timeout\n",
            "        self._session: Optional[aiohttp.ClientSession] = None\n",
            "        self._connector: Optional[aiohttp.TCPConnector] = None\n",
            "        \n",
            "        # Retry configuration\n",
            "        self.retry_config = retry_config or {}\n",
            "        self.max_retries = self.retry_config.get(\"max_retries\", 3)\n",
            "        self.retry_delay = self.retry_config.get(\"retry_delay\", 1.0)\n",
            "        self.retry_multiplier = self.retry_config.get(\"retry_multiplier\", 2.0)\n",
            "        self.retry_jitter = self.retry_config.get(\"retry_jitter\", 0.1)\n",
            "        \n",
            "        # Cache configuration\n",
            "        self._cache = TTLCache(maxsize=cache_max_size, ttl=cache_ttl)\n",
            "        self._cache_lock = asyncio.Lock()\n",
            "        \n",
            "        # Rate limiting configuration\n",
            "        self._rate_limits: Dict[str, List[float]] = {}\n",
            "        self._rate_limit_locks: Dict[str, asyncio.Lock] = {}\n",
            "        self.rate_limits_config = rate_limits or {}\n",
            "        \n",
            "        # Connection pool configuration\n",
            "        self.max_connections = max_connections\n",
            "        self.max_connections_per_host = max_connections_per_host\n",
            "        \n",
            "        # Create session and connector\n",
            "        self._create_session()\n",
            "    \n",
            "    def _create_session(self) -> None:\n",
            "        \"\"\"Create the aiohttp session and connector.\"\"\"\n",
            "        if self._connector is None:\n",
            "            self._connector = aiohttp.TCPConnector(\n",
            "                limit=self.max_connections,\n",
            "                limit_per_host=self.max_connections_per_host,\n",
            "                enable_cleanup_closed=True,\n",
            "            )\n",
            "        \n",
            "        if self._session is None:\n",
            "            self._session = aiohttp.ClientSession(\n",
            "                connector=self._connector,\n",
            "                headers=self.default_headers,\n",
            "                timeout=ClientTimeout(total=self.default_timeout),\n",
            "            )\n",
            "    \n",
            "    async def __aenter__(self) -> \"HTTPClient\":\n",
            "        \"\"\"Async context manager entry.\"\"\"\n",
            "        return self\n",
            "    \n",
            "    async def __aexit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> None:\n",
            "        \"\"\"Async context manager exit.\"\"\"\n",
            "        await self.close()\n",
            "    \n",
            "    async def close(self) -> None:\n",
            "        \"\"\"Close the client and release resources.\"\"\"\n",
            "        if self._session is not None:\n",
            "            await self._session.close()\n",
            "            self._session = None\n",
            "        if self._connector is not None:\n",
            "            await self._connector.close()\n",
            "            self._connector = None\n",
            "    \n",
            "    def _get_cache_key(self, method: str, url: str, params: Optional[Dict] = None, \n",
            "                      data: Optional[Dict] = None) -> str:\n",
            "        \"\"\"Generate a cache key for the request.\"\"\"\n",
            "        # Normalize parameters and data for consistent hashing\n",
            "        params_str = json.dumps(params or {}, sort_keys=True) if params else \"\"\n",
            "        data_str = json.dumps(data or {}, sort_keys=True) if data else \"\"\n",
            "        \n",
            "        # Create hash of request components\n",
            "        key_str = f\"{method}:{url}:{params_str}:{data_str}\"\n",
            "        return hashlib.sha256(key_str.encode()).hexdigest()\n",
            "    \n",
            "    async def _get_from_cache(self, cache_key: str) -> Optional[Dict[str, Any]]:\n",
            "        \"\"\"Get response from cache.\"\"\"\n",
            "        async with self._cache_lock:\n",
            "            if cache_key in self._cache:\n",
            "                logger.debug(f\"Cache hit for key: {cache_key}\")\n",
            "                return self._cache[cache_key]\n",
            "        return None\n",
            "    \n",
            "    async def _set_cache(self, cache_key: str, response_data: Dict[str, Any]) -> None:\n",
            "        \"\"\"Set response in cache.\"\"\"\n",
            "        async with self._cache_lock:\n",
            "            self._cache[cache_key] = response_data\n",
            "            logger.debug(f\"Response cached with key: {cache_key}\")\n",
            "    \n",
            "    async def _check_rate_limit(self, key: str) -> None:\n",
            "        \"\"\"Check and update rate limit for a key.\"\"\"\n",
            "        if not key or key not in self.rate_limits_config:\n",
            "            return\n",
            "        \n",
            "        requests_limit, window_seconds = self.rate_limits_config[key]\n",
            "        \n",
            "        # Create lock for this key if it doesn't exist\n",
            "        if key not in self._rate_limit_locks:\n",
            "            self._rate_limit_locks[key] = asyncio.Lock()\n",
            "        \n",
            "        async with self._rate_limit_locks[key]:\n",
            "            current_time = time.time()\n",
            "            \n",
            "            # Initialize list if it doesn't exist\n",
            "            if key not in self._rate_limits:\n",
            "                self._rate_limits[key] = []\n",
            "            \n",
            "            # Remove expired timestamps\n",
            "            self._rate_limits[key] = [\n",
            "                ts for ts in self._rate_limits[key] \n",
            "                if current_time - ts < window_seconds\n",
            "            ]\n",
            "            \n",
            "            # Check if rate limit exceeded\n",
            "            if len(self._rate_limits[key]) >= requests_limit:\n",
            "                oldest_timestamp = min(self._rate_limits[key])\n",
            "                wait_time = window_seconds - (current_time - oldest_timestamp)\n",
            "                raise RateLimitError(\n",
            "                    f\"Rate limit exceeded for key '{key}'. Wait {wait_time:.2f} seconds.\"\n",
            "                )\n",
            "            \n",
            "            # Add current request timestamp\n",
            "            self._rate_limits[key].append(current_time)\n",
            "    \n",
            "    def _calculate_retry_delay(self, attempt: int) -> float:\n",
            "        \"\"\"Calculate delay with exponential backoff and jitter.\"\"\"\n",
            "        delay = self.retry_delay * (self.retry_multiplier ** attempt)\n",
            "        jitter = delay * self.retry_jitter * (hash(f\"{attempt}{time.time()}\") % 100) / 100\n",
            "        return delay + jitter\n",
            "    \n",
            "    async def _execute_request(\n",
            "        self,\n",
            "        method: str,\n",
            "        url: str,\n",
            "        config: RequestConfig,\n",
            "        **kwargs: Any,\n",
            "    ) -> ClientResponse:\n",
            "        \"\"\"Execute a single request with retry logic.\"\"\"\n",
            "        last_error: Optional[Exception] = None\n",
            "        \n",
            "        for attempt in range(config.max_retries + 1):\n",
            "            try:\n",
            "                # Check rate limit\n",
            "                if config.rate_limit_key:\n",
            "                    await self._check_rate_limit(config.rate_limit_key)\n",
            "                \n",
            "                # Make the request\n",
            "                response = await self._session.request(  # type: ignore\n",
            "                    method,\n",
            "                    url,\n",
            "                    **kwargs,\n",
            "                    timeout=ClientTimeout(total=config.timeout),\n",
            "                )\n",
            "                \n",
            "                # Raise exception for bad status codes\n",
            "                response.raise_for_status()\n",
            "                return response\n",
            "                \n",
            "            except ClientResponseError as e:\n",
            "                # 5xx errors are retryable, 4xx are not (except 429)\n",
            "                if e.status >= 500:\n",
            "                    last_error = ServerError(f\"Server error: {e.status} {e.message}\")\n",
            "                    if attempt < config.max_retries:\n",
            "                        delay = self._calculate_retry_delay(attempt)\n",
            "                        logger.warning(\n",
            "                            f\"Server error {e.status}, retrying in {delay:.2f}s \"\n",
            "                            f\"(attempt {attempt + 1}/{config.max_retries})\"\n",
            "                        )\n",
            "                        await asyncio.sleep(delay)\n",
            "                        continue\n",
            "                elif e.status == 429:\n",
            "                    last_error = RateLimitError(f\"Rate limited: {e.message}\")\n",
            "                    if attempt < config.max_retries:\n",
            "                        # Use retry-after header if available\n",
            "                        retry_after = response.headers.get(\"Retry-After\", config.retry_delay)\n",
            "                        try:\n",
            "                            wait_time = float(retry_after)\n",
            "                        except ValueError:\n",
            "                            # Try parsing as HTTP-date\n",
            "                            try:\n",
            "                                from email.utils import parsedate_to_datetime\n",
            "                                retry_date = parsedate_to_datetime(retry_after)\n",
            "                                wait_time = (retry_date - datetime.now()).total_seconds()\n",
            "                            except:\n",
            "                                wait_time = config.retry_delay\n",
            "                        \n",
            "                        logger.warning(\n",
            "                            f\"Rate limited, retrying in {wait_time:.2f}s \"\n",
            "                            f\"(attempt {attempt + 1}/{config.max_retries})\"\n",
            "                        )\n",
            "                        await asyncio.sleep(wait_time)\n",
            "                        continue\n",
            "                else:\n",
            "                    last_error = ClientError(f\"Client error: {e.status} {e.message}\")\n",
            "                    # Don't retry for other 4xx errors\n",
            "                    break\n",
            "                    \n",
            "            except (ServerTimeoutError, ServerDisconnectedError, \n",
            "                   ClientOSError, ClientConnectorError) as e:\n",
            "                last_error = NetworkError(f\"Network error: {str(e)}\")\n",
            "                if attempt < config.max_retries:\n",
            "                    delay = self._calculate_retry_delay(attempt)\n",
            "                    logger.warning(\n",
            "                        f\"Network error, retrying in {delay:.2f}s \"\n",
            "                        f\"(attempt {attempt + 1}/{config.max_retries})\"\n",
            "                    )\n",
            "                    await asyncio.sleep(delay)\n",
            "                    continue\n",
            "                    \n",
            "            except asyncio.TimeoutError as e:\n",
            "                last_error = TimeoutError(f\"Request timeout: {str(e)}\")\n",
            "                # Don't retry timeouts by default\n",
            "                break\n",
            "                \n",
            "            except ClientPayloadError as e:\n",
            "                last_error = NonRetryableError(f\"Payload error: {str(e)}\")\n",
            "                break\n",
            "                \n",
            "            except ClientError as e:\n",
            "                last_error = e\n",
            "                break\n",
            "        \n",
            "        # If we've exhausted all retries, raise the last error\n",
            "        if last_error:\n",
            "            raise last_error\n",
            "        \n",
            "        raise RuntimeError(\"Unexpected error in request execution\")\n",
            "    \n",
            "    async def _make_request(\n",
            "        self,\n",
            "        method: HTTPMethod,\n",
            "        endpoint: str,\n",
            "        config: RequestConfig,\n",
            "        **kwargs: Any,\n",
            "    ) -> Dict[str, Any]:\n",
            "        \"\"\"Make a request with caching and retry logic.\"\"\"\n",
            "        # Construct full URL\n",
            "        full_url = f\"{self.base_url}/{endpoint.lstrip('/')}\"\n",
            "        \n",
            "        # Check cache for GET requests\n",
            "        cache_key = None\n",
            "        if config.cache_enabled and method == HTTPMethod.GET:\n",
            "            cache_key = self._get_cache_key(\n",
            "                method.value, full_url, \n",
            "                kwargs.get(\"params\"), kwargs.get(\"json\") or kwargs.get(\"data\")\n",
            "            )\n",
            "            \n",
            "            cached_response = await self._get_from_cache(cache_key)\n",
            "            if cached_response:\n",
            "                return cached_response\n",
            "        \n",
            "        # Execute the request\n",
            "        response = await self._execute_request(\n",
            "            method.value, full_url, config, **kwargs\n",
            "        )\n",
            "        \n",
            "        # Prepare response data\n",
            "        try:\n",
            "            # Try to parse as JSON first\n",
            "            try:\n",
            "                response_data = await response.json()\n",
            "            except:\n",
            "                # Fall back to text\n",
            "                response_text = await response.text()\n",
            "                try:\n",
            "                    response_data = json.loads(response_text)\n",
            "                except:\n",
            "                    response_data =\n"
          ]
        }
      ],
      "source": [
        "# Complex code generation test\n",
        "code_response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an expert Python developer. Write clean, well-documented, production-ready code.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"Create a Python async HTTP client wrapper with:\n",
        "\n",
        "1. Connection pooling\n",
        "2. Automatic retry with exponential backoff\n",
        "3. Request timeout handling\n",
        "4. Response caching with TTL\n",
        "5. Rate limiting\n",
        "6. Proper error handling with custom exceptions\n",
        "\n",
        "Use aiohttp as the base. Include type hints and docstrings.\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.3,\n",
        "    max_tokens=3000\n",
        ")\n",
        "\n",
        "print(\"üíª Advanced Code Generation:\")\n",
        "print(\"=\"*50)\n",
        "print(code_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "code_review",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "832fed7b-916d-4744-d0a3-0191a84cbcf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîí Security Code Review:\n",
            "==================================================\n",
            "## Security Review of Flask Application\n",
            "\n",
            "### 1. Security Issues Found (with Severity)\n",
            "\n",
            "| Issue | Severity | Location |\n",
            "|-------|----------|----------|\n",
            "| **SQL Injection** | Critical | `/search` endpoint |\n",
            "| **Command Injection** | Critical | `/run` endpoint |\n",
            "| **Path Traversal / Arbitrary File Write** | High | `/upload` endpoint |\n",
            "| **Missing Input Validation** | Medium | All endpoints |\n",
            "| **Missing Security Headers** | Medium | Application-wide |\n",
            "| **Insecure File Storage** | High | `/upload` endpoint |\n",
            "\n",
            "---\n",
            "\n",
            "### 2. Vulnerability Explanations\n",
            "\n",
            "#### üî¥ **Critical: SQL Injection (`/search`)**\n",
            "- **Problem**: The query is directly concatenated into the SQL statement using f-strings: `f\"SELECT * FROM users WHERE name = '{query}'\"`\n",
            "- **Impact**: Attackers can inject malicious SQL code to extract, modify, or delete data (e.g., `?q=' OR '1'='1` or `?q='; DROP TABLE users; --`)\n",
            "- **Root Cause**: Using string formatting instead of parameterized queries\n",
            "\n",
            "#### üî¥ **Critical: Command Injection (`/run`)**\n",
            "- **Problem**: User input is passed directly to `subprocess.run()` with `shell=True`\n",
            "- **Impact**: Attackers can execute arbitrary system commands (e.g., `?cmd=ls; rm -rf /`)\n",
            "- **Root Cause**: Using `shell=True` with untrusted input + no input sanitization\n",
            "\n",
            "#### üü† **High: Path Traversal / Arbitrary File Write (`/upload`)**\n",
            "- **Problem**: User-controlled filename is used directly in file path: `file.save('/uploads/' + file.filename)`\n",
            "- **Impact**: Attackers can write files outside intended directory using `../` sequences (e.g., `../../etc/passwd`)\n",
            "- **Additional Risks**:\n",
            "  - No file type validation (could upload `.php`, `.exe`, etc.)\n",
            "  - No size limits (potential DoS)\n",
            "  - No permission checks on upload directory\n",
            "\n",
            "#### üü† **High: Insecure File Storage**\n",
            "- **Problem**: Files saved to a fixed path without sanitization or validation\n",
            "- **Impact**: Could lead to remote code execution if web server serves uploaded files (e.g., uploading `.php` file)\n",
            "\n",
            "#### üü° **Medium: Missing Input Validation**\n",
            "- **Problem**: No validation of input parameters across all endpoints\n",
            "- **Impact**: Enables all the above attacks and potential application crashes\n",
            "\n",
            "#### üü° **Medium: Missing Security Headers**\n",
            "- **Problem**: No security headers (CSP, HSTS, etc.)\n",
            "- **Impact**: Increases risk of XSS, clickjacking, and other client-side attacks\n",
            "\n",
            "---\n",
            "\n",
            "### 3. Corrected Secure Code\n",
            "\n",
            "```python\n",
            "from flask import Flask, request, jsonify\n",
            "from werkzeug.utils import secure_filename\n",
            "import sqlite3\n",
            "import subprocess\n",
            "import os\n",
            "import re\n",
            "from functools import wraps\n",
            "\n",
            "app = Flask(__name__)\n",
            "\n",
            "# Configuration\n",
            "UPLOAD_FOLDER = '/uploads'\n",
            "ALLOWED_EXTENSIONS = {'txt', 'pdf', 'png', 'jpg', 'jpeg', 'gif'}\n",
            "MAX_FILE_SIZE = 16 * 1024 * 1024  # 16MB\n",
            "\n",
            "# Ensure upload directory exists and has proper permissions\n",
            "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
            "\n",
            "# Security headers middleware\n",
            "@app.after_request\n",
            "def add_security_headers(response):\n",
            "    response.headers['X-Content-Type-Options'] = 'nosniff'\n",
            "    response.headers['X-Frame-Options'] = 'DENY'\n",
            "    response.headers['X-XSS-Protection'] = '1; mode=block'\n",
            "    response.headers['Content-Security-Policy'] = \"default-src 'self'\"\n",
            "    return response\n",
            "\n",
            "# Input validation helper\n",
            "def allowed_file(filename):\n",
            "    return '.' in filename and \\\n",
            "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
            "\n",
            "# Sanitize command arguments (whitelist approach)\n",
            "def sanitize_command(cmd):\n",
            "    # Only allow specific safe commands\n",
            "    safe_commands = ['ls', 'date', 'whoami', 'pwd']\n",
            "    parts = cmd.strip().split()\n",
            "    if not parts:\n",
            "        return None\n",
            "    base_cmd = parts[0]\n",
            "    if base_cmd not in safe_commands:\n",
            "        return None\n",
            "    # Only allow safe arguments\n",
            "    safe_args = []\n",
            "    for arg in parts[1:]:\n",
            "        # Only allow alphanumeric, dash, underscore, dot\n",
            "        if re.match(r'^[a-zA-Z0-9_\\-./]+$', arg):\n",
            "            safe_args.append(arg)\n",
            "    return [base_cmd] + safe_args\n",
            "\n",
            "@app.route('/search')\n",
            "def search():\n",
            "    query = request.args.get('q', '')\n",
            "    \n",
            "    # Input validation\n",
            "    if not query or len(query) > 100:\n",
            "        return jsonify({'error': 'Invalid query'}), 400\n",
            "    \n",
            "    # Use parameterized query to prevent SQL injection\n",
            "    try:\n",
            "        conn = sqlite3.connect('database.db')\n",
            "        cursor = conn.execute(\n",
            "            \"SELECT * FROM users WHERE name = ?\", \n",
            "            (query,)\n",
            "        )\n",
            "        results = cursor.fetchall()\n",
            "        conn.close()\n",
            "        return jsonify({'results': results})\n",
            "    except Exception as e:\n",
            "        return jsonify({'error': 'Database error'}), 500\n",
            "\n",
            "@app.route('/run')\n",
            "def run_command():\n",
            "    cmd = request.args.get('cmd', '')\n",
            "    \n",
            "    # Input validation\n",
            "    if not cmd or len(cmd) > 200:\n",
            "        return jsonify({'error': 'Invalid command'}), 400\n",
            "    \n",
            "    # Sanitize and validate command\n",
            "    safe_cmd = sanitize_command(cmd)\n",
            "    if safe_cmd is None:\n",
            "        return jsonify({'error': 'Command not allowed'}), 400\n",
            "    \n",
            "    try:\n",
            "        # Use list form instead of shell=True\n",
            "        result = subprocess.run(\n",
            "            safe_cmd,\n",
            "            capture_output=True,\n",
            "            timeout=5,  # Prevent hanging\n",
            "            text=True\n",
            "        )\n",
            "        return jsonify({\n",
            "            'stdout': result.stdout,\n",
            "            'stderr': result.stderr,\n",
            "            'returncode': result.returncode\n",
            "        })\n",
            "    except subprocess.TimeoutExpired:\n",
            "        return jsonify({'error': 'Command timeout'}), 408\n",
            "    except Exception as e:\n",
            "        return jsonify({'error': 'Command execution failed'}), 500\n",
            "\n",
            "@app.route('/upload', methods=['POST'])\n",
            "def upload():\n",
            "    # Check if file part exists\n",
            "    if 'file' not in request.files:\n",
            "        return jsonify({'error': 'No file part'}), 400\n",
            "    \n",
            "    file = request.files['file']\n",
            "    \n",
            "    # Check if file selected\n",
            "    if file.filename == '':\n",
            "        return jsonify({'error': 'No selected file'}), 400\n",
            "    \n",
            "    # Validate filename\n",
            "    if not allowed_file(file.filename):\n",
            "        return jsonify({'error': 'File type not allowed'}), 400\n",
            "    \n",
            "    # Secure the filename\n",
            "    filename = secure_filename(file.filename)\n",
            "    \n",
            "    # Generate unique filename to prevent overwrites\n",
            "    unique_filename = f\"{os.urandom(16).hex()}_{filename}\"\n",
            "    filepath = os.path.join(UPLOAD_FOLDER, unique_filename)\n",
            "    \n",
            "    try:\n",
            "        # Save file with size limit\n",
            "        file.save(filepath)\n",
            "        \n",
            "        # Optional: Validate file content (e.g., check image headers)\n",
            "        # This would require file type specific validation\n",
            "        \n",
            "        return jsonify({\n",
            "            'message': 'File uploaded successfully',\n",
            "            'filename': unique_filename\n",
            "        })\n",
            "    except Exception as e:\n",
            "        return jsonify({'error': 'File upload failed'}), 500\n",
            "\n",
            "# Error handlers\n",
            "@app.errorhandler(404)\n",
            "def not_found(e):\n",
            "    return jsonify({'error': 'Not found'}), 404\n",
            "\n",
            "@app.errorhandler(500)\n",
            "def internal_error(e):\n",
            "    return jsonify({'error': 'Internal server error'}), 500\n",
            "```\n",
            "\n",
            "### Key Security Improvements:\n",
            "\n",
            "1. **SQL Injection Prevention**:\n",
            "   - Used parameterized queries with `?` placeholders\n",
            "   - Added input length validation\n",
            "\n",
            "2. **Command Injection Prevention**:\n",
            "   - Removed `shell=True`\n",
            "   - Used whitelist approach for allowed commands\n",
            "   - Validated command arguments with regex\n",
            "   - Used list form for subprocess arguments\n",
            "   - Added timeout to prevent hanging\n",
            "\n",
            "3. **Path Traversal Prevention**:\n",
            "   - Used `secure_filename()` to sanitize filenames\n",
            "   - Generated unique filenames to prevent overwrites\n",
            "   - Limited allowed file extensions\n",
            "   - Stored files in dedicated directory\n",
            "\n",
            "4. **Additional Security Measures**:\n",
            "   - Added security headers middleware\n",
            "   - Implemented input validation and sanitization\n",
            "   - Added proper error handling with JSON responses\n",
            "   - Set file size limits\n",
            "   - Used secure file storage practices\n",
            "\n",
            "5. **Best Practices**:\n",
            "   - Used `jsonify` for consistent JSON responses\n",
            "   - Added proper HTTP status codes\n",
            "   - Implemented error handlers\n",
            "   - Used type hints and clear variable names\n",
            "\n",
            "This implementation follows security best practices and significantly reduces the attack surface of the application.\n"
          ]
        }
      ],
      "source": [
        "# Code review and security analysis\n",
        "insecure_code = \"\"\"\n",
        "from flask import Flask, request\n",
        "import sqlite3\n",
        "import subprocess\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/search')\n",
        "def search():\n",
        "    query = request.args.get('q')\n",
        "    conn = sqlite3.connect('database.db')\n",
        "    cursor = conn.execute(f\"SELECT * FROM users WHERE name = '{query}'\")\n",
        "    return str(cursor.fetchall())\n",
        "\n",
        "@app.route('/run')\n",
        "def run_command():\n",
        "    cmd = request.args.get('cmd')\n",
        "    result = subprocess.run(cmd, shell=True, capture_output=True)\n",
        "    return result.stdout.decode()\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload():\n",
        "    file = request.files['file']\n",
        "    file.save('/uploads/' + file.filename)\n",
        "    return 'Uploaded'\n",
        "\"\"\"\n",
        "\n",
        "review_response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a security-focused code reviewer. Identify vulnerabilities and provide secure alternatives.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Review this Flask application for security vulnerabilities:\n",
        "\n",
        "```python\n",
        "{insecure_code}\n",
        "```\n",
        "\n",
        "1. List all security issues found (with severity)\n",
        "2. Explain each vulnerability\n",
        "3. Provide the corrected secure code\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.2,\n",
        "    max_tokens=2500\n",
        ")\n",
        "\n",
        "print(\"üîí Security Code Review:\")\n",
        "print(\"=\"*50)\n",
        "print(review_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "algorithm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d0d515-e52e-42f4-8df2-6d997601d505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßÆ LRU Cache Implementation:\n",
            "==================================================\n",
            "Here's a complete implementation of an LRU Cache with all the requested features:\n",
            "\n",
            "- **O(1) get/put operations** using `OrderedDict`\n",
            "- **Thread-safe** with `threading.Lock`\n",
            "- **TTL support** per entry\n",
            "- **Metrics tracking** (hits, misses, evictions)\n",
            "- **Iterator support**\n",
            "- **Comprehensive tests**\n",
            "\n",
            "```python\n",
            "import time\n",
            "import threading\n",
            "from collections import OrderedDict\n",
            "from typing import Any, Optional, Iterator, Tuple, Dict\n",
            "from dataclasses import dataclass, field\n",
            "import unittest\n",
            "\n",
            "\n",
            "@dataclass\n",
            "class CacheMetrics:\n",
            "    \"\"\"Metrics for cache operations.\"\"\"\n",
            "    hits: int = 0\n",
            "    misses: int = 0\n",
            "    evictions: int = 0\n",
            "    total_gets: int = 0\n",
            "    total_puts: int = 0\n",
            "\n",
            "    def reset(self):\n",
            "        \"\"\"Reset all metrics to zero.\"\"\"\n",
            "        self.hits = 0\n",
            "        self.misses = 0\n",
            "        self.evictions = 0\n",
            "        self.total_gets = 0\n",
            "        self.total_puts = 0\n",
            "\n",
            "\n",
            "class LRUCache:\n",
            "    \"\"\"\n",
            "    Thread-safe LRU Cache with TTL support and metrics tracking.\n",
            "    \n",
            "    Time Complexity:\n",
            "        - get: O(1)\n",
            "        - put: O(1)\n",
            "    \n",
            "    Space Complexity: O(capacity)\n",
            "    \"\"\"\n",
            "    \n",
            "    def __init__(self, capacity: int = 100, default_ttl: Optional[float] = None):\n",
            "        \"\"\"\n",
            "        Initialize the LRU cache.\n",
            "        \n",
            "        Args:\n",
            "            capacity: Maximum number of items the cache can hold.\n",
            "            default_ttl: Default time-to-live in seconds for entries. \n",
            "                        None means no default TTL (entries persist until evicted).\n",
            "        \"\"\"\n",
            "        if capacity <= 0:\n",
            "            raise ValueError(\"Capacity must be positive\")\n",
            "        \n",
            "        self.capacity = capacity\n",
            "        self.default_ttl = default_ttl\n",
            "        self.cache: OrderedDict[str, Tuple[Any, float]] = OrderedDict()\n",
            "        self.lock = threading.RLock()  # Reentrant lock for thread safety\n",
            "        self.metrics = CacheMetrics()\n",
            "    \n",
            "    def get(self, key: str) -> Optional[Any]:\n",
            "        \"\"\"\n",
            "        Get item by key.\n",
            "        \n",
            "        Args:\n",
            "            key: The key to look up.\n",
            "            \n",
            "        Returns:\n",
            "            The value if found and not expired, None otherwise.\n",
            "        \"\"\"\n",
            "        with self.lock:\n",
            "            self.metrics.total_gets += 1\n",
            "            \n",
            "            if key not in self.cache:\n",
            "                self.metrics.misses += 1\n",
            "                return None\n",
            "            \n",
            "            value, expiry_time = self.cache[key]\n",
            "            \n",
            "            # Check if entry has expired\n",
            "            if expiry_time is not None and time.time() > expiry_time:\n",
            "                # Remove expired entry\n",
            "                del self.cache[key]\n",
            "                self.metrics.misses += 1\n",
            "                return None\n",
            "            \n",
            "            # Move to end (most recently used)\n",
            "            self.cache.move_to_end(key)\n",
            "            self.metrics.hits += 1\n",
            "            return value\n",
            "    \n",
            "    def put(self, key: str, value: Any, ttl: Optional[float] = None) -> None:\n",
            "        \"\"\"\n",
            "        Insert or update a key-value pair.\n",
            "        \n",
            "        Args:\n",
            "            key: The key to insert/update.\n",
            "            value: The value to store.\n",
            "            ttl: Time-to-live in seconds for this entry. \n",
            "                 If None, uses default_ttl. None means no expiration.\n",
            "        \"\"\"\n",
            "        with self.lock:\n",
            "            self.metrics.total_puts += 1\n",
            "            \n",
            "            # Calculate expiry time\n",
            "            if ttl is None:\n",
            "                ttl = self.default_ttl\n",
            "            \n",
            "            expiry_time = time.time() + ttl if ttl is not None else None\n",
            "            \n",
            "            # If key exists, remove it first (to handle TTL update)\n",
            "            if key in self.cache:\n",
            "                del self.cache[key]\n",
            "            \n",
            "            # Insert new entry at end (most recently used)\n",
            "            self.cache[key] = (value, expiry_time)\n",
            "            \n",
            "            # Evict if over capacity\n",
            "            if len(self.cache) > self.capacity:\n",
            "                # Pop the first item (least recently used)\n",
            "                self.cache.popitem(last=False)\n",
            "                self.metrics.evictions += 1\n",
            "    \n",
            "    def delete(self, key: str) -> bool:\n",
            "        \"\"\"\n",
            "        Delete a key from the cache.\n",
            "        \n",
            "        Args:\n",
            "            key: The key to delete.\n",
            "            \n",
            "        Returns:\n",
            "            True if key was deleted, False if key didn't exist.\n",
            "        \"\"\"\n",
            "        with self.lock:\n",
            "            if key in self.cache:\n",
            "                del self.cache[key]\n",
            "                return True\n",
            "            return False\n",
            "    \n",
            "    def clear(self) -> None:\n",
            "        \"\"\"Clear all items from the cache.\"\"\"\n",
            "        with self.lock:\n",
            "            self.cache.clear()\n",
            "    \n",
            "    def size(self) -> int:\n",
            "        \"\"\"Return the current number of items in the cache.\"\"\"\n",
            "        with self.lock:\n",
            "            return len(self.cache)\n",
            "    \n",
            "    def __contains__(self, key: str) -> bool:\n",
            "        \"\"\"Check if key exists and is not expired.\"\"\"\n",
            "        return self.get(key) is not None\n",
            "    \n",
            "    def __len__(self) -> int:\n",
            "        \"\"\"Return the number of items in the cache.\"\"\"\n",
            "        return self.size()\n",
            "    \n",
            "    def __iter__(self) -> Iterator[str]:\n",
            "        \"\"\"Iterate over keys in order from most recently used to least recently used.\"\"\"\n",
            "        with self.lock:\n",
            "            current_time = time.time()\n",
            "            for key in reversed(self.cache):\n",
            "                _, expiry_time = self.cache[key]\n",
            "                # Only include non-expired entries\n",
            "                if expiry_time is None or current_time <= expiry_time:\n",
            "                    yield key\n",
            "    \n",
            "    def items(self) -> Iterator[Tuple[str, Any]]:\n",
            "        \"\"\"Iterate over (key, value) pairs in order from most recently used to least recently used.\"\"\"\n",
            "        with self.lock:\n",
            "            current_time = time.time()\n",
            "            for key in reversed(self.cache):\n",
            "                value, expiry_time = self.cache[key]\n",
            "                # Only include non-expired entries\n",
            "                if expiry_time is None or current_time <= expiry_time:\n",
            "                    yield key, value\n",
            "    \n",
            "    def get_metrics(self) -> CacheMetrics:\n",
            "        \"\"\"Return a copy of the current metrics.\"\"\"\n",
            "        with self.lock:\n",
            "            return CacheMetrics(\n",
            "                hits=self.metrics.hits,\n",
            "                misses=self.metrics.misses,\n",
            "                evictions=self.metrics.evictions,\n",
            "                total_gets=self.metrics.total_gets,\n",
            "                total_puts=self.metrics.total_puts\n",
            "            )\n",
            "    \n",
            "    def reset_metrics(self) -> None:\n",
            "        \"\"\"Reset all metrics to zero.\"\"\"\n",
            "        with self.lock:\n",
            "            self.metrics.reset()\n",
            "\n",
            "\n",
            "class TestLRUCache(unittest.TestCase):\n",
            "    \"\"\"Comprehensive tests for LRUCache.\"\"\"\n",
            "    \n",
            "    def setUp(self):\n",
            "        \"\"\"Set up test fixtures.\"\"\"\n",
            "        self.cache = LRUCache(capacity=3)\n",
            "    \n",
            "    def test_basic_operations(self):\n",
            "        \"\"\"Test basic put and get operations.\"\"\"\n",
            "        self.cache.put(\"key1\", \"value1\")\n",
            "        self.assertEqual(self.cache.get(\"key1\"), \"value1\")\n",
            "        \n",
            "        # Update existing key\n",
            "        self.cache.put(\"key1\", \"new_value1\")\n",
            "        self.assertEqual(self.cache.get(\"key1\"), \"new_value1\")\n",
            "        \n",
            "        # Non-existent key\n",
            "        self.assertIsNone(self.cache.get(\"nonexistent\"))\n",
            "    \n",
            "    def test_lru_eviction(self):\n",
            "        \"\"\"Test that LRU eviction works correctly.\"\"\"\n",
            "        # Fill cache to capacity\n",
            "        self.cache.put(\"a\", 1)\n",
            "        self.cache.put(\"b\", 2)\n",
            "        self.cache.put(\"c\", 3)\n",
            "        \n",
            "        # Access 'a' to make it recently used\n",
            "        self.cache.get(\"a\")\n",
            "        \n",
            "        # Add new item, should evict 'b' (LRU)\n",
            "        self.cache.put(\"d\", 4)\n",
            "        \n",
            "        # Check eviction\n",
            "        self.assertIsNone(self.cache.get(\"b\"))  # Evicted\n",
            "        self.assertEqual(self.cache.get(\"a\"), 1)  # Still there\n",
            "        self.assertEqual(self.cache.get(\"c\"), 3)  # Still there\n",
            "        self.assertEqual(self.cache.get(\"d\"), 4)  # New item\n",
            "    \n",
            "    def test_ttl_expiration(self):\n",
            "        \"\"\"Test TTL functionality.\"\"\"\n",
            "        # Create cache with short TTL\n",
            "        cache = LRUCache(capacity=3, default_ttl=0.1)\n",
            "        \n",
            "        cache.put(\"key1\", \"value1\")\n",
            "        self.assertEqual(cache.get(\"key1\"), \"value1\")\n",
            "        \n",
            "        # Wait for TTL to expire\n",
            "        time.sleep(0.15)\n",
            "        \n",
            "        # Entry should be expired\n",
            "        self.assertIsNone(cache.get(\"key1\"))\n",
            "    \n",
            "    def test_ttl_override(self):\n",
            "        \"\"\"Test that per-entry TTL overrides default TTL.\"\"\"\n",
            "        cache = LRUCache(capacity=3, default_ttl=0.1)\n",
            "        \n",
            "        # Put with custom TTL\n",
            "        cache.put(\"short\", \"value\", ttl=0.05)\n",
            "        cache.put(\"long\", \"value\", ttl=0.2)\n",
            "        \n",
            "        # Wait for short TTL to expire\n",
            "        time.sleep(0.1)\n",
            "        \n",
            "        # Short TTL entry should be expired, long TTL should still be there\n",
            "        self.assertIsNone(cache.get(\"short\"))\n",
            "        self.assertEqual(cache.get(\"long\"), \"value\")\n",
            "    \n",
            "    def test_metrics(self):\n",
            "        \"\"\"Test metrics tracking.\"\"\"\n",
            "        cache = LRUCache(capacity=2)\n",
            "        \n",
            "        # Initial metrics\n",
            "        metrics = cache.get_metrics()\n",
            "        self.assertEqual(metrics.hits, 0)\n",
            "        self.assertEqual(metrics.misses, 0)\n",
            "        self.assertEqual(metrics.evictions, 0)\n",
            "        \n",
            "        # Perform operations\n",
            "        cache.put(\"a\", 1)\n",
            "        cache.put(\"b\", 2)\n",
            "        cache.get(\"a\")  # hit\n",
            "        cache.get(\"c\")  # miss\n",
            "        cache.put(\"c\", 3)  # eviction of 'b'\n",
            "        \n",
            "        metrics = cache.get_metrics()\n",
            "        self.assertEqual(metrics.total_gets, 2)\n",
            "        self.assertEqual(metrics.total_puts, 3)\n",
            "        self.assertEqual(metrics.hits, 1)\n",
            "        self.assertEqual(metrics.misses, 1)\n",
            "        self.assertEqual(metrics.evictions, 1)\n",
            "    \n",
            "    def test_reset_metrics(self):\n",
            "        \"\"\"Test metrics reset functionality.\"\"\"\n",
            "        cache = LRUCache(capacity=2)\n",
            "        cache.put(\"a\", 1)\n",
            "        cache.get(\"a\")\n",
            "        cache.reset_metrics()\n",
            "        \n",
            "        metrics = cache.get_metrics()\n",
            "        self.assertEqual(metrics.hits, 0)\n",
            "        self.assertEqual(metrics.misses, 0)\n",
            "    \n",
            "    def test_iteration(self):\n",
            "        \"\"\"Test iterator support.\"\"\"\n",
            "        cache = LRUCache(capacity=3)\n",
            "        cache.put(\"a\", 1)\n",
            "        cache.put(\"b\", 2)\n",
            "        cache.put(\"c\", 3)\n",
            "        \n",
            "        # Access 'a' to make it most recently used\n",
            "        cache.get(\"a\")\n",
            "        \n",
            "        # Iterate and check order (most recently used first)\n",
            "        keys = list(cache)\n",
            "        self.assertEqual(keys, [\"a\", \"c\", \"b\"])\n",
            "    \n",
            "    def test_ttl_expiration_during_iteration(self):\n",
            "        \"\"\"Test that expired entries are excluded from iteration.\"\"\"\n",
            "        cache = LRUCache(capacity=3, default_ttl=0.1)\n",
            "        cache.put(\"a\", 1)\n",
            "        cache.put(\"b\", 2)\n",
            "        \n",
            "        # Wait for TTL to expire\n",
            "        time.sleep(0.15)\n",
            "        \n",
            "        # All entries should be expired\n",
            "        self.assertEqual(list(cache), [])\n",
            "    \n",
            "    def test_thread_safety(self):\n",
            "        \"\"\"Test thread safety with concurrent operations.\"\"\"\n",
            "        cache = LRUCache(capacity=100)\n",
            "        errors = []\n",
            "        \n",
            "        def writer(start, end):\n",
            "            try:\n",
            "                for i in range(start, end):\n",
            "                    cache.put(f\"key{i}\", i)\n",
            "            except Exception as e:\n",
            "                errors.append(e)\n",
            "        \n",
            "        def reader(start, end):\n",
            "            try:\n",
            "                for i in range(start, end):\n",
            "                    cache.get(f\"key{i}\")\n",
            "            except Exception as e:\n",
            "                errors.append(e)\n",
            "        \n",
            "        # Create threads\n",
            "        threads = []\n",
            "        for i in range(5):\n",
            "            threads.append(threading.Thread(target=writer, args=(i*20, (i+1)*20)))\n",
            "            threads.append(threading.Thread(target=reader, args=(i*20, (i+1)*20)))\n",
            "        \n",
            "        # Start all threads\n",
            "        for t in threads:\n",
            "            t.start()\n",
            "        \n",
            "        # Wait for all threads to complete\n",
            "        for t in threads:\n",
            "            t.join()\n",
            "        \n",
            "        # Check no errors occurred\n",
            "        self.assertEqual(errors, [], \"Thread safety test failed\")\n",
            "        \n",
            "        # Verify cache is in consistent state\n",
            "        self.assertLessEqual(cache.size(), 100)\n",
            "    \n",
            "    def test_capacity_validation(self):\n",
            "        \"\"\"Test that invalid capacity raises ValueError.\"\"\"\n",
            "        with self.assertRaises(ValueError):\n",
            "            LRUCache(capacity=0)\n",
            "        with self.assertRaises(ValueError):\n",
            "            LRUCache(capacity=-1)\n",
            "    \n",
            "    def test_delete_operation(self):\n",
            "        \"\"\"Test delete operation.\"\"\"\n",
            "        cache = LRUCache(capacity=3)\n",
            "        cache.put(\"a\", 1)\n",
            "        cache.put(\"b\", 2)\n",
            "        \n",
            "        self.assertTrue(cache.delete(\"a\"))\n",
            "        self.assertFalse(cache.delete(\"a\"))  # Already deleted\n",
            "        self.assertIsNone(cache.get(\"a\"))\n",
            "        self.assertEqual(cache.get(\"b\"), 2)\n",
            "    \n",
            "    def test_contains_operator(self):\n",
            "        \"\"\"Test __contains__ operator.\"\"\"\n",
            "        cache = LRUCache(capacity=2)\n",
            "        cache.put(\"a\", 1)\n",
            "        \n",
            "        self.assertIn(\"a\", cache)\n",
            "        self.assertNotIn(\"b\", cache)\n",
            "        \n",
            "        # TTL expiration\n",
            "        cache_ttl = LRUCache(capacity=2, default_ttl=0.05)\n",
            "        cache_ttl.put(\"x\", 1)\n",
            "        self.assertIn(\"x\", cache_ttl)\n",
            "        time.sleep(0.1)\n",
            "        self.assertNotIn(\"x\", cache_ttl)\n",
            "    \n",
            "    def test_clear(self):\n",
            "        \"\"\"Test clear operation.\"\"\"\n",
            "        cache = LRUCache(capacity=3)\n",
            "        cache.put(\"a\", 1)\n",
            "        cache.put(\"b\", 2)\n",
            "        cache.put(\"c\", 3)\n",
            "        \n",
            "        cache.clear()\n",
            "        self.assertEqual(cache.size(), 0)\n",
            "        self.assertEqual(list(cache), [])\n",
            "    \n",
            "    def test_items_iterator(self):\n",
            "        \"\"\"Test items() iterator.\"\"\"\n",
            "        cache = LRUCache(capacity=3)\n",
            "        cache.put(\"a\", 1)\n",
            "        cache.put(\"b\", 2)\n",
            "        cache.put(\"c\", 3)\n",
            "        \n",
            "        items = list(cache.items())\n",
            "        self.assertEqual(len(items), 3)\n",
            "        self.assertEqual(items[0], (\"c\", 3))  # Most recently used first\n",
            "        self.assertEqual(items[1],\n"
          ]
        }
      ],
      "source": [
        "# Algorithm design and implementation\n",
        "algo_response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"Implement an LRU (Least Recently Used) Cache in Python with O(1) time complexity for both get and put operations.\n",
        "\n",
        "Requirements:\n",
        "1. Use OrderedDict or implement with doubly linked list + hashmap\n",
        "2. Thread-safe implementation\n",
        "3. Support for TTL (time-to-live) on individual entries\n",
        "4. Metrics tracking (hits, misses, evictions)\n",
        "5. Iterator support\n",
        "\n",
        "Include comprehensive tests.\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.3,\n",
        "    max_tokens=3000\n",
        ")\n",
        "\n",
        "print(\"üßÆ LRU Cache Implementation:\")\n",
        "print(\"=\"*50)\n",
        "print(algo_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section6"
      },
      "source": [
        "---\n",
        "\n",
        "## üåä Section 6: Streaming Responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "streaming",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14a2c14-0585-49a6-d290-475e176c5ff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìñ Streaming Code Explanation:\n",
            "==================================================\n",
            "\n",
            "Python‚Äôs **Global Interpreter Lock (GIL)** is a mutex (mutual exclusion lock) that protects access to Python objects, preventing multiple native threads from executing Python *bytecode* simultaneously in CPython (the standard Python implementation). It exists primarily to ensure thread safety in CPython‚Äôs reference-counted memory management system.\n",
            "\n",
            "---\n",
            "\n",
            "## üîí How the GIL Works (CPython-specific)\n",
            "\n",
            "### Core Mechanics:\n",
            "- Only **one thread** holds the GIL at a time.\n",
            "- Threads **take turns** executing Python bytecode.\n",
            "- The GIL is released (or yielded) periodically:\n",
            "  - Every **5 milliseconds** (by default, via `sys.setswitchinterval()`), or\n",
            "  - When a thread performs a **blocking I/O operation** (e.g., `time.sleep()`, file I/O, socket calls), or\n",
            "  - When a thread explicitly releases it (e.g., in C extensions using `Py_BEGIN_ALLOW_THREADS`).\n",
            "\n",
            "> ‚ö†Ô∏è The GIL is **specific to CPython**. Other implementations (e.g., PyPy, Jython, IronPython) may not have one.\n",
            "\n",
            "---\n",
            "\n",
            "## üßµ Implications for Multithreading\n",
            "\n",
            "### ‚úÖ Where threads *help*:\n",
            "- **I/O-bound tasks** (e.g., web scraping, file processing, network requests) ‚Äî because threads spend time waiting (blocking), during which the GIL is released, allowing other threads to run.\n",
            "\n",
            "### ‚ùå Where threads *don‚Äôt help* (or hurt):\n",
            "- **CPU-bound tasks** ‚Äî since only one thread executes Python bytecode at a time, adding threads won‚Äôt speed up computation. In fact, **thread switching overhead can make things slower** than sequential execution.\n",
            "\n",
            "---\n",
            "\n",
            "## üìú Code Examples\n",
            "\n",
            "### 1Ô∏è‚É£ CPU-bound task: Threads *do not* speed up execution\n",
            "\n",
            "```python\n",
            "import threading\n",
            "import time\n",
            "\n",
            "def cpu_bound(n):\n",
            "    # Simulate heavy computation\n",
            "    count = 0\n",
            "    for i in range(n):\n",
            "        count += i * i\n",
            "    return count\n",
            "\n",
            "def run_sequential():\n",
            "    start = time.time()\n",
            "    cpu_bound(5_000_000)\n",
            "    cpu_bound(5_000_000)\n",
            "    print(f\"Sequential: {time.time() - start:.2f}s\")\n",
            "\n",
            "def run_threads():\n",
            "    start = time.time()\n",
            "    t1 = threading.Thread(target=cpu_bound, args=(5_000_000,))\n",
            "    t2 = threading.Thread(target=cpu_bound, args=(5_000_000,))\n",
            "    t1.start(); t2.start()\n",
            "    t1.join(); t2.join()\n",
            "    print(f\"Multithreaded: {time.time() - start:.2f}s\")\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    run_sequential()\n",
            "    run_threads()\n",
            "```\n",
            "\n",
            "**Typical output:**\n",
            "```\n",
            "Sequential: 2.80s\n",
            "Multithreaded: 2.95s   # Often *slower* due to GIL contention!\n",
            "```\n",
            "\n",
            "> ‚úÖ **Fix for CPU-bound**: Use `multiprocessing` (separate processes, each with its own GIL).\n",
            "\n",
            "```python\n",
            "from multiprocessing import Pool\n",
            "\n",
            "def run_parallel():\n",
            "    start = time.time()\n",
            "    with Pool(2) as p:\n",
            "        p.map(cpu_bound, [5_000_000, 5_000_000])\n",
            "    print(f\"Multiprocessing: {time.time() - start:.2f}s\")\n",
            "# Output: ~1.5s (on 2-core CPU)\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "### 2Ô∏è‚É£ I/O-bound task: Threads *do* help\n",
            "\n",
            "```python\n",
            "import threading\n",
            "import time\n",
            "import requests\n",
            "\n",
            "def fetch_url(url):\n",
            "    response = requests.get(url)  # Blocking I/O ‚Üí releases GIL\n",
            "    return len(response.text)\n",
            "\n",
            "urls = [\n",
            "    \"https://httpbin.org/delay/1\",\n",
            "    \"https://httpbin.org/delay/1\",\n",
            "    \"https://httpbin.org/delay/1\"\n",
            "] * 3  # 9 URLs\n",
            "\n",
            "def run_sequential():\n",
            "    start = time.time()\n",
            "    for url in urls:\n",
            "        fetch_url(url)\n",
            "    print(f\"Sequential: {time.time() - start:.2f}s\")\n",
            "\n",
            "def run_threads():\n",
            "    start = time.time()\n",
            "    threads = [threading.Thread(target=fetch_url, args=(url,)) for url in urls]\n",
            "    for t in threads: t.start()\n",
            "    for t in threads: t.join()\n",
            "    print(f\"Multithreaded: {time.time() - start:.2f}s\")\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    run_sequential()  # ~9s (1s per request, serial)\n",
            "    run_threads()     #\n",
            "\n",
            "‚úÖ Streaming complete!\n"
          ]
        }
      ],
      "source": [
        "# Streaming response example\n",
        "print(\"üìñ Streaming Code Explanation:\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "stream = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain how Python's GIL (Global Interpreter Lock) works and its implications for multithreading. Include code examples.\"\n",
        "        }\n",
        "    ],\n",
        "    stream=True,\n",
        "    temperature=0.5,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "full_response = \"\"\n",
        "for chunk in stream:\n",
        "    if chunk.choices[0].delta.content:\n",
        "        content = chunk.choices[0].delta.content\n",
        "        full_response += content\n",
        "        print(content, end=\"\", flush=True)\n",
        "\n",
        "print(\"\\n\\n‚úÖ Streaming complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section7"
      },
      "source": [
        "---\n",
        "\n",
        "## üìä Section 7: Structured Output (JSON Mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "json_output",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1d3032a-6a93-4f7c-872f-1de1e67e2d06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Code Analysis JSON:\n",
            "==================================================\n",
            "{\n",
            "  \"class_name\": \"UserService\",\n",
            "  \"methods\": [\n",
            "    {\n",
            "      \"name\": \"__init__\",\n",
            "      \"parameters\": [\n",
            "        \"self\",\n",
            "        \"db\"\n",
            "      ],\n",
            "      \"return_type\": \"None\",\n",
            "      \"complexity\": \"O(1)\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"create_user\",\n",
            "      \"parameters\": [\n",
            "        \"self\",\n",
            "        \"name\",\n",
            "        \"email\"\n",
            "      ],\n",
            "      \"return_type\": \"dict\",\n",
            "      \"complexity\": \"O(1)\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"get_user\",\n",
            "      \"parameters\": [\n",
            "        \"self\",\n",
            "        \"user_id\"\n",
            "      ],\n",
            "      \"return_type\": \"Any\",\n",
            "      \"complexity\": \"O(1)\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"delete_user\",\n",
            "      \"parameters\": [\n",
            "        \"self\",\n",
            "        \"user_id\"\n",
            "      ],\n",
            "      \"return_type\": \"None\",\n",
            "      \"complexity\": \"O(1)\"\n",
            "    }\n",
            "  ],\n",
            "  \"dependencies\": [\n",
            "    \"db\"\n",
            "  ],\n",
            "  \"issues\": [\n",
            "    \"No input validation for `name` and `email` in `create_user` (e.g., empty strings, invalid email format)\",\n",
            "    \"No error handling for database operations (e.g., exceptions from `insert`, `find_one`, `delete`)\",\n",
            "    \"No return value validation in `create_user` (e.g., no check if user was actually inserted)\",\n",
            "    \"No return value in `delete_user` (should indicate success/failure)\",\n",
            "    \"Assumes `db` object has methods `insert`, `find_one`, and `delete` \\u2014 no interface or type hinting to enforce this contract\",\n",
            "    \"No type hints for parameters or return types, reducing code clarity and IDE/tooling support\",\n",
            "    \"No documentation (docstrings) for methods, reducing maintainability\",\n",
            "    \"Potential security issue: `user_id` used directly in query without sanitization/validation (if `user_id` comes from untrusted input)\"\n",
            "  ],\n",
            "  \"test_suggestions\": [\n",
            "    \"Test `create_user` with valid inputs and verify returned user matches expected structure\",\n",
            "    \"Test `create_user` with invalid inputs (e.g., empty name, invalid email) and verify appropriate behavior (exception or rejection)\",\n",
            "    \"Test `get_user` with existing and non-existing `user_id`\",\n",
            "    \"Test `delete_user` with existing and non-existing `user_id`, and verify return value indicates success/failure\",\n",
            "    \"Test `create_user` when database `insert` fails (e.g., mock raises exception)\",\n",
            "    \"Test `get_user` when database `find_one` fails\",\n",
            "    \"Test `delete_user` when database `delete` fails\",\n",
            "    \"Verify `db` dependency is correctly stored and used (e.g., via mocking)\",\n",
            "    \"Test behavior when `db` is `None` or missing required methods\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# JSON structured output for code analysis\n",
        "code_to_analyze = \"\"\"\n",
        "class UserService:\n",
        "    def __init__(self, db):\n",
        "        self.db = db\n",
        "\n",
        "    def create_user(self, name, email):\n",
        "        user = {'name': name, 'email': email}\n",
        "        self.db.insert(user)\n",
        "        return user\n",
        "\n",
        "    def get_user(self, user_id):\n",
        "        return self.db.find_one({'id': user_id})\n",
        "\n",
        "    def delete_user(self, user_id):\n",
        "        self.db.delete({'id': user_id})\n",
        "\"\"\"\n",
        "\n",
        "json_response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Analyze code and return structured JSON output.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Analyze this Python code and return a JSON object with:\n",
        "- class_name: name of the class\n",
        "- methods: array of method objects with (name, parameters, return_type, complexity)\n",
        "- dependencies: array of external dependencies\n",
        "- issues: array of potential issues or improvements\n",
        "- test_suggestions: array of test cases that should be written\n",
        "\n",
        "```python\n",
        "{code_to_analyze}\n",
        "```\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    response_format={\"type\": \"json_object\"},\n",
        "    temperature=0.2\n",
        ")\n",
        "\n",
        "print(\"üìä Code Analysis JSON:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    result = json.loads(json_response.choices[0].message.content)\n",
        "    print(json.dumps(result, indent=2))\n",
        "except json.JSONDecodeError:\n",
        "    print(json_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "api_spec_generation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d180f30-b645-4835-d8c0-5ebc282817d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù OpenAPI Specification:\n",
            "==================================================\n",
            "{\n",
            "  \"openapi\": \"3.0.3\",\n",
            "  \"info\": {\n",
            "    \"title\": \"TODO API\",\n",
            "    \"description\": \"A simple REST API for managing TODO items\",\n",
            "    \"version\": \"1.0.0\"\n",
            "  },\n",
            "  \"servers\": [\n",
            "    {\n",
            "      \"url\": \"https://api.example.com/v1\",\n",
            "      \"description\": \"Production server\"\n",
            "    }\n",
            "  ],\n",
            "  \"paths\": {\n",
            "    \"/todos\": {\n",
            "      \"get\": {\n",
            "        \"summary\": \"List all todos\",\n",
            "        \"description\": \"Retrieve a paginated list of TODO items\",\n",
            "        \"operationId\": \"listTodos\",\n",
            "        \"tags\": [\"Todos\"],\n",
            "        \"parameters\": [\n",
            "          {\n",
            "            \"name\": \"page\",\n",
            "            \"in\": \"query\",\n",
            "            \"description\": \"Page number for pagination (1-based)\",\n",
            "            \"required\": false,\n",
            "            \"schema\": {\n",
            "              \"type\": \"integer\",\n",
            "              \"minimum\": 1,\n",
            "              \"default\": 1\n",
            "            }\n",
            "          },\n",
            "          {\n",
            "            \"name\": \"limit\",\n",
            "            \"in\": \"query\",\n",
            "            \"description\": \"Number of items per page\",\n",
            "            \"required\": false,\n",
            "            \"schema\": {\n",
            "              \"type\": \"integer\",\n",
            "              \"minimum\": 1,\n",
            "              \"maximum\": 100,\n",
            "              \"default\": 20\n",
            "            }\n",
            "          }\n",
            "        ],\n",
            "        \"responses\": {\n",
            "          \"200\": {\n",
            "            \"description\": \"Successful response with paginated todos\",\n",
            "            \"content\": {\n",
            "              \"application/json\": {\n",
            "                \"schema\": {\n",
            "                  \"$ref\": \"#/components/schemas/PaginatedTodoList\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "          },\n",
            "          \"401\": {\n",
            "            \"$ref\": \"#/components/responses/Unauthorized\"\n",
            "          },\n",
            "          \"500\": {\n",
            "            \"$ref\": \"#/components/responses/ServerError\"\n",
            "          }\n",
            "        },\n",
            "        \"security\": [\n",
            "          {\n",
            "            \"BearerAuth\": []\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      \"post\": {\n",
            "        \"summary\": \"Create a new todo\",\n",
            "        \"description\": \"Create a new TODO item\",\n",
            "        \"operationId\": \"createTodo\",\n",
            "        \"tags\": [\"Todos\"],\n",
            "        \"requestBody\": {\n",
            "          \"required\": true,\n",
            "          \"content\": {\n",
            "            \"application/json\": {\n",
            "              \"schema\": {\n",
            "                \"$ref\": \"#/components/schemas/CreateTodoRequest\"\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        },\n",
            "        \"responses\": {\n",
            "          \"201\": {\n",
            "            \"description\": \"TODO item created successfully\",\n",
            "            \"headers\": {\n",
            "              \"Location\": {\n",
            "                \"description\": \"URL of the newly created TODO item\",\n",
            "                \"schema\": {\n",
            "                  \"type\": \"string\",\n",
            "                  \"format\": \"uri\"\n",
            "                }\n",
            "              }\n",
            "            },\n",
            "            \"content\": {\n",
            "              \"application/json\": {\n",
            "                \"schema\": {\n",
            "                  \"$ref\": \"#/components/schemas/Todo\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "          },\n",
            "          \"400\": {\n",
            "            \"$ref\": \"#/components/responses/BadRequest\"\n",
            "          },\n",
            "          \"401\": {\n",
            "            \"$ref\": \"#/components/responses/Unauthorized\"\n",
            "          },\n",
            "          \"500\": {\n",
            "            \"$ref\": \"#/components/responses/ServerError\"\n",
            "          }\n",
            "        },\n",
            "        \"security\": [\n",
            "          {\n",
            "            \"BearerAuth\": []\n",
            "          }\n",
            "        ]\n",
            "      }\n",
            "    },\n",
            "    \"/todos/{id}\": {\n",
            "      \"get\": {\n",
            "        \"summary\": \"Get a specific todo\",\n",
            "        \"description\": \"Retrieve a TODO item by its ID\",\n",
            "        \"operationId\": \"getTodo\",\n",
            "        \"tags\": [\"Todos\"],\n",
            "        \"parameters\": [\n",
            "          {\n",
            "            \"name\": \"id\",\n",
            "            \"in\": \"path\",\n",
            "            \"required\": true,\n",
            "            \"description\": \"Unique identifier of the TODO item\",\n",
            "            \"schema\": {\n",
            "              \"type\": \"string\",\n",
            "              \"format\": \"uuid\"\n",
            "            }\n",
            "          }\n",
            "        ],\n",
            "        \"responses\": {\n",
            "          \"200\": {\n",
            "            \"description\": \"Successful response with the TODO item\",\n",
            "            \"content\": {\n",
            "              \"application/json\": {\n",
            "                \"schema\": {\n",
            "                  \"$ref\": \"#/components/schemas/Todo\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "          },\n",
            "          \"401\": {\n",
            "            \"$ref\": \"#/components/responses/Unauthorized\"\n",
            "          },\n",
            "          \"404\": {\n",
            "            \"$ref\": \"#/components/responses/NotFound\"\n",
            "          },\n",
            "          \"500\": {\n",
            "            \"$ref\": \"#/components/responses/ServerError\"\n",
            "          }\n",
            "        },\n",
            "        \"security\": [\n",
            "          {\n",
            "            \"BearerAuth\": []\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      \"put\": {\n",
            "        \"summary\": \"Update a todo\",\n",
            "        \"description\": \"Update an existing TODO item\",\n",
            "        \"operationId\": \"updateTodo\",\n",
            "        \"tags\": [\"Todos\"],\n",
            "        \"parameters\": [\n",
            "          {\n",
            "            \"name\": \"id\",\n",
            "            \"in\": \"path\",\n",
            "            \"required\": true,\n",
            "            \"description\": \"Unique identifier of the TODO item to update\",\n",
            "            \"schema\": {\n",
            "              \"type\": \"string\",\n",
            "              \"format\": \"uuid\"\n",
            "            }\n",
            "          }\n",
            "        ],\n",
            "        \"requestBody\": {\n",
            "          \"required\": true,\n",
            "          \"content\": {\n",
            "            \"application/json\": {\n",
            "              \"schema\": {\n",
            "                \"$ref\": \"#/components/schemas/UpdateTodoRequest\"\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        },\n",
            "        \"responses\": {\n",
            "          \"200\": {\n",
            "            \"description\": \"TODO item updated successfully\",\n",
            "            \"content\": {\n",
            "              \"application/json\": {\n",
            "                \"schema\": {\n",
            "                  \"$ref\": \"#/components/schemas/Todo\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "          },\n",
            "          \"400\": {\n",
            "            \"$ref\": \"#/components/responses/BadRequest\"\n",
            "          },\n",
            "          \"401\": {\n",
            "            \"$ref\": \"#/components/responses/Unauthorized\"\n",
            "          },\n",
            "          \"404\": {\n",
            "            \"$ref\": \"#/components/responses/NotFound\"\n",
            "          },\n",
            "          \"500\": {\n",
            "            \"$ref\": \"#/components/responses/ServerError\"\n",
            "          }\n",
            "        },\n",
            "        \"security\": [\n",
            "          {\n",
            "            \"BearerAuth\": []\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      \"delete\": {\n",
            "        \"summary\": \"Delete a todo\",\n",
            "        \"description\": \"Delete a TODO item by its ID\",\n",
            "        \"operationId\": \"deleteTodo\",\n",
            "        \"tags\": [\"Todos\"],\n",
            "        \"parameters\": [\n",
            "          {\n",
            "            \"name\": \"id\",\n",
            "            \"in\": \"path\",\n",
            "            \"required\": true,\n",
            "            \"description\": \"Unique identifier of the TODO item to delete\",\n",
            "            \"schema\": {\n",
            "              \"type\": \"string\",\n",
            "              \"format\": \"uuid\"\n",
            "            }\n",
            "          }\n",
            "        ],\n",
            "        \"responses\": {\n",
            "          \"204\": {\n",
            "            \"description\": \"TODO item deleted successfully (no content)\"\n",
            "          },\n",
            "          \"401\": {\n",
            "            \"$ref\": \"#/components/responses/Unauthorized\"\n",
            "          },\n",
            "          \"404\": {\n",
            "            \"$ref\": \"#/components/responses/NotFound\"\n",
            "          },\n",
            "          \"500\": {\n",
            "            \"$ref\": \"#/components/responses/ServerError\"\n",
            "          }\n",
            "        },\n",
            "        \"security\": [\n",
            "          {\n",
            "            \"BearerAuth\": []\n",
            "          }\n",
            "        ]\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"components\": {\n",
            "    \"securitySchemes\": {\n",
            "      \"BearerAuth\": {\n",
            "        \"type\": \"http\",\n",
            "        \"scheme\": \"bearer\",\n",
            "        \"bearerFormat\": \"JWT\",\n",
            "        \"description\": \"Enter your JWT token in the format: `Bearer <token>`\"\n",
            "      }\n",
            "    },\n",
            "    \"schemas\": {\n",
            "      \"Todo\": {\n",
            "        \"type\": \"object\",\n",
            "        \"required\": [\"id\", \"title\", \"completed\", \"createdAt\"],\n",
            "        \"properties\": {\n",
            "          \"id\": {\n",
            "            \"type\": \"string\",\n",
            "            \"format\": \"uuid\",\n",
            "            \"description\": \"Unique identifier of the TODO item\",\n",
            "            \"example\": \"550e8400-e29b-41d4-a716-446655440000\"\n",
            "          },\n",
            "          \"title\": {\n",
            "            \"type\": \"string\",\n",
            "            \"minLength\": 1,\n",
            "            \"maxLength\": 255,\n",
            "            \"description\": \"Title of the TODO item\",\n",
            "            \"example\": \"Buy groceries\"\n",
            "          },\n",
            "          \"description\": {\n",
            "            \"type\": \"string\",\n",
            "            \"nullable\": true,\n",
            "            \"maxLength\": 2000,\n",
            "            \"description\": \"Optional description of the TODO item\",\n",
            "            \"example\": \"Milk, eggs, bread\"\n",
            "          },\n",
            "          \"completed\": {\n",
            "            \"type\": \"boolean\",\n",
            "            \"description\": \"Whether the TODO item is completed\",\n",
            "            \"example\": false\n",
            "          },\n",
            "          \"createdAt\": {\n",
            "            \"type\": \"string\",\n",
            "            \"format\": \"date-time\",\n",
            "            \"description\": \"Timestamp when the TODO item was created\",\n",
            "            \"example\": \"2023-01-15T10:30:00Z\"\n",
            "          },\n",
            "          \"updatedAt\": {\n",
            "            \"type\": \"string\",\n",
            "            \"format\": \"date-time\",\n",
            "            \"nullable\": true,\n",
            "            \"description\": \"Timestamp when the TODO item was last updated\",\n",
            "            \"example\": \"2023-01-16T14:20:00Z\"\n",
            "          }\n",
            "        }\n",
            "      },\n",
            "      \"CreateTodoRequest\": {\n",
            "        \"type\": \"object\",\n",
            "        \"required\": [\"title\"],\n",
            "        \"properties\": {\n",
            "          \"title\": {\n",
            "            \"type\": \"string\",\n",
            "            \"minLength\": 1,\n",
            "            \"maxLength\": 255,\n",
            "            \"description\": \"Title of the TODO item\",\n",
            "            \"example\": \"Buy groceries\"\n",
            "          },\n",
            "          \"description\": {\n",
            "            \"type\": \"string\",\n",
            "            \"nullable\": true,\n",
            "            \"maxLength\": 2000,\n",
            "            \"description\": \"Optional description of the TODO item\",\n",
            "            \"example\": \"Milk, eggs, bread\"\n",
            "          },\n",
            "          \"completed\": {\n",
            "            \"type\": \"boolean\",\n",
            "            \"description\": \"Initial completion status (default: false)\",\n",
            "            \"example\": false\n",
            "          }\n",
            "        }\n",
            "      },\n",
            "      \"UpdateTodoRequest\": {\n",
            "        \"type\": \"object\",\n",
            "        \"properties\": {\n",
            "          \"title\": {\n",
            "            \"type\": \"string\",\n",
            "            \"minLength\": 1,\n",
            "            \"maxLength\": 255,\n",
            "            \"description\": \"Updated title of the TODO item\",\n",
            "            \"example\": \"Buy groceries and cook dinner\"\n",
            "          },\n",
            "          \"description\": {\n",
            "            \"type\": \"string\",\n",
            "            \"nullable\": true,\n",
            "            \"maxLength\": 2000,\n",
            "            \"description\": \"Updated description of the TODO item\",\n",
            "            \"example\": \"Milk, eggs, bread, vegetables\"\n",
            "          },\n",
            "          \"completed\": {\n",
            "            \"type\": \"boolean\",\n",
            "            \"description\": \"Updated completion status\",\n",
            "            \"example\": true\n",
            "          }\n",
            "        }\n",
            "      },\n",
            "      \"PaginatedTodoList\": {\n",
            "        \"type\": \"object\",\n",
            "        \"required\": [\"items\", \"page\", \"limit\", \"total\"],\n",
            "        \"properties\": {\n",
            "          \"items\": {\n",
            "            \"type\": \"array\",\n",
            "            \"items\": {\n",
            "              \"$ref\": \"#/components/schemas/Todo\"\n",
            "            },\n",
            "            \"description\": \"List of TODO items for the current page\"\n",
            "          },\n",
            "          \"page\": {\n",
            "            \"type\": \"integer\",\n",
            "            \"minimum\": 1,\n",
            "            \"description\": \"Current page number\",\n",
            "            \"example\": 1\n",
            "          },\n",
            "          \"limit\": {\n",
            "            \"type\": \"integer\",\n",
            "            \"minimum\": 1,\n",
            "            \"maximum\": 100,\n",
            "            \"description\": \"Number of items per page\",\n",
            "            \"example\": 20\n",
            "          },\n",
            "          \"total\": {\n",
            "            \"type\": \"integer\",\n",
            "            \"minimum\": 0,\n",
            "            \"description\": \"Total number of TODO items across all pages\",\n",
            "            \"example\": 150\n",
            "          },\n",
            "          \"totalPages\": {\n",
            "            \"type\": \"integer\",\n",
            "            \"minimum\n"
          ]
        }
      ],
      "source": [
        "# Generate OpenAPI specification\n",
        "api_response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"Generate an OpenAPI 3.0 specification (in JSON) for a simple TODO API with:\n",
        "- GET /todos - List all todos (with pagination)\n",
        "- POST /todos - Create a todo\n",
        "- GET /todos/{id} - Get a specific todo\n",
        "- PUT /todos/{id} - Update a todo\n",
        "- DELETE /todos/{id} - Delete a todo\n",
        "\n",
        "Include proper schemas, error responses, and authentication (Bearer token).\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    response_format={\"type\": \"json_object\"},\n",
        "    temperature=0.2,\n",
        "    max_tokens=2500\n",
        ")\n",
        "\n",
        "print(\"üìù OpenAPI Specification:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    spec = json.loads(api_response.choices[0].message.content)\n",
        "    print(json.dumps(spec, indent=2))\n",
        "except:\n",
        "    print(api_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section8"
      },
      "source": [
        "---\n",
        "\n",
        "## üîÑ Section 8: Error Recovery & Debugging\n",
        "\n",
        "Testing Qwen3 Coder Next's ability to recover from failures - a key feature for agentic coding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "error_recovery",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6993c80-ec7e-49aa-a3a6-8f59264085b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Error Recovery Response:\n",
            "==================================================\n",
            "The error occurs because the JSON file contains invalid JSON syntax:\n",
            "\n",
            "1. Single quotes (`'version'`) instead of double quotes for keys\n",
            "2. A comment (`// this is the version`) which is not allowed in standard JSON\n",
            "\n",
            "Since standard JSON doesn't support comments or single quotes, we need to preprocess the file content to make it valid JSON before parsing. Here's a robust solution:\n",
            "\n",
            "```python\n",
            "import json\n",
            "import re\n",
            "\n",
            "def parse_json_file(filepath):\n",
            "    try:\n",
            "        with open(filepath, 'r') as f:\n",
            "            content = f.read()\n",
            "        \n",
            "        # Remove single-line comments (// ...)\n",
            "        content = re.sub(r'//.*$', '', content, flags=re.MULTILINE)\n",
            "        \n",
            "        # Remove multi-line comments (/* ... */)\n",
            "        content = re.sub(r'/\\*.*?\\*/', '', content, flags=re.DOTALL)\n",
            "        \n",
            "        # Convert single quotes to double quotes (but be careful with apostrophes in strings)\n",
            "        # This is a simple approach - for production code you might want more sophisticated handling\n",
            "        content = re.sub(r\"'([^']*)'\", r'\"\\1\"', content)\n",
            "        \n",
            "        # Parse the cleaned JSON\n",
            "        return json.loads(content)\n",
            "    \n",
            "    except FileNotFoundError:\n",
            "        raise FileNotFoundError(f\"File not found: {filepath}\")\n",
            "    except json.JSONDecodeError as e:\n",
            "        raise ValueError(f\"Invalid JSON in file {filepath}: {e}\")\n",
            "\n",
            "# Alternative: Use a more robust JSON parser like json5 if available\n",
            "# pip install json5\n",
            "# import json5\n",
            "# def parse_json_file(filepath):\n",
            "#     with open(filepath, 'r') as f:\n",
            "#         return json5.load(f)\n",
            "```\n",
            "\n",
            "**How this solution works:**\n",
            "\n",
            "1. **Read the file content** as text first\n",
            "2. **Remove single-line comments** using regex (`// ...`)\n",
            "3. **Remove multi-line comments** using regex (`/* ... */`)\n",
            "4. **Convert single quotes to double quotes** for keys and string values\n",
            "5. **Parse the cleaned content** using standard `json.loads()`\n",
            "\n",
            "**Important notes:**\n",
            "\n",
            "- This approach handles the specific issues in your file but might not handle all edge cases (like apostrophes inside string values)\n",
            "- For production code, consider using a more robust library like `json5` which supports comments and single quotes\n",
            "- The error message indicates the issue is at \"line 3 column 5\", which corresponds to the `'version'` key in your file\n",
            "\n",
            "**To use the json5 approach (recommended for production):**\n",
            "\n",
            "```bash\n",
            "pip install json5\n",
            "```\n",
            "\n",
            "```python\n",
            "import json5\n",
            "\n",
            "def parse_json_file(filepath):\n",
            "    with open(filepath, 'r') as f:\n",
            "        return json5.load(f)\n",
            "```\n",
            "\n",
            "The json5 library is specifically designed to handle JSON-like files with comments, single quotes, and other extensions that aren't valid in strict JSON.\n"
          ]
        }
      ],
      "source": [
        "# Simulating an agentic error recovery scenario\n",
        "recovery_response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a coding agent that helps debug and recover from errors.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Write a function to parse JSON from a file\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"\"\"```python\n",
        "def parse_json_file(filepath):\n",
        "    with open(filepath, 'r') as f:\n",
        "        return json.load(f)\n",
        "```\"\"\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"I ran the code and got this error:\n",
        "\n",
        "```\n",
        "Traceback (most recent call last):\n",
        "  File \"main.py\", line 5, in <module>\n",
        "    data = parse_json_file('config.json')\n",
        "  File \"main.py\", line 3, in parse_json_file\n",
        "    return json.load(f)\n",
        "  File \"/usr/lib/python3.9/json/__init__.py\", line 293, in load\n",
        "    return loads(fp.read(),\n",
        "json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 3 column 5 (char 45)\n",
        "```\n",
        "\n",
        "The file content is:\n",
        "```\n",
        "{\n",
        "  \"name\": \"test\",\n",
        "  'version': 1.0,  // this is the version\n",
        "  \"enabled\": true\n",
        "}\n",
        "```\n",
        "\n",
        "Fix the code to handle this malformed JSON.\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.3,\n",
        "    max_tokens=1500\n",
        ")\n",
        "\n",
        "print(\"üîß Error Recovery Response:\")\n",
        "print(\"=\"*50)\n",
        "print(recovery_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section9"
      },
      "source": [
        "---\n",
        "\n",
        "## üìè Section 9: Long Context Handling (256K)\n",
        "\n",
        "Testing Qwen3 Coder Next's ability to handle large codebases with its 256K context window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "long_context",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1028dc73-4bdf-4be6-f787-822d22f3b053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìè Long Context Analysis:\n",
            "==================================================\n",
            "Let's analyze the provided e-commerce backend code thoroughly, addressing your four requested tasks:\n",
            "\n",
            "---\n",
            "\n",
            "## üîç **1. Potential Bugs & Race Conditions**\n",
            "\n",
            "### ‚úÖ **Critical Race Conditions**\n",
            "| Location | Issue | Why It's Dangerous |\n",
            "|---------|-------|-------------------|\n",
            "| `CartService.add_item()` | **Non-atomic stock check + cart update** | Between `product.stock < quantity` check and actual purchase, another request could consume stock ‚Üí overselling. |\n",
            "| `OrderService.checkout()` | **Multiple non-atomic stock reservations** | `update_stock` is called in a loop. If one fails, earlier ones are *not rolled back* (see below). Also, between checking `product.stock < item.quantity` and calling `update_stock`, stock may change. |\n",
            "| `CartService.add_item()` | **In-memory `self.carts` is not thread/process-safe** | In production (e.g., multi-worker Gunicorn/Uvicorn), carts won‚Äôt be shared ‚Äî users may lose carts or get inconsistent data. |\n",
            "| `OrderService.checkout()` | **`product.price_at_addition` vs current price** | Uses `item.price_at_addition`, but stock validation uses *current* `product.stock`. If price changed since add, total may be inconsistent. More critically: **stock is validated against current stock, but price is locked at add-time** ‚Äî this is *intentional*, but risky if not documented. |\n",
            "| `OrderService.checkout()` | **No isolation between checkout attempts** | Two concurrent checkouts for same user could both succeed, creating duplicate orders. |\n",
            "\n",
            "### ‚ö†Ô∏è **Other Bugs**\n",
            "| Location | Issue |\n",
            "|---------|-------|\n",
            "| `CartService.add_item()` | No validation for `quantity <= 0`. |\n",
            "| `CartService.add_item()` | `product.name` used in error but `Product` may be `None` (though guarded above). |\n",
            "| `OrderService.checkout()` | `del self.cart_service.carts[user_id]` happens *after* stock deduction but *before* order persistence ‚Äî if order creation fails, cart is gone but stock is reserved ‚Üí user can‚Äôt reorder. |\n",
            "| `OrderService.checkout()` | `product_repo.update_stock()` returns `bool`, but no retry or idempotency. |\n",
            "| `ProductRepository.update_stock()` | Uses `$gte` in filter but doesn‚Äôt handle concurrent updates robustly (e.g., two requests both see `stock=5`, both try to reduce by 3 ‚Üí final stock = -1 if no atomicity). |\n",
            "| `CartService.add_item()` | No handling of `Decimal` precision loss (e.g., `price * quantity` may overflow or lose cents). |\n",
            "| `OrderService.checkout()` | `order.id` uses `datetime.now().timestamp()` ‚Äî **not unique under high concurrency** (same second ‚Üí collision). |\n",
            "\n",
            "---\n",
            "\n",
            "## üèóÔ∏è **2. Architectural Improvements**\n",
            "\n",
            "### ‚úÖ **Core Recommendations**\n",
            "| Area | Improvement | Rationale |\n",
            "|------|-------------|-----------|\n",
            "| **State Management** | Replace `self.carts = {}` with a **distributed cache** (e.g., Redis) | Ensures cart consistency across multiple app instances. |\n",
            "| **Database Layer** | Use **database-level transactions** for stock operations | MongoDB supports multi-document transactions (since v4.0); use them for atomic stock reservation. |\n",
            "| **Concurrency Control** | Implement **optimistic locking** or **pessimistic locking** for stock | E.g., add `version` field to `Product` and use `$inc` + `$version` condition. |\n",
            "| **Idempotency** | Add `idempotency_key` to checkout requests | Prevents duplicate orders from retries. |\n",
            "| **Error Handling** | Introduce **domain exceptions** (e.g., `StockUnavailableError`, `CartEmptyError`) | Better than generic `ValueError`. |\n",
            "| **Validation** | Move validation logic into **domain services**, not repositories | Repositories should only persist/fetch. |\n",
            "| **Order Creation** | Use **UUIDs** (e.g., `uuid.uuid4()`) for order IDs | Avoid timestamp collisions. |\n",
            "| **Decoupling** | Inject `CartRepository` instead of exposing `CartService.carts` | `OrderService` shouldn‚Äôt know about `CartService` internals. |\n",
            "\n",
            "### üîÑ **Refactored Flow Suggestion**\n",
            "```text\n",
            "1. Fetch cart from Redis (or DB)\n",
            "2. Validate cart items & prices (with current product data)\n",
            "3. Begin DB transaction\n",
            "4. For each item:\n",
            "   - Check stock atomically (e.g., `update_one` with `$inc` and `$gte`)\n",
            "   - If any fails ‚Üí abort transaction\n",
            "5. Create order\n",
            "6. Commit transaction\n",
            "7. Delete cart (or mark as \"checked out\")\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "## üßæ **3. Proper Transaction Handling in `checkout()`**\n",
            "\n",
            "Assuming MongoDB with **session-based transactions** (requires replica set or sharded cluster in production, but works in dev with `--replSet`):\n",
            "\n",
            "### ‚úÖ Updated `OrderService.checkout()` with Transactions\n",
            "\n",
            "```python\n",
            "from pymongo.errors import OperationFailure\n",
            "from bson.decimal128 import Decimal128\n",
            "\n",
            "class OrderService:\n",
            "    def __init__(self, cart_service: CartService, product_repo: ProductRepository, order_repo: OrderRepository):\n",
            "        self.cart_service = cart_service\n",
            "        self.product_repo = product_repo\n",
            "        self.order_repo = order_repo\n",
            "\n",
            "    def checkout(self, user_id: str, shipping_address: str) -> Order:\n",
            "        # Get cart from cart_service (now via method, not internal dict)\n",
            "        cart = self.cart_service.get_cart(user_id)\n",
            "        if not cart or not cart.items:\n",
            "            raise ValueError(\"Cart is empty\")\n",
            "\n",
            "        # Validate cart items exist and prices are valid\n",
            "        for item in cart.items:\n",
            "            product = self.product_repo.get_by_id(item.product_id)\n",
            "            if not product:\n",
            "                raise ValueError(f\"Product {item.product_id} no longer exists\")\n",
            "            if item.quantity <= 0:\n",
            "                raise ValueError(\"Item quantity must be positive\")\n",
            "\n",
            "        # Start transaction\n",
            "        with self.product_repo.db.client.start_session() as session:\n",
            "            try:\n",
            "                with session.start_transaction():\n",
            "                    # Step 1: Reserve stock atomically\n",
            "                    for item in cart.items:\n",
            "                        product = self.product_repo.get_by_id(item.product_id)\n",
            "                        if not product:\n",
            "                            raise ValueError(f\"Product {item.product_id} no longer exists\")\n",
            "\n",
            "                        # Atomic stock check & decrement\n",
            "                        result = self.product_repo.db.products.update_one(\n",
            "                            {\n",
            "                                \"id\": item.product_id,\n",
            "                                \"stock\": {\"$gte\": item.quantity}\n",
            "                            },\n",
            "                            {\"$inc\": {\"stock\": -item.quantity}},\n",
            "                            session=session\n",
            "                        )\n",
            "                        if result.modified_count != 1:\n",
            "                            raise StockUnavailableError(f\"Insufficient stock for {product.name}\")\n",
            "\n",
            "                    # Step 2: Calculate total using *current* prices (or lock prices at add-time if required)\n",
            "                    # Here we use current prices for accuracy (common practice)\n",
            "                    total = Decimal(0)\n",
            "                    for item in cart.items:\n",
            "                        product = self.product_repo.get_by_id(item.product_id, session=session)\n",
            "                        if not product:\n",
            "                            raise ValueError(f\"Product {item.product_id} no longer exists\")\n",
            "                        total += product.price * item.quantity\n",
            "\n",
            "                    # Step 3: Create order\n",
            "                    order = Order(\n",
            "                        id=str(uuid.uuid4()),  # Use UUID\n",
            "                        user_id=user_id,\n",
            "                        items=[CartItem(p.id, item.quantity, p.price) \n",
            "                               for item in cart.items \n",
            "                               for p in [self.product_repo.get_by_id(item.product_id, session=session)]],\n",
            "                        total=total,\n",
            "                        status=OrderStatus.PENDING,\n",
            "                        shipping_address=shipping_address,\n",
            "                        created_at=datetime.utcnow()\n",
            "                    )\n",
            "                    self.order_repo.create(order, session=session)\n",
            "\n",
            "                    # Step 4: Clear cart atomically (if using DB-backed cart)\n",
            "                    # For Redis: use pipeline + DEL\n",
            "                    self.cart_service.clear_cart(user_id)\n",
            "\n",
            "                    # Commit happens automatically on context exit if no exception\n",
            "                    return order\n",
            "\n",
            "            except Exception as e:\n",
            "                # Transaction auto-aborts on exception\n",
            "                raise e\n",
            "```\n",
            "\n",
            "### ‚úÖ Updated `ProductRepository.get_by_id()` & `create()` to support sessions\n",
            "```python\n",
            "def get_by_id(self, product_id: str, session=None) -> Optional[Product]:\n",
            "    return self.db.products.find_one({\"id\": product_id}, session=session)\n",
            "\n",
            "def create(self, order: Order, session=None):\n",
            "    self.db.orders.insert_one(order.__dict__, session=session)\n",
            "```\n",
            "\n",
            "### ‚úÖ Add Custom Exception\n",
            "```python\n",
            "class StockUnavailableError(Exception):\n",
            "    pass\n",
            "```\n",
            "\n",
            "> üí° **Note**: If using a relational DB (e.g., PostgreSQL), use `SELECT ... FOR UPDATE` or `UPDATE ... WHERE stock >= ? RETURNING *` inside `BEGIN; ... COMMIT;`.\n",
            "\n",
            "---\n",
            "\n",
            "## üß™ **4. Unit Tests for `CartService.add_item()`**\n",
            "\n",
            "We‚Äôll use `unittest.mock` and `pytest`. Since `CartService` uses in-memory `self.carts`, we can test directly ‚Äî but note: **in real code, this should be replaced with Redis/DB**.\n",
            "\n",
            "### ‚úÖ Test File: `test_cart_service.py`\n",
            "```python\n",
            "import pytest\n",
            "from unittest.mock import Mock, patch\n",
            "from decimal import Decimal\n",
            "from datetime import datetime\n",
            "\n",
            "# Assuming models & services imported\n",
            "# from your_module import CartService, Product, CartItem, Cart, ProductRepository, ValueError\n",
            "\n",
            "class TestCartService:\n",
            "    @pytest.fixture\n",
            "    def mock_product_repo(self):\n",
            "        return Mock(spec=ProductRepository)\n",
            "\n",
            "    @pytest.fixture\n",
            "    def cart_service(self, mock_product_repo):\n",
            "        return CartService(mock_product_repo)\n",
            "\n",
            "    def test_add_item_new_product(self, cart_service, mock_product_repo):\n",
            "        # Arrange\n",
            "        user_id = \"user123\"\n",
            "        product_id = \"prod1\"\n",
            "        quantity = 2\n",
            "        product = Product(id=product_id, name=\"Widget\", description=\"A widget\", \n",
            "                          price=Decimal(\"19.99\"), stock=10, category_id=\"cat1\")\n",
            "        mock_product_repo.get_by_id.return_value = product\n",
            "\n",
            "        # Act\n",
            "        cart = cart_service.add_item(user_id, product_id, quantity)\n",
            "\n",
            "        # Assert\n",
            "        assert cart.user_id == user_id\n",
            "        assert len(cart.items) == 1\n",
            "        assert cart.items[0].product_id == product_id\n",
            "        assert cart.items[0].quantity == quantity\n",
            "        assert cart.items[0].price_at_addition == product.price\n",
            "        assert cart_service.carts[user_id] is cart\n",
            "\n",
            "    def test_add_item_existing_product_increments_quantity(self, cart_service, mock_product_repo):\n",
            "        # Arrange\n",
            "        user_id = \"user123\"\n",
            "        product_id = \"prod1\"\n",
            "        product = Product(id=product_id, name=\"Widget\", description=\"A widget\", \n",
            "                          price=Decimal(\"19.99\"), stock=10, category_id=\"cat1\")\n",
            "        mock_product_repo.get_by_id.return_value = product\n",
            "\n",
            "        # Pre-populate cart\n",
            "        cart_service.carts[user_id] = Cart(\n",
            "            user_id=user_id,\n",
            "            items=[CartItem(product_id=product_id, quantity=1, price_at_addition=Decimal(\"19.99\"))],\n",
            "            created_at=datetime.now()\n",
            "        )\n",
            "\n",
            "        # Act\n",
            "        cart = cart_service.add_item(user_id, product_id, quantity=3)\n",
            "\n",
            "        # Assert\n",
            "        assert cart.items[0].quantity == 4  # 1 + 3\n",
            "\n",
            "    def test_add_item_insufficient_stock_raises(self, cart_service, mock_product_repo):\n",
            "        # Arrange\n",
            "        user_id = \"user123\"\n",
            "        product_id = \"prod1\"\n",
            "        product = Product(id=product_id, name=\"Widget\", description=\"A widget\", \n",
            "                          price=Decimal(\"19.99\"), stock=2, category_id=\"cat1\")\n",
            "        mock_product_repo.get_by_id.return_value = product\n",
            "\n",
            "        # Act & Assert\n",
            "        with pytest.raises(ValueError, match=\"Insufficient stock\"):\n",
            "            cart_service.add_item(user_id, product_id, quantity=5)\n",
            "\n",
            "    def test_add_item_product_not_found_raises(self, cart_service, mock_product_repo):\n",
            "        # Arrange\n",
            "        user_id = \"user123\"\n",
            "        product_id = \"prod999\"\n",
            "        mock_product_repo.get_by_id.return_value = None\n",
            "\n",
            "        # Act & Assert\n",
            "        with pytest.raises(ValueError, match=\"Product prod999 not found\"):\n",
            "            cart_service.add_item(user_id, product_id, quantity=1)\n",
            "\n",
            "    def test_add_item_zero_quantity_raises(self, cart_service, mock_product_repo):\n",
            "        # Arrange\n",
            "        user_id = \"user123\"\n",
            "        product_id = \"prod1\"\n",
            "        product = Product(id=product_id, name=\"Widget\", description=\"A widget\", \n",
            "                          price=Decimal(\"19.99\"), stock=10, category_id=\"cat1\")\n",
            "        mock_product_repo.get_by_id.return_value = product\n",
            "\n",
            "        # Act & Assert\n",
            "        with pytest.raises(ValueError, match=\"Item quantity must be positive\"):\n",
            "            cart_service.add_item(user_id, product_id, quantity=0)\n",
            "\n",
            "    def test_add_item_negative_quantity_raises(self, cart_service, mock_product_repo):\n",
            "        # Arrange\n",
            "        user_id = \"user123\"\n",
            "        product_id = \"prod1\"\n",
            "        product = Product(id=product_id, name=\"Widget\", description=\"A widget\", \n",
            "                          price=Decimal(\"19.99\"), stock=10, category_id=\"cat1\")\n",
            "        mock_product_repo.get_by_id.return_value = product\n",
            "\n",
            "        # Act & Assert\n",
            "        with pytest.raises(ValueError, match=\"Item quantity must be positive\"):\n",
            "            cart_service.add_item(user_id, product_id, quantity=-1)\n",
            "```\n",
            "\n",
            "### ‚úÖ Bonus: Add `get_cart()` & `clear_cart()` to `CartService`\n",
            "To support testability and decoupling:\n",
            "```python\n",
            "def get_cart(self, user_id: str) -> Optional[Cart]:\n",
            "    return self.carts.get(user_id)\n",
            "\n",
            "def clear_cart(self, user_id: str):\n",
            "    if user_id in self.carts:\n",
            "        del self.carts[user_id]\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "## üìå Summary of Key Fixes\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate a moderately long code sample to test context handling\n",
        "long_code = \"\"\"\n",
        "# This is a sample e-commerce backend system\n",
        "# Multiple modules simulating a real-world codebase\n",
        "\n",
        "# ==================== MODELS ====================\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional\n",
        "from datetime import datetime\n",
        "from decimal import Decimal\n",
        "from enum import Enum\n",
        "\n",
        "class OrderStatus(Enum):\n",
        "    PENDING = \"pending\"\n",
        "    CONFIRMED = \"confirmed\"\n",
        "    SHIPPED = \"shipped\"\n",
        "    DELIVERED = \"delivered\"\n",
        "    CANCELLED = \"cancelled\"\n",
        "\n",
        "@dataclass\n",
        "class Product:\n",
        "    id: str\n",
        "    name: str\n",
        "    description: str\n",
        "    price: Decimal\n",
        "    stock: int\n",
        "    category_id: str\n",
        "\n",
        "@dataclass\n",
        "class CartItem:\n",
        "    product_id: str\n",
        "    quantity: int\n",
        "    price_at_addition: Decimal\n",
        "\n",
        "@dataclass\n",
        "class Cart:\n",
        "    user_id: str\n",
        "    items: List[CartItem]\n",
        "    created_at: datetime\n",
        "\n",
        "@dataclass\n",
        "class Order:\n",
        "    id: str\n",
        "    user_id: str\n",
        "    items: List[CartItem]\n",
        "    total: Decimal\n",
        "    status: OrderStatus\n",
        "    shipping_address: str\n",
        "    created_at: datetime\n",
        "\n",
        "# ==================== REPOSITORIES ====================\n",
        "class ProductRepository:\n",
        "    def __init__(self, db):\n",
        "        self.db = db\n",
        "\n",
        "    def get_by_id(self, product_id: str) -> Optional[Product]:\n",
        "        return self.db.products.find_one({\"id\": product_id})\n",
        "\n",
        "    def update_stock(self, product_id: str, quantity: int) -> bool:\n",
        "        result = self.db.products.update_one(\n",
        "            {\"id\": product_id, \"stock\": {\"$gte\": quantity}},\n",
        "            {\"$inc\": {\"stock\": -quantity}}\n",
        "        )\n",
        "        return result.modified_count > 0\n",
        "\n",
        "class OrderRepository:\n",
        "    def __init__(self, db):\n",
        "        self.db = db\n",
        "\n",
        "    def create(self, order: Order) -> Order:\n",
        "        self.db.orders.insert_one(order.__dict__)\n",
        "        return order\n",
        "\n",
        "    def update_status(self, order_id: str, status: OrderStatus) -> bool:\n",
        "        result = self.db.orders.update_one(\n",
        "            {\"id\": order_id},\n",
        "            {\"$set\": {\"status\": status.value}}\n",
        "        )\n",
        "        return result.modified_count > 0\n",
        "\n",
        "# ==================== SERVICES ====================\n",
        "class CartService:\n",
        "    def __init__(self, product_repo: ProductRepository):\n",
        "        self.product_repo = product_repo\n",
        "        self.carts = {}  # In-memory for simplicity\n",
        "\n",
        "    def add_item(self, user_id: str, product_id: str, quantity: int) -> Cart:\n",
        "        product = self.product_repo.get_by_id(product_id)\n",
        "        if not product:\n",
        "            raise ValueError(f\"Product {product_id} not found\")\n",
        "\n",
        "        if product.stock < quantity:\n",
        "            raise ValueError(f\"Insufficient stock for {product.name}\")\n",
        "\n",
        "        cart = self.carts.get(user_id, Cart(user_id, [], datetime.now()))\n",
        "\n",
        "        # Check if item already exists\n",
        "        for item in cart.items:\n",
        "            if item.product_id == product_id:\n",
        "                item.quantity += quantity\n",
        "                return cart\n",
        "\n",
        "        cart.items.append(CartItem(product_id, quantity, product.price))\n",
        "        self.carts[user_id] = cart\n",
        "        return cart\n",
        "\n",
        "class OrderService:\n",
        "    def __init__(self, cart_service: CartService, product_repo: ProductRepository, order_repo: OrderRepository):\n",
        "        self.cart_service = cart_service\n",
        "        self.product_repo = product_repo\n",
        "        self.order_repo = order_repo\n",
        "\n",
        "    def checkout(self, user_id: str, shipping_address: str) -> Order:\n",
        "        cart = self.cart_service.carts.get(user_id)\n",
        "        if not cart or not cart.items:\n",
        "            raise ValueError(\"Cart is empty\")\n",
        "\n",
        "        # Validate stock and calculate total\n",
        "        total = Decimal(0)\n",
        "        for item in cart.items:\n",
        "            product = self.product_repo.get_by_id(item.product_id)\n",
        "            if product.stock < item.quantity:\n",
        "                raise ValueError(f\"Insufficient stock for {product.name}\")\n",
        "            total += item.price_at_addition * item.quantity\n",
        "\n",
        "        # Reserve stock\n",
        "        for item in cart.items:\n",
        "            success = self.product_repo.update_stock(item.product_id, item.quantity)\n",
        "            if not success:\n",
        "                # Rollback would be needed here\n",
        "                raise ValueError(\"Failed to reserve stock\")\n",
        "\n",
        "        # Create order\n",
        "        order = Order(\n",
        "            id=f\"ORD-{datetime.now().timestamp()}\",\n",
        "            user_id=user_id,\n",
        "            items=cart.items.copy(),\n",
        "            total=total,\n",
        "            status=OrderStatus.PENDING,\n",
        "            shipping_address=shipping_address,\n",
        "            created_at=datetime.now()\n",
        "        )\n",
        "\n",
        "        self.order_repo.create(order)\n",
        "        del self.cart_service.carts[user_id]\n",
        "\n",
        "        return order\n",
        "\"\"\"\n",
        "\n",
        "context_response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Analyze this e-commerce backend code and:\n",
        "\n",
        "1. Identify all potential bugs or race conditions\n",
        "2. Suggest architectural improvements\n",
        "3. Add proper transaction handling to the checkout method\n",
        "4. Write unit tests for the CartService.add_item method\n",
        "\n",
        "```python\n",
        "{long_code}\n",
        "```\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.3,\n",
        "    max_tokens=3000\n",
        ")\n",
        "\n",
        "print(\"üìè Long Context Analysis:\")\n",
        "print(\"=\"*50)\n",
        "print(context_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section10"
      },
      "source": [
        "---\n",
        "\n",
        "## üß™ Section 10: Test Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "test_generation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefd072f-22ff-4c6a-db1a-90bc072ab8da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Generated Tests:\n",
            "==================================================\n",
            "Here's a comprehensive suite of `pytest` tests for the `merge_sorted_arrays` function, covering normal cases, edge cases, and property-based tests using `hypothesis`. The tests verify correctness, performance expectations, and edge behavior.\n",
            "\n",
            "```python\n",
            "import pytest\n",
            "from hypothesis import given, strategies as st, settings, example\n",
            "from hypothesis.strategies import lists, integers, one_of\n",
            "\n",
            "\n",
            "# Import the function (adjust import path as needed)\n",
            "# from your_module import merge_sorted_arrays\n",
            "\n",
            "\n",
            "class TestMergeSortedArrays:\n",
            "    \"\"\"Test suite for merge_sorted_arrays function.\"\"\"\n",
            "\n",
            "    # ==========================\n",
            "    # Normal Cases\n",
            "    # ==========================\n",
            "    @pytest.mark.parametrize(\n",
            "        \"arr1, arr2, expected\",\n",
            "        [\n",
            "            # Basic merging\n",
            "            ([1], [2], [1, 2]),\n",
            "            ([2], [1], [1, 2]),\n",
            "            ([1, 3], [2, 4], [1, 2, 3, 4]),\n",
            "            ([1, 2], [3, 4], [1, 2, 3, 4]),\n",
            "            ([3, 4], [1, 2], [1, 2, 3, 4]),\n",
            "            ([1, 3, 5], [2, 4, 6], [1, 2, 3, 4, 5, 6]),\n",
            "            ([1, 3, 5, 7], [2, 4, 6], [1, 2, 3, 4, 5, 6, 7]),\n",
            "            # Overlapping ranges\n",
            "            ([1, 5, 10], [2, 6, 11], [1, 2, 5, 6, 10, 11]),\n",
            "        ],\n",
            "    )\n",
            "    def test_normal_cases(self, arr1, arr2, expected):\n",
            "        assert merge_sorted_arrays(arr1, arr2) == expected\n",
            "\n",
            "    # ==========================\n",
            "    # Edge Cases\n",
            "    # ==========================\n",
            "    @pytest.mark.parametrize(\n",
            "        \"arr1, arr2, expected\",\n",
            "        [\n",
            "            # Empty arrays\n",
            "            ([], [], []),\n",
            "            ([], [1, 2, 3], [1, 2, 3]),\n",
            "            ([1, 2, 3], [], [1, 2, 3]),\n",
            "            # Single element arrays\n",
            "            ([1], [], [1]),\n",
            "            ([], [2], [2]),\n",
            "            ([5], [5], [5, 5]),\n",
            "            # Identical arrays\n",
            "            ([1, 2, 3], [1, 2, 3], [1, 1, 2, 2, 3, 3]),\n",
            "            # All same elements\n",
            "            ([0, 0, 0], [0, 0], [0, 0, 0, 0, 0]),\n",
            "            # Negative numbers\n",
            "            ([-5, -3, -1], [-4, -2, 0], [-5, -4, -3, -2, -1, 0]),\n",
            "            # Mixed positive/negative\n",
            "            ([-2, 0, 3], [-1, 1, 4], [-2, -1, 0, 1, 3, 4]),\n",
            "            # Large difference in lengths\n",
            "            ([1, 2], [3, 4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7, 8]),\n",
            "            ([1, 2, 3, 4, 5, 6, 7, 8], [9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]),\n",
            "        ],\n",
            "    )\n",
            "    def test_edge_cases(self, arr1, arr2, expected):\n",
            "        assert merge_sorted_arrays(arr1, arr2) == expected\n",
            "\n",
            "    # ==========================\n",
            "    # Property-Based Tests (Hypothesis)\n",
            "    # ==========================\n",
            "    @given(\n",
            "        arr1=lists(integers(), max_size=50).map(sorted),\n",
            "        arr2=lists(integers(), max_size=50).map(sorted),\n",
            "    )\n",
            "    @settings(max_examples=200, deadline=None)\n",
            "    def test_merge_preserves_sortedness(self, arr1, arr2):\n",
            "        \"\"\"Result should be sorted.\"\"\"\n",
            "        result = merge_sorted_arrays(arr1, arr2)\n",
            "        assert result == sorted(result)\n",
            "\n",
            "    @given(\n",
            "        arr1=lists(integers(), max_size=50).map(sorted),\n",
            "        arr2=lists(integers(), max_size=50).map(sorted),\n",
            "    )\n",
            "    @settings(max_examples=200, deadline=None)\n",
            "    def test_merge_preserves_all_elements(self, arr1, arr2):\n",
            "        \"\"\"Result should contain all elements from both inputs (with multiplicity).\"\"\"\n",
            "        result = merge_sorted_arrays(arr1, arr2)\n",
            "        combined = arr1 + arr2\n",
            "        assert sorted(result) == sorted(combined)\n",
            "\n",
            "    @given(\n",
            "        arr1=lists(integers(), max_size=50).map(sorted),\n",
            "        arr2=lists(integers(), max_size=50).map(sorted),\n",
            "    )\n",
            "    @settings(max_examples=200, deadline=None)\n",
            "    def test_merge_length(self, arr1, arr2):\n",
            "        \"\"\"Result length should be sum of input lengths.\"\"\"\n",
            "        result = merge_sorted_arrays(arr1, arr2)\n",
            "        assert len(result) == len(arr1) + len(arr2)\n",
            "\n",
            "    @given(\n",
            "        arr1=lists(integers(), min_size=1, max_size=50).map(sorted),\n",
            "        arr2=lists(integers(), min_size=1, max_size=50).map(sorted),\n",
            "    )\n",
            "    @settings(max_examples=50, deadline=None)\n",
            "    def test_merge_min_max(self, arr1, arr2):\n",
            "        \"\"\"Min and max of result should match global min/max.\"\"\"\n",
            "        result = merge_sorted_arrays(arr1, arr2)\n",
            "        assert result[0] == min(arr1[0], arr2[0])\n",
            "        assert result[-1] == max(arr1[-1], arr2[-1])\n",
            "\n",
            "    @example(arr1=[1, 2, 3], arr2=[1, 2, 3])\n",
            "    @given(\n",
            "        arr1=lists(integers(), max_size=50).map(sorted),\n",
            "        arr2=lists(integers(), max_size=50).map(sorted),\n",
            "    )\n",
            "    @settings(max_examples=200, deadline=None)\n",
            "    def test_merge_stability(self, arr1, arr2):\n",
            "        \"\"\"Test that equal elements preserve relative order (stability).\"\"\"\n",
            "        # We'll tag elements to track origin and order\n",
            "        arr1_tagged = [(x, 'a', i) for i, x in enumerate(arr1)]\n",
            "        arr2_tagged = [(x, 'b', i) for i, x in enumerate(arr2)]\n",
            "        result = merge_sorted_arrays(arr1, arr2)\n",
            "        # Since we use <= for arr1[i] <= arr2[j], arr1 elements come first when equal\n",
            "        # Build expected order: for equal values, arr1 elements appear before arr2 ones\n",
            "        # and within same array, original order preserved\n",
            "        expected = sorted(arr1_tagged + arr2_tagged, key=lambda t: (t[0], t[1] == 'b', t[2]))\n",
            "        assert [x for x, _, _ in expected] == result\n",
            "\n",
            "    # ==========================\n",
            "    # Additional Parameterized Tests\n",
            "    # ==========================\n",
            "    @pytest.mark.parametrize(\n",
            "        \"arr1, arr2\",\n",
            "        [\n",
            "            # Test with very large numbers\n",
            "            ([10**9, 10**10], [10**8, 10**11]),\n",
            "            # Test with zero\n",
            "            ([0, 0, 0], [0]),\n",
            "            # Test with duplicates across arrays\n",
            "            ([1, 1, 2, 2], [1, 2, 3, 3]),\n",
            "        ],\n",
            "    )\n",
            "    def test_special_values(self, arr1, arr2):\n",
            "        result = merge_sorted_arrays(arr1, arr2)\n",
            "        assert result == sorted(arr1 + arr2)\n",
            "\n",
            "    @pytest.mark.parametrize(\n",
            "        \"arr1, arr2\",\n",
            "        [\n",
            "            # Test with negative zero (Python doesn't distinguish, but good to be safe)\n",
            "            ([0], [0]),\n",
            "            # Test with large negative numbers\n",
            "            ([-10**9, -10**10], [-10**8, -10**11]),\n",
            "        ],\n",
            "    )\n",
            "    def test_boundary_values(self, arr1, arr2):\n",
            "        result = merge_sorted_arrays(arr1, arr2)\n",
            "        assert result == sorted(arr1 + arr2)\n",
            "\n",
            "    # ==========================\n",
            "    # Type/Behavior Tests\n",
            "    # ==========================\n",
            "    def test_does_not_mutate_inputs(self):\n",
            "        arr1 = [1, 3, 5]\n",
            "        arr2 = [2, 4, 6]\n",
            "        arr1_copy = arr1.copy()\n",
            "        arr2_copy = arr2.copy()\n",
            "        result = merge_sorted_arrays(arr1, arr2)\n",
            "        assert arr1 == arr1_copy\n",
            "        assert arr2 == arr2_copy\n",
            "        assert result == [1, 2, 3, 4, 5, 6]\n",
            "\n",
            "    def test_returns\n"
          ]
        }
      ],
      "source": [
        "# Test generation capabilities\n",
        "function_to_test = \"\"\"\n",
        "def merge_sorted_arrays(arr1: list[int], arr2: list[int]) -> list[int]:\n",
        "    \\\"\\\"\\\"Merge two sorted arrays into one sorted array.\\\"\\\"\\\"\n",
        "    result = []\n",
        "    i = j = 0\n",
        "\n",
        "    while i < len(arr1) and j < len(arr2):\n",
        "        if arr1[i] <= arr2[j]:\n",
        "            result.append(arr1[i])\n",
        "            i += 1\n",
        "        else:\n",
        "            result.append(arr2[j])\n",
        "            j += 1\n",
        "\n",
        "    result.extend(arr1[i:])\n",
        "    result.extend(arr2[j:])\n",
        "\n",
        "    return result\n",
        "\"\"\"\n",
        "\n",
        "test_response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Generate comprehensive pytest tests for this function:\n",
        "\n",
        "```python\n",
        "{function_to_test}\n",
        "```\n",
        "\n",
        "Include:\n",
        "- Normal cases\n",
        "- Edge cases (empty arrays, single elements, duplicates)\n",
        "- Property-based tests with hypothesis\n",
        "- Parameterized tests\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.3,\n",
        "    max_tokens=2000\n",
        ")\n",
        "\n",
        "print(\"üß™ Generated Tests:\")\n",
        "print(\"=\"*50)\n",
        "print(test_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section11"
      },
      "source": [
        "---\n",
        "\n",
        "## üìà Section 11: Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "performance_test",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98c7455-4dff-4798-de54-1a4e2badee8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Performance Metrics:\n",
            "============================================================\n",
            "Task                      Time (s)     Tokens          Tok/s\n",
            "------------------------------------------------------------\n",
            "Simple Chat               8.08         500             61.9\n",
            "Code Generation           5.90         500             84.8\n",
            "Code Review               6.65         476             71.6\n",
            "Complex Reasoning         7.22         500             69.3\n",
            "\n",
            "‚úÖ Performance test complete!\n"
          ]
        }
      ],
      "source": [
        "# Performance testing across different task types\n",
        "import time\n",
        "\n",
        "tests = [\n",
        "    (\"Simple Chat\", \"What is a Python decorator?\"),\n",
        "    (\"Code Generation\", \"Write a binary search function in Python\"),\n",
        "    (\"Code Review\", \"Review this code: def add(a,b): return a+b\"),\n",
        "    (\"Complex Reasoning\", \"Explain the trade-offs between microservices and monolithic architecture\")\n",
        "]\n",
        "\n",
        "print(\"üìä Performance Metrics:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Task':<25} {'Time (s)':<12} {'Tokens':<15} {'Tok/s'}\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "for task_name, prompt in tests:\n",
        "    start_time = time.time()\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=500\n",
        "    )\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "    if response.usage:\n",
        "        total_tokens = response.usage.completion_tokens\n",
        "        tokens_per_sec = total_tokens / elapsed if elapsed > 0 else 0\n",
        "        print(f\"{task_name:<25} {elapsed:<12.2f} {total_tokens:<15} {tokens_per_sec:.1f}\")\n",
        "    else:\n",
        "        print(f\"{task_name:<25} {elapsed:<12.2f} {'N/A':<15} {'N/A'}\")\n",
        "\n",
        "print(\"\\n‚úÖ Performance test complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "---\n",
        "\n",
        "## üìã Summary\n",
        "\n",
        "### Qwen3 Coder Next Capabilities Tested:\n",
        "\n",
        "| Capability | Status | Notes |\n",
        "|-----------|--------|-------|\n",
        "| ‚úÖ Basic Chat | Tested | Fast responses |\n",
        "| ‚úÖ Agentic Coding | Tested | Strong debugging & refactoring |\n",
        "| ‚úÖ Tool Calling | Tested | Parallel tool calls supported |\n",
        "| ‚úÖ Code Generation | Tested | Production-quality code |\n",
        "| ‚úÖ Security Review | Tested | Identifies vulnerabilities |\n",
        "| ‚úÖ Streaming | Tested | Works well |\n",
        "| ‚úÖ JSON Mode | Tested | Structured outputs |\n",
        "| ‚úÖ Error Recovery | Tested | Good debugging abilities |\n",
        "| ‚úÖ Long Context | Tested | 256K context window |\n",
        "| ‚úÖ Test Generation | Tested | Comprehensive test suites |\n",
        "\n",
        "### Key Takeaways:\n",
        "\n",
        "1. **Efficient MoE Design**: 80B total params with only 3B active - great for cost-sensitive deployments\n",
        "2. **Agentic-First**: Built specifically for coding agents with tool use and error recovery\n",
        "3. **Production-Ready**: No thinking tokens, streamlined output for production systems\n",
        "4. **Versatile**: Handles everything from simple chat to complex multi-file refactoring\n",
        "\n",
        "---\n",
        "\n",
        "**Created by: @BuildFastWithAI**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}