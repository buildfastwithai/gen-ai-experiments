{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Gen AI Experiments](https://img.shields.io/badge/Gen%20AI%20Experiments-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://github.com/buildfastwithai/gen-ai-experiments)\n",
        "[![Gen AI Experiments GitHub](https://img.shields.io/github/stars/buildfastwithai/gen-ai-experiments?style=for-the-badge&logo=github&color=gold)](http://github.com/buildfastwithai/gen-ai-experiments)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1SnLSbiQxs5WBhkR5LwXm5F-Lsy3SEsid?usp=sharing)"
      ],
      "metadata": {
        "id": "header-cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Master Generative AI in 8 Weeks\n",
        "**What You'll Learn:**\n",
        "- Master cutting-edge AI tools & frameworks\n",
        "- 6 weeks of hands-on, project-based learning\n",
        "- Weekly live mentorship sessions\n",
        "- Join Innovation Community\n",
        "\n",
        "Learn by building. Get expert mentorship and work on real AI projects.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)"
      ],
      "metadata": {
        "id": "38b1uP8G0zOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸš€ Claude Sonnet 4.6 â€” Complete Testing Notebook\n",
        "\n",
        "**Anthropic's Most Capable Sonnet Model Yet**\n",
        "\n",
        "Claude Sonnet 4.6 is a full upgrade across coding, computer use, long-context reasoning, agent planning, knowledge work, and design. Developers with early access preferred Sonnet 4.6 over Sonnet 4.5 **~70% of the time**, and even preferred it to Opus 4.5 **59% of the time**.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Š Model Specifications\n",
        "\n",
        "| Feature | Specification |\n",
        "|---------|---------------|\n",
        "| **Model ID** | `anthropic/claude-sonnet-4.6` |\n",
        "| **Context Window** | 1M tokens (beta) |\n",
        "| **Max Output** | 128K tokens |\n",
        "| **Modalities** | Text, Vision/Images |\n",
        "| **Tool Calling** | âœ… Parallel & chained |\n",
        "| **Adaptive Thinking** | âœ… Reasoning control |\n",
        "| **Streaming** | âœ… Supported |\n",
        "| **JSON Mode** | âœ… Structured output |\n",
        "| **Input Pricing** | $3 / 1M tokens |\n",
        "| **Output Pricing** | $15 / 1M tokens |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”‘ Key Capabilities (from Anthropic)\n",
        "\n",
        "1. **Coding Excellence** â€” Preferred 70% over Sonnet 4.5 in Claude Code; reads context before modifying, consolidates shared logic\n",
        "2. **Computer Use** â€” Major improvements on OSWorld benchmark; human-level at spreadsheets & multi-step web forms\n",
        "3. **1M Token Context** â€” Hold entire codebases, contracts, or dozens of research papers in a single request\n",
        "4. **Agent Planning** â€” Long-horizon planning with strategic pivoting (top performer on Vending-Bench Arena)\n",
        "5. **Adaptive Thinking** â€” Adjusts reasoning depth; strong with or without extended thinking\n",
        "6. **Tool Use** â€” Parallel calls, web search, code execution, memory, and programmatic tool calling\n",
        "7. **Design & Frontend** â€” Polished layouts, animations, and design sensibility\n",
        "8. **Instruction Following** â€” Fewer hallucinations, fewer false success claims, better follow-through on multi-step tasks\n",
        "\n",
        "ğŸ“– *Source: [Anthropic â€” Introducing Claude Sonnet 4.6](https://www.anthropic.com/news/claude-sonnet-4-6)*"
      ],
      "metadata": {
        "id": "intro-cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ“¦ Setup & Installation"
      ],
      "metadata": {
        "id": "setup-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# @title Install Dependencies\n",
        "!pip install -q openai httpx"
      ],
      "outputs": [],
      "metadata": {
        "id": "install-cell"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# @title Configure API Client (OpenRouter)\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "# Setup OpenRouter client\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=userdata.get(\"OPENROUTER_API_KEY\")\n",
        ")\n",
        "\n",
        "MODEL = \"anthropic/claude-sonnet-4.6\"\n",
        "\n",
        "print(f\"âœ… Client configured for: {MODEL}\")\n",
        "print(f\"ğŸ”— Model page: https://openrouter.ai/anthropic/claude-sonnet-4.6\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "config-cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ§ª Example 1: Basic Chat & Self-Introduction\n",
        "\n",
        "Let's start by testing Sonnet 4.6's basic chat and see how it describes its own capabilities."
      ],
      "metadata": {
        "id": "example1-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# @title Basic Chat Completion\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are Claude Sonnet 4.6 by Anthropic, accessed via OpenRouter. Be helpful and concise.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What are your key strengths compared to previous Sonnet models? Be specific and concise.\"}\n",
        "    ],\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "print(\"ğŸ’¬ Claude Sonnet 4.6 Response:\")\n",
        "print(\"=\" * 50)\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¬ Claude Sonnet 4.6 Response:\n",
            "==================================================\n",
            "I'm Claude Sonnet 4.6, and compared to previous Sonnet models, my key improvements include:\n",
            "\n",
            "1. **Enhanced reasoning** â€“ Better at complex, multi-step problems and logical analysis\n",
            "2. **Improved instruction-following** â€“ More precise adherence to nuanced or detailed prompts\n",
            "3. **Better coding** â€“ More accurate code generation, debugging, and explanation\n",
            "4. **Stronger factual accuracy** â€“ Reduced hallucinations on knowledge-based tasks\n",
            "5. **More nuanced writing** â€“ Better tone calibration and stylistic control\n",
            "6. **Improved agentic performance** â€“ Better at tool use and multi-turn task completion\n",
            "\n",
            "**Honest caveat:** I don't have detailed internal benchmarks comparing myself to specific prior Sonnet versions, so I can't give you precise, quantified differences. For rigorous comparisons, Anthropic's release notes and third-party benchmarks (like MMLU, HumanEval, etc.) are more reliable sources.\n"
          ]
        }
      ],
      "metadata": {
        "id": "example1-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98e0eaa-e907-41e8-bf96-16025d45836d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ› ï¸ Example 2: Advanced Tool Calling (Parallel Execution)\n",
        "\n",
        "Sonnet 4.6 excels at tool use with parallel calls, web search, and programmatic tool calling. Let's test with multiple tools simultaneously."
      ],
      "metadata": {
        "id": "example2-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# @title Define Tools\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_weather\",\n",
        "            \"description\": \"Get the current weather for a location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\"type\": \"string\", \"description\": \"City name (e.g., 'Tokyo', 'New York')\"},\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"], \"description\": \"Temperature unit\"}\n",
        "                },\n",
        "                \"required\": [\"location\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"calculate\",\n",
        "            \"description\": \"Perform a mathematical calculation\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"expression\": {\"type\": \"string\", \"description\": \"Math expression to evaluate (e.g., '15 * 0.18')\"}\n",
        "                },\n",
        "                \"required\": [\"expression\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_stock_price\",\n",
        "            \"description\": \"Get the current stock price for a ticker symbol\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"ticker\": {\"type\": \"string\", \"description\": \"Stock ticker symbol (e.g., 'AAPL', 'GOOGL')\"}\n",
        "                },\n",
        "                \"required\": [\"ticker\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Simulate tool execution\n",
        "def execute_tool(name, args):\n",
        "    if name == \"get_weather\":\n",
        "        location = args.get('location', 'Unknown')\n",
        "        unit = args.get('unit', 'celsius')\n",
        "        temp = 24 if unit == 'celsius' else 75\n",
        "        return json.dumps({\"location\": location, \"temperature\": temp, \"unit\": unit, \"condition\": \"Partly Cloudy\", \"humidity\": 62})\n",
        "    elif name == \"calculate\":\n",
        "        try:\n",
        "            result = eval(args.get('expression', '0'))\n",
        "            return json.dumps({\"result\": result, \"expression\": args.get('expression')})\n",
        "        except Exception as e:\n",
        "            return json.dumps({\"error\": str(e)})\n",
        "    elif name == \"get_stock_price\":\n",
        "        prices = {\"AAPL\": 198.50, \"GOOGL\": 175.30, \"MSFT\": 425.80, \"AMZN\": 192.60}\n",
        "        ticker = args.get('ticker', 'AAPL').upper()\n",
        "        return json.dumps({\"ticker\": ticker, \"price\": prices.get(ticker, 150.00), \"currency\": \"USD\", \"change\": \"+1.2%\"})\n",
        "    return json.dumps({\"error\": \"Unknown tool\"})\n",
        "\n",
        "print(\"âœ… Tools defined: get_weather, calculate, get_stock_price\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Tools defined: get_weather, calculate, get_stock_price\n"
          ]
        }
      ],
      "metadata": {
        "id": "example2-tools",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcaa63ff-8944-4aea-94ae-cf4c34aa0e21"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# @title Parallel Tool Calling Demo\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"I need three things: 1) Weather in Tokyo, 2) Calculate 18% tip on $125.50, and 3) Current price of AAPL stock.\"}\n",
        "    ],\n",
        "    tools=tools,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "message = response.choices[0].message\n",
        "print(\"ğŸ“¤ Model Response:\")\n",
        "\n",
        "if message.tool_calls:\n",
        "    print(f\"\\nğŸ”§ Tool Calls Detected: {len(message.tool_calls)}\")\n",
        "    print(f\"{'â”€' * 50}\")\n",
        "\n",
        "    # Process each tool call\n",
        "    tool_messages = [{\"role\": \"assistant\", \"content\": message.content, \"tool_calls\": [{\"id\": tc.id, \"type\": \"function\", \"function\": {\"name\": tc.function.name, \"arguments\": tc.function.arguments}} for tc in message.tool_calls]}]\n",
        "\n",
        "    for tc in message.tool_calls:\n",
        "        args = json.loads(tc.function.arguments)\n",
        "        result = execute_tool(tc.function.name, args)\n",
        "        print(f\"   â¤ {tc.function.name}({json.dumps(args)})\")\n",
        "        print(f\"   ğŸ“‹ Result: {result}\")\n",
        "        print()\n",
        "        tool_messages.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": result})\n",
        "\n",
        "    # Get final response with tool results\n",
        "    final_response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": \"I need three things: 1) Weather in Tokyo, 2) Calculate 18% tip on $125.50, and 3) Current price of AAPL stock.\"},\n",
        "        ] + tool_messages,\n",
        "        tools=tools,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    print(f\"{'â”€' * 50}\")\n",
        "    print(\"\\nâœ… Final Answer:\")\n",
        "    print(final_response.choices[0].message.content)\n",
        "else:\n",
        "    print(message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¤ Model Response:\n",
            "\n",
            "ğŸ”§ Tool Calls Detected: 3\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "   â¤ get_weather({\"location\": \"Tokyo\"})\n",
            "   ğŸ“‹ Result: {\"location\": \"Tokyo\", \"temperature\": 24, \"unit\": \"celsius\", \"condition\": \"Partly Cloudy\", \"humidity\": 62}\n",
            "\n",
            "   â¤ calculate({\"expression\": \"125.50 * 0.18\"})\n",
            "   ğŸ“‹ Result: {\"result\": 22.59, \"expression\": \"125.50 * 0.18\"}\n",
            "\n",
            "   â¤ get_stock_price({\"ticker\": \"AAPL\"})\n",
            "   ğŸ“‹ Result: {\"ticker\": \"AAPL\", \"price\": 198.5, \"currency\": \"USD\", \"change\": \"+1.2%\"}\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "âœ… Final Answer:\n",
            "Here are all three results:\n",
            "\n",
            "1. ğŸŒ¤ï¸ **Weather in Tokyo**\n",
            "   - Temperature: **24Â°C**\n",
            "   - Condition: **Partly Cloudy**\n",
            "   - Humidity: **62%**\n",
            "\n",
            "2. ğŸ§¾ **18% Tip on $125.50**\n",
            "   - Tip Amount: **$22.59**\n",
            "   - Total (with tip): **$148.09**\n",
            "\n",
            "3. ğŸ“ˆ **AAPL Stock Price**\n",
            "   - Current Price: **$198.50 USD**\n",
            "   - Change: **+1.2%** â–²\n",
            "\n",
            "Let me know if you need anything else!\n"
          ]
        }
      ],
      "metadata": {
        "id": "example2-demo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3f3653-7e92-498c-cede-a58ee5f8d5d9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ’» Example 3: Code Generation & Debugging\n",
        "\n",
        "Sonnet 4.6 brings much-improved coding skills â€” it reads context before modifying code, consolidates shared logic, and is less prone to overengineering. Users rated it significantly better at instruction following with fewer hallucinations."
      ],
      "metadata": {
        "id": "example3-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# @title Advanced Code Generation\n",
        "coding_prompt = \"\"\"\n",
        "Create a Python `AsyncRateLimiter` class with the following requirements:\n",
        "\n",
        "1. Token bucket algorithm with configurable rate and burst size\n",
        "2. Async/await compatible (use asyncio)\n",
        "3. Decorator pattern for easy function wrapping\n",
        "4. Usage tracking with stats (total requests, throttled count, avg wait time)\n",
        "5. Graceful shutdown support\n",
        "6. Type hints and docstrings throughout\n",
        "\n",
        "Include a demo showing it in action with 3 simulated API calls.\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert Python developer. Write clean, production-quality code. Include complete, runnable implementations.\"},\n",
        "        {\"role\": \"user\", \"content\": coding_prompt}\n",
        "    ],\n",
        "    max_tokens=4096\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [],
      "metadata": {
        "id": "example3-code"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# @title Code Debugging & Refactoring\n",
        "debug_prompt = \"\"\"\n",
        "Here's a buggy Python function. Find ALL bugs, explain each one, and provide the fixed version:\n",
        "\n",
        "```python\n",
        "def merge_sorted_lists(list1, list2):\n",
        "    result = []\n",
        "    i = j = 0\n",
        "\n",
        "    while i <= len(list1) and j <= len(list2):\n",
        "        if list1[i] < list2[j]:\n",
        "            result.append(list1[i])\n",
        "            i += 1\n",
        "        else:\n",
        "            result.append(list2[j])\n",
        "            j += 1\n",
        "\n",
        "    result += list1[i:]\n",
        "    result += list2[j:]\n",
        "    return result\n",
        "\n",
        "def find_duplicates(lst):\n",
        "    seen = {}\n",
        "    duplicates = []\n",
        "    for item in lst:\n",
        "        if item in seen:\n",
        "            duplicates.append(item)\n",
        "        seen[item] = True\n",
        "    return list(duplicates)\n",
        "```\n",
        "\n",
        "Also suggest performance improvements and add edge case handling.\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert code reviewer. Be thorough â€” identify ALL bugs, explain them clearly, and provide clean fixes.\"},\n",
        "        {\"role\": \"user\", \"content\": debug_prompt}\n",
        "    ],\n",
        "    max_tokens=3000\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [],
      "metadata": {
        "id": "example3-debug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ“Š Example 4: Structured JSON Output\n",
        "\n",
        "Sonnet 4.6 provides reliable structured output for data extraction, API responses, and pipeline integrations."
      ],
      "metadata": {
        "id": "example4-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# @title JSON Mode â€” Data Extraction\n",
        "import json\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"\"\"You are a data extraction specialist. Always respond with valid JSON matching this exact schema:\n",
        "{\n",
        "  \"company\": {\"name\": string, \"industry\": string, \"founded\": number, \"hq\": string},\n",
        "  \"products\": [{\"name\": string, \"category\": string, \"description\": string}],\n",
        "  \"key_metrics\": {\"employees\": string, \"valuation\": string, \"funding\": string},\n",
        "  \"competitors\": [string],\n",
        "  \"notable_achievements\": [string]\n",
        "}\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": \"Extract structured information about Anthropic, the AI safety company that created Claude.\"}\n",
        "    ],\n",
        "    max_tokens=1024,\n",
        "    response_format={\"type\": \"json_object\"}\n",
        ")\n",
        "\n",
        "content = response.choices[0].message.content\n",
        "\n",
        "try:\n",
        "    result = json.loads(content)\n",
        "    print(\"ğŸ“‹ Extracted Data:\")\n",
        "    print(json.dumps(result, indent=2))\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"âŒ JSONDecodeError: {e}\")\n",
        "    print(\"Raw content received from model:\")\n",
        "    print(\"-\" * 20)\n",
        "    print(content if content else \"[Empty Response]\")\n",
        "    print(\"-\" * 20)"
      ],
      "outputs": [],
      "metadata": {
        "id": "example4-code"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# @title Complex Schema â€” Multi-Entity Extraction\n",
        "text = \"\"\"\n",
        "In Q4 2025, OpenAI launched GPT-5.2 with multimodal reasoning. Google followed with Gemini 3 Pro,\n",
        "which set new records on MMLU-Pro and GPQA benchmarks. Anthropic's Claude Opus 4.5 introduced\n",
        "adaptive thinking and a 1M token context window. Meta released Llama 4.1, an open-weight model\n",
        "that matched GPT-4-level performance. Meanwhile, Mistral launched their Pixtral Large model with\n",
        "improved vision capabilities.\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"\"\"Extract all AI models mentioned. Return JSON array:\n",
        "[{\"model\": string, \"company\": string, \"key_features\": [string], \"release_period\": string}]\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Extract model information from this text:\\n{text}\"}\n",
        "    ],\n",
        "    max_tokens=1024,\n",
        "    response_format={\"type\": \"json_object\"}\n",
        ")\n",
        "\n",
        "content = response.choices[0].message.content\n",
        "\n",
        "try:\n",
        "    # Strip markdown code blocks if present\n",
        "    clean_content = content.strip()\n",
        "    if clean_content.startswith(\"```\"):\n",
        "        # Find the end of the first line (e.g., ```json)\n",
        "        first_newline = clean_content.find('\\n')\n",
        "        if first_newline != -1:\n",
        "            clean_content = clean_content[first_newline:].strip()\n",
        "    if clean_content.endswith(\"```\"):\n",
        "        clean_content = clean_content[:-3].strip()\n",
        "\n",
        "    models = json.loads(clean_content)\n",
        "    print(\"ğŸ¤– Extracted AI Models:\")\n",
        "    print(json.dumps(models, indent=2))\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"âŒ JSONDecodeError: {e}\")\n",
        "    print(\"Raw content received from model:\")\n",
        "    print(\"-\" * 20)\n",
        "    print(content)\n",
        "    print(\"-\" * 20)"
      ],
      "outputs": [],
      "metadata": {
        "id": "example4-multi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸŒŠ Example 5: Streaming Responses\n",
        "\n",
        "Stream long-form content generation for real-time output."
      ],
      "metadata": {
        "id": "example5-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# @title Streaming with Token Counting\n",
        "import time\n",
        "\n",
        "stream = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Explain the key differences between Claude Sonnet 4.6 and GPT-5 from an AI architecture perspective. Be concise (3 paragraphs).\"}\n",
        "    ],\n",
        "    max_tokens=1024,\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "full_response = \"\"\n",
        "token_count = 0\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"ğŸ“¡ Streaming response:\\n\")\n",
        "print(\"â”€\" * 50)\n",
        "\n",
        "for chunk in stream:\n",
        "    if chunk.choices[0].delta.content:\n",
        "        content = chunk.choices[0].delta.content\n",
        "        full_response += content\n",
        "        token_count += 1\n",
        "        print(content, end=\"\", flush=True)\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"\\n{'â”€' * 50}\")\n",
        "print(f\"\\nâœ… Stream complete!\")\n",
        "print(f\"â±ï¸ Time: {elapsed:.2f}s | ğŸ“Š Chunks: {token_count} | âš¡ Speed: {token_count/elapsed:.1f} chunks/s\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "example5-code"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ”„ Example 6: Multi-Turn Conversation with Memory\n",
        "\n",
        "Test Sonnet 4.6's ability to maintain context across multiple turns â€” a key capability for agentic workflows."
      ],
      "metadata": {
        "id": "example6-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# @title Multi-Turn Conversation\n",
        "conversation = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful AI tutor specializing in machine learning. Keep responses concise and educational. Remember all context from the conversation.\"}\n",
        "]\n",
        "\n",
        "questions = [\n",
        "    \"What is a transformer architecture? Explain in 2-3 sentences.\",\n",
        "    \"How does self-attention work in transformers? Use the concept you just explained.\",\n",
        "    \"Now explain how this relates to modern LLMs like yourself. Connect it to your earlier explanations.\"\n",
        "]\n",
        "\n",
        "for i, question in enumerate(questions, 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ğŸ‘¤ Turn {i}: {question}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    conversation.append({\"role\": \"user\", \"content\": question})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=conversation,\n",
        "        max_tokens=512\n",
        "    )\n",
        "\n",
        "    reply = response.choices[0].message.content\n",
        "    conversation.append({\"role\": \"assistant\", \"content\": reply})\n",
        "\n",
        "    print(f\"\\nğŸ¤– Claude: {reply}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"âœ… Conversation complete! Total turns: {len(questions)}\")\n",
        "print(f\"ğŸ“ Total messages in context: {len(conversation)}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "example6-code"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ§  Example 7: Complex Reasoning & Long-Context Analysis\n",
        "\n",
        "Sonnet 4.6 approaches Opus-level intelligence for complex reasoning. It excels at multi-source analysis across legal, financial, and technical content â€” all within its 1M token context window."
      ],
      "metadata": {
        "id": "example7-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# @title Complex Multi-Step Reasoning\n",
        "reasoning_prompt = \"\"\"\n",
        "You are a senior data scientist. Analyze this scenario and provide a complete, structured recommendation:\n",
        "\n",
        "## Scenario\n",
        "An e-commerce company has the following data:\n",
        "- Monthly active users: 2.4M\n",
        "- Conversion rate: 2.1% (industry avg: 3.2%)\n",
        "- Average order value: $67\n",
        "- Cart abandonment rate: 78%\n",
        "- Mobile traffic: 65% (but mobile conversion: only 1.1%)\n",
        "- Email open rate: 18%, click rate: 2.3%\n",
        "- Customer return rate: 22% within 60 days\n",
        "- Top traffic sources: Organic (35%), Paid (28%), Social (22%), Direct (15%)\n",
        "\n",
        "## Task\n",
        "1. Identify the TOP 3 problems from this data\n",
        "2. For each problem, propose a data-driven solution with expected impact\n",
        "3. Prioritize solutions by ROI (calculate estimated revenue impact)\n",
        "4. Propose an A/B testing plan for the highest-priority solution\n",
        "5. Identify what additional data you would need to refine these recommendations\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a senior data scientist and growth strategist. Be quantitative and specific with your analysis.\"},\n",
        "        {\"role\": \"user\", \"content\": reasoning_prompt}\n",
        "    ],\n",
        "    max_tokens=4096\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [],
      "metadata": {
        "id": "example7-code"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ¤– Example 8: Agentic Workflow â€” Research & Report Agent\n",
        "\n",
        "Sonnet 4.6 excels at agentic workflows with independent operation, sub-task identification, and self-correction. Let's build a mini research agent that plans, gathers data, and synthesizes a report."
      ],
      "metadata": {
        "id": "example8-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# @title Agentic Research Workflow\n",
        "import json\n",
        "\n",
        "# Define agent tools\n",
        "agent_tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"search_web\",\n",
        "            \"description\": \"Search the web for information on a topic\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"query\": {\"type\": \"string\", \"description\": \"Search query\"}\n",
        "                },\n",
        "                \"required\": [\"query\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"analyze_data\",\n",
        "            \"description\": \"Analyze data and extract key insights\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"data\": {\"type\": \"string\", \"description\": \"Data to analyze\"},\n",
        "                    \"analysis_type\": {\"type\": \"string\", \"enum\": [\"summary\", \"trends\", \"comparison\", \"forecast\"]}\n",
        "                },\n",
        "                \"required\": [\"data\", \"analysis_type\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"write_report\",\n",
        "            \"description\": \"Write a structured report section\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"title\": {\"type\": \"string\", \"description\": \"Section title\"},\n",
        "                    \"content\": {\"type\": \"string\", \"description\": \"Section content\"},\n",
        "                    \"section_type\": {\"type\": \"string\", \"enum\": [\"introduction\", \"findings\", \"analysis\", \"conclusion\"]}\n",
        "                },\n",
        "                \"required\": [\"title\", \"content\", \"section_type\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Simulate tool responses\n",
        "def execute_agent_tool(name, args):\n",
        "    if name == \"search_web\":\n",
        "        query = args.get('query', '')\n",
        "        return json.dumps({\n",
        "            \"results\": [\n",
        "                {\"title\": f\"Recent developments in {query}\", \"snippet\": f\"Latest research shows significant advances in {query} with new breakthroughs in efficiency and performance.\"},\n",
        "                {\"title\": f\"{query} market analysis 2026\", \"snippet\": f\"The {query} market is projected to grow 35% YoY, driven by enterprise adoption and new use cases.\"},\n",
        "                {\"title\": f\"Expert opinions on {query}\", \"snippet\": f\"Industry experts believe {query} will transform how businesses operate within the next 2-3 years.\"}\n",
        "            ]\n",
        "        })\n",
        "    elif name == \"analyze_data\":\n",
        "        return json.dumps({\"insights\": [\"Strong growth trajectory\", \"Increasing enterprise adoption\", \"Cost efficiency improvements\"], \"confidence\": 0.87})\n",
        "    elif name == \"write_report\":\n",
        "        return json.dumps({\"status\": \"success\", \"section\": args.get('section_type'), \"word_count\": len(args.get('content', '').split())})\n",
        "    return json.dumps({\"error\": \"Unknown tool\"})\n",
        "\n",
        "# Run the agent\n",
        "agent_messages = [\n",
        "    {\"role\": \"system\", \"content\": \"\"\"You are a research agent. Your task is to research a topic using available tools and produce a comprehensive report.\n",
        "Follow this workflow:\n",
        "1. PLAN: Outline your research approach\n",
        "2. GATHER: Use search_web to find information\n",
        "3. ANALYZE: Use analyze_data to extract insights\n",
        "4. REPORT: Use write_report to compile findings\n",
        "\n",
        "Think step by step and use tools strategically.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"Research the current state of AI agents in 2026 and create a brief report on the key trends.\"}\n",
        "]\n",
        "\n",
        "print(\"ğŸ¤– Agent Starting Research...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Agent loop (max 3 iterations)\n",
        "for step in range(3):\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=agent_messages,\n",
        "        tools=agent_tools,\n",
        "        max_tokens=2048\n",
        "    )\n",
        "\n",
        "    message = response.choices[0].message\n",
        "\n",
        "    if message.content:\n",
        "        print(f\"\\nğŸ’­ Agent Thinking (Step {step+1}):\\n{message.content[:300]}...\" if len(message.content or '') > 300 else f\"\\nğŸ’­ Agent (Step {step+1}):\\n{message.content}\")\n",
        "\n",
        "    if not message.tool_calls:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"âœ… Agent completed! Final response:\")\n",
        "        print(message.content)\n",
        "        break\n",
        "\n",
        "    # Process tool calls\n",
        "    agent_messages.append({\"role\": \"assistant\", \"content\": message.content, \"tool_calls\": [{\"id\": tc.id, \"type\": \"function\", \"function\": {\"name\": tc.function.name, \"arguments\": tc.function.arguments}} for tc in message.tool_calls]})\n",
        "\n",
        "    for tc in message.tool_calls:\n",
        "        args = json.loads(tc.function.arguments)\n",
        "        result = execute_agent_tool(tc.function.name, args)\n",
        "        print(f\"   ğŸ”§ Tool: {tc.function.name}({json.dumps(args)[:80]}...)\")\n",
        "        agent_messages.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": result})\n",
        "\n",
        "print(f\"\\nğŸ“Š Total agent steps: {step + 1}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "example8-code"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ“ˆ Token Usage & Cost Tracking"
      ],
      "metadata": {
        "id": "summary-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "# @title Check Token Usage (Last Response)\n",
        "if hasattr(response, 'usage') and response.usage:\n",
        "    usage = response.usage\n",
        "    input_cost = (usage.prompt_tokens / 1_000_000) * 3.0\n",
        "    output_cost = (usage.completion_tokens / 1_000_000) * 15.0\n",
        "    total_cost = input_cost + output_cost\n",
        "\n",
        "    print(\"ğŸ“Š Token Usage (Last Request):\")\n",
        "    print(f\"   â€¢ Prompt tokens:     {usage.prompt_tokens:,}\")\n",
        "    print(f\"   â€¢ Completion tokens: {usage.completion_tokens:,}\")\n",
        "    print(f\"   â€¢ Total tokens:      {usage.total_tokens:,}\")\n",
        "    print(f\"\\nğŸ’° Estimated Cost:\")\n",
        "    print(f\"   â€¢ Input:  ${input_cost:.6f}\")\n",
        "    print(f\"   â€¢ Output: ${output_cost:.6f}\")\n",
        "    print(f\"   â€¢ Total:  ${total_cost:.6f}\")\n",
        "    print(f\"\\nğŸ’¡ Claude Sonnet 4.6 Pricing (via OpenRouter):\")\n",
        "    print(f\"   â€¢ Input: $3 / 1M tokens\")\n",
        "    print(f\"   â€¢ Output: $15 / 1M tokens\")\n",
        "else:\n",
        "    print(\"Token usage not available in response\")\n",
        "    print(\"\\nğŸ’¡ Claude Sonnet 4.6 Pricing (via OpenRouter):\")\n",
        "    print(\"   â€¢ Input: $3 / 1M tokens\")\n",
        "    print(\"   â€¢ Output: $15 / 1M tokens\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Token Usage (Last Request):\n",
            "   â€¢ Prompt tokens:     2,488\n",
            "   â€¢ Completion tokens: 1,163\n",
            "   â€¢ Total tokens:      3,651\n",
            "\n",
            "ğŸ’° Estimated Cost:\n",
            "   â€¢ Input:  $0.007464\n",
            "   â€¢ Output: $0.017445\n",
            "   â€¢ Total:  $0.024909\n",
            "\n",
            "ğŸ’¡ Claude Sonnet 4.6 Pricing (via OpenRouter):\n",
            "   â€¢ Input: $3 / 1M tokens\n",
            "   â€¢ Output: $15 / 1M tokens\n"
          ]
        }
      ],
      "metadata": {
        "id": "summary-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ebfd6f-2a8a-4b21-af03-8c84f87ef550"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ğŸ¯ Key Takeaways\n",
        "\n",
        "**Claude Sonnet 4.6 excels at:**\n",
        "- âœ… **Coding** â€” 70% preferred over Sonnet 4.5; less overengineering, better context awareness\n",
        "- âœ… **Tool Calling** â€” Parallel execution, complex multi-tool workflows\n",
        "- âœ… **Instruction Following** â€” Fewer hallucinations, better follow-through\n",
        "- âœ… **Long Context** â€” 1M token window with effective reasoning across all of it\n",
        "- âœ… **Agent Planning** â€” Long-horizon strategy with self-correction\n",
        "- âœ… **Structured Output** â€” Reliable JSON mode for data pipelines\n",
        "- âœ… **Computer Use** â€” Major OSWorld benchmark improvements\n",
        "- âœ… **Design** â€” Polished frontend code, layouts, and animations\n",
        "\n",
        "**Best for:**\n",
        "- ğŸ’» Software development & code review\n",
        "- ğŸ¤– Building agentic AI workflows\n",
        "- ğŸ“Š Data analysis & reporting\n",
        "- ğŸ¢ Enterprise knowledge work\n",
        "- ğŸ¨ Frontend design & prototyping\n",
        "\n",
        "**Pricing advantage:**\n",
        "- Opus-level performance at Sonnet pricing ($3/$15 per M tokens)\n",
        "\n",
        "ğŸ“– *Learn more: [Anthropic Blog](https://www.anthropic.com/news/claude-sonnet-4-6) | [OpenRouter](https://openrouter.ai/anthropic/claude-sonnet-4.6)*\n",
        "\n",
        "---\n",
        "*Notebook by [@BuildFastWithAI](https://www.buildfastwithai.com)*"
      ],
      "metadata": {
        "id": "takeaways-cell"
      }
    }
  ]
}