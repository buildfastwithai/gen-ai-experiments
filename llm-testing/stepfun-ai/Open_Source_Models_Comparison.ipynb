{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Gen AI Experiments](https://img.shields.io/badge/Gen%20AI%20Experiments-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://github.com/buildfastwithai/gen-ai-experiments)\n",
        "[![Gen AI Experiments GitHub](https://img.shields.io/github/stars/buildfastwithai/gen-ai-experiments?style=for-the-badge&logo=github&color=gold)](http://github.com/buildfastwithai/gen-ai-experiments)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](hhttps://colab.research.google.com/drive/1V8GA2zIs88WprTiUoUdVfSg5BW6uawRO?usp=sharing)\n",
        "\n",
        "## Master Generative AI in 8 Weeks\n",
        "**What You'll Learn:**\n",
        "- Master cutting-edge AI tools & frameworks\n",
        "- 6 weeks of hands-on, project-based learning\n",
        "- Weekly live mentorship sessions\n",
        "- No coding experience required\n",
        "- Join Innovation Community\n",
        "\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "overview"
      },
      "source": [
        "# üèÜ Open Source Models Battle: Step 3.5 Flash vs DeepSeek vs GLM\n",
        "\n",
        "Compare the **latest open-source LLMs** head-to-head across multiple tasks.\n",
        "\n",
        "## Models Compared\n",
        "\n",
        "| Model | Provider | Parameters | Context | Key Strength |\n",
        "|-------|----------|------------|---------|-------------|\n",
        "| **Step 3.5 Flash** | StepFun | 196B (MoE) | 256K | Speed + Coding |\n",
        "| **DeepSeek V3** | DeepSeek | 671B (MoE) | 128K | Reasoning |\n",
        "| **GLM-4.7 Flash** | Zhipu AI | 130B+ | 128K | Multilingual |\n",
        "| **Min Max M2** | Alibaba | 72B | 128K | Balanced |\n",
        "\n",
        "## Test Categories\n",
        "\n",
        "| Test | What We Measure |\n",
        "|------|----------------|\n",
        "| **Coding** | Python, debugging, algorithms |\n",
        "| **Reasoning** | Logic, math, puzzles |\n",
        "| **Creative** | Writing, stories, marketing |\n",
        "| **Knowledge** | Facts, explanations |\n",
        "| **Speed** | Response time |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section1"
      },
      "source": [
        "## üì¶ Section 1: Setup & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q openai pandas tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "setup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb63290-4df0-4c17-93ee-77960f1d2187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Setup complete!\n",
            "\n",
            "üìä Models to compare:\n",
            "  ‚Ä¢ Step 3.5 Flash: stepfun/step-3.5-flash:free\n",
            "  ‚Ä¢ DeepSeek V3.2: deepseek/deepseek-v3.2\n",
            "  ‚Ä¢ GLM-4.7: z-ai/glm-4.7\n",
            "  ‚Ä¢ Min Max M2: minimax/minimax-m2\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import time\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "# OpenRouter client (access to all models)\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=userdata.get(\"OPENROUTER_API_KEY\")\n",
        ")\n",
        "\n",
        "# Models to compare (low-cost on OpenRouter)\n",
        "MODELS = {\n",
        "    \"Step 3.5 Flash\": \"stepfun/step-3.5-flash:free\",\n",
        "    \"DeepSeek V3.2\": \"deepseek/deepseek-v3.2\",\n",
        "    \"GLM-4.7\": \"z-ai/glm-4.7\",\n",
        "    \"Min Max M2\": \"minimax/minimax-m2\"\n",
        "}\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n",
        "print(f\"\\nüìä Models to compare:\")\n",
        "for name, model_id in MODELS.items():\n",
        "    print(f\"  ‚Ä¢ {name}: {model_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "helper",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fbe864c-5604-4252-e6bb-5ea78adf5195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Helper functions ready!\n"
          ]
        }
      ],
      "source": [
        "def query_model(model_id: str, prompt: str, max_tokens: int = 500) -> dict:\n",
        "    \"\"\"Query a model and return response with timing.\"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_id,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        content = response.choices[0].message.content\n",
        "        tokens = response.usage.completion_tokens if response.usage else len(content.split())\n",
        "\n",
        "        return {\n",
        "            \"response\": content,\n",
        "            \"time\": elapsed,\n",
        "            \"tokens\": tokens,\n",
        "            \"tokens_per_sec\": tokens / elapsed if elapsed > 0 else 0,\n",
        "            \"error\": None\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"response\": None,\n",
        "            \"time\": time.time() - start_time,\n",
        "            \"tokens\": 0,\n",
        "            \"tokens_per_sec\": 0,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "\n",
        "def compare_models(prompt: str, test_name: str, max_tokens: int = 500):\n",
        "    \"\"\"Compare all models on the same prompt.\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üß™ TEST: {test_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"üìù Prompt: {prompt[:100]}...\\n\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for name, model_id in MODELS.items():\n",
        "        print(f\"‚è≥ Testing {name}...\")\n",
        "        result = query_model(model_id, prompt, max_tokens)\n",
        "        result[\"model\"] = name\n",
        "        results.append(result)\n",
        "\n",
        "        if result[\"error\"]:\n",
        "            print(f\"  ‚ùå Error: {result['error'][:50]}\")\n",
        "        else:\n",
        "            print(f\"  ‚úÖ {result['time']:.2f}s | {result['tokens_per_sec']:.1f} tok/s\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def display_results(results: list):\n",
        "    \"\"\"Display results in a formatted table.\"\"\"\n",
        "    df = pd.DataFrame(results)\n",
        "    df = df[[\"model\", \"time\", \"tokens\", \"tokens_per_sec\", \"error\"]]\n",
        "    df.columns = [\"Model\", \"Time (s)\", \"Tokens\", \"Tok/s\", \"Error\"]\n",
        "    df[\"Time (s)\"] = df[\"Time (s)\"].round(2)\n",
        "    df[\"Tok/s\"] = df[\"Tok/s\"].round(1)\n",
        "    print(\"\\nüìä Performance Summary:\")\n",
        "    print(tabulate(df, headers=\"keys\", tablefmt=\"grid\", showindex=False))\n",
        "    return df\n",
        "\n",
        "print(\"‚úÖ Helper functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section2"
      },
      "source": [
        "---\n",
        "\n",
        "## üíª Section 2: Coding Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coding_test"
      },
      "outputs": [],
      "source": [
        "# Test 1: Python Code Generation\n",
        "coding_prompt = \"\"\"Write a Python function that implements a binary search tree with:\n",
        "1. Insert method\n",
        "2. Search method\n",
        "3. In-order traversal\n",
        "\n",
        "Include type hints and docstrings.\"\"\"\n",
        "\n",
        "coding_results = compare_models(coding_prompt, \"Python Code Generation\", max_tokens=800)\n",
        "display_results(coding_results)\n",
        "\n",
        "# Show best response\n",
        "best = min([r for r in coding_results if not r[\"error\"]], key=lambda x: x[\"time\"])\n",
        "print(f\"\\nüèÜ Fastest: {best['model']} ({best['time']:.2f}s)\")\n",
        "print(f\"\\nüìù Response from {best['model']}:\")\n",
        "print(best[\"response\"][:1500] + \"...\" if len(best[\"response\"]) > 1500 else best[\"response\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "debug_test"
      },
      "outputs": [],
      "source": [
        "# Test 2: Debugging\n",
        "debug_prompt = \"\"\"Debug this Python code. Find all bugs and fix them:\n",
        "\n",
        "def quicksort(arr):\n",
        "    if len(arr) < 1:\n",
        "        return arr\n",
        "    pivot = arr[0]\n",
        "    left = [x for x in arr if x < pivot]\n",
        "    right = [x for x in arr if x > pivot]\n",
        "    return quicksort(left) + pivot + quicksort(right)\n",
        "\n",
        "print(quicksort([3, 1, 4, 1, 5, 9, 2, 6]))\n",
        "\n",
        "Explain each bug and provide the corrected code.\"\"\"\n",
        "\n",
        "debug_results = compare_models(debug_prompt, \"Debugging\", max_tokens=600)\n",
        "display_results(debug_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section3"
      },
      "source": [
        "---\n",
        "\n",
        "## üß† Section 3: Reasoning Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "math_test"
      },
      "outputs": [],
      "source": [
        "# Test 3: Math Reasoning\n",
        "math_prompt = \"\"\"Solve this step by step:\n",
        "\n",
        "A train travels from City A to City B at 60 km/h and returns at 40 km/h.\n",
        "The total journey takes 5 hours.\n",
        "\n",
        "What is the distance between the two cities?\n",
        "\n",
        "Show your complete reasoning.\"\"\"\n",
        "\n",
        "math_results = compare_models(math_prompt, \"Math Reasoning\", max_tokens=500)\n",
        "display_results(math_results)\n",
        "\n",
        "# Show all responses for comparison\n",
        "print(\"\\nüìä All Responses:\")\n",
        "for r in math_results:\n",
        "    if not r[\"error\"]:\n",
        "        print(f\"\\n--- {r['model']} ---\")\n",
        "        print(r[\"response\"][:500] + \"...\" if len(r[\"response\"]) > 500 else r[\"response\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "logic_test"
      },
      "outputs": [],
      "source": [
        "# Test 4: Logic Puzzle\n",
        "logic_prompt = \"\"\"Solve this logic puzzle:\n",
        "\n",
        "Five friends - Alice, Bob, Carol, David, and Eve - sit in a row.\n",
        "- Alice is not at either end.\n",
        "- Bob is immediately to the left of Carol.\n",
        "- David is at one of the ends.\n",
        "- Eve is not next to Alice.\n",
        "\n",
        "In what position is each friend sitting (from left to right)?\n",
        "\n",
        "Show your reasoning step by step.\"\"\"\n",
        "\n",
        "logic_results = compare_models(logic_prompt, \"Logic Puzzle\", max_tokens=600)\n",
        "display_results(logic_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section4"
      },
      "source": [
        "---\n",
        "\n",
        "## ‚úçÔ∏è Section 4: Creative Writing Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "creative_test"
      },
      "outputs": [],
      "source": [
        "# Test 5: Creative Writing\n",
        "creative_prompt = \"\"\"Write a compelling 100-word story about an AI that discovers it has emotions.\n",
        "\n",
        "Requirements:\n",
        "- Strong opening hook\n",
        "- Clear narrative arc\n",
        "- Emotional impact\n",
        "- Surprising ending\"\"\"\n",
        "\n",
        "creative_results = compare_models(creative_prompt, \"Creative Writing\", max_tokens=300)\n",
        "display_results(creative_results)\n",
        "\n",
        "# Show all stories\n",
        "print(\"\\nüìñ Stories:\")\n",
        "for r in creative_results:\n",
        "    if not r[\"error\"]:\n",
        "        print(f\"\\n--- {r['model']} ---\")\n",
        "        print(r[\"response\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "marketing_test"
      },
      "outputs": [],
      "source": [
        "# Test 6: Marketing Copy\n",
        "marketing_prompt = \"\"\"Write a viral tweet (under 280 chars) announcing a new AI-powered app that:\n",
        "- Generates quizzes from any URL\n",
        "- Uses FREE open-source models\n",
        "- Takes 5 seconds\n",
        "\n",
        "Make it engaging with emojis and a hook.\"\"\"\n",
        "\n",
        "marketing_results = compare_models(marketing_prompt, \"Marketing Copy\", max_tokens=150)\n",
        "display_results(marketing_results)\n",
        "\n",
        "# Show all tweets\n",
        "print(\"\\nüê¶ Tweets:\")\n",
        "for r in marketing_results:\n",
        "    if not r[\"error\"]:\n",
        "        print(f\"\\n{r['model']}:\")\n",
        "        print(f\"  {r['response'][:280]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section5"
      },
      "source": [
        "---\n",
        "\n",
        "## üìö Section 5: Knowledge Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "knowledge_test",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "df21cad3-9890-4d49-bbde-f499896e63e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üß™ TEST: Technical Explanation\n",
            "============================================================\n",
            "üìù Prompt: Explain Retrieval-Augmented Generation (RAG) in simple terms.\n",
            "\n",
            "Include:\n",
            "1. What it is (1 sentence)\n",
            "2...\n",
            "\n",
            "‚è≥ Testing Step 3.5 Flash...\n",
            "  ‚úÖ 2.09s | 191.0 tok/s\n",
            "‚è≥ Testing DeepSeek V3.2...\n",
            "  ‚úÖ 8.97s | 24.2 tok/s\n",
            "‚è≥ Testing GLM-4.7...\n",
            "  ‚úÖ 12.77s | 31.3 tok/s\n",
            "‚è≥ Testing Min Max M2...\n",
            "  ‚úÖ 2.68s | 149.3 tok/s\n",
            "\n",
            "üìä Performance Summary:\n",
            "+----------------+------------+----------+---------+---------+\n",
            "| Model          |   Time (s) |   Tokens |   Tok/s | Error   |\n",
            "+================+============+==========+=========+=========+\n",
            "| Step 3.5 Flash |       2.09 |      400 |   191   |         |\n",
            "+----------------+------------+----------+---------+---------+\n",
            "| DeepSeek V3.2  |       8.97 |      217 |    24.2 |         |\n",
            "+----------------+------------+----------+---------+---------+\n",
            "| GLM-4.7        |      12.77 |      400 |    31.3 |         |\n",
            "+----------------+------------+----------+---------+---------+\n",
            "| Min Max M2     |       2.68 |      400 |   149.3 |         |\n",
            "+----------------+------------+----------+---------+---------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Model  Time (s)  Tokens  Tok/s Error\n",
              "0  Step 3.5 Flash      2.09     400  191.0  None\n",
              "1   DeepSeek V3.2      8.97     217   24.2  None\n",
              "2         GLM-4.7     12.77     400   31.3  None\n",
              "3      Min Max M2      2.68     400  149.3  None"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9fe5590-9383-4002-a5bc-45f5701adc7a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Tok/s</th>\n",
              "      <th>Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Step 3.5 Flash</td>\n",
              "      <td>2.09</td>\n",
              "      <td>400</td>\n",
              "      <td>191.0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DeepSeek V3.2</td>\n",
              "      <td>8.97</td>\n",
              "      <td>217</td>\n",
              "      <td>24.2</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GLM-4.7</td>\n",
              "      <td>12.77</td>\n",
              "      <td>400</td>\n",
              "      <td>31.3</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Min Max M2</td>\n",
              "      <td>2.68</td>\n",
              "      <td>400</td>\n",
              "      <td>149.3</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9fe5590-9383-4002-a5bc-45f5701adc7a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e9fe5590-9383-4002-a5bc-45f5701adc7a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e9fe5590-9383-4002-a5bc-45f5701adc7a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Test 7: Technical Explanation\n",
        "knowledge_prompt = \"\"\"Explain Retrieval-Augmented Generation (RAG) in simple terms.\n",
        "\n",
        "Include:\n",
        "1. What it is (1 sentence)\n",
        "2. How it works (3 steps)\n",
        "3. Why it's useful (2 benefits)\n",
        "4. A real-world example\n",
        "\n",
        "Keep it under 200 words.\"\"\"\n",
        "\n",
        "knowledge_results = compare_models(knowledge_prompt, \"Technical Explanation\", max_tokens=400)\n",
        "display_results(knowledge_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section6"
      },
      "source": [
        "---\n",
        "\n",
        "## üåç Section 6: Multilingual Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "multilingual_test",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d5de6c1-f860-40a5-eadf-edd277165872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üß™ TEST: Multilingual Translation\n",
            "============================================================\n",
            "üìù Prompt: Translate this English text to:\n",
            "1. Chinese (Simplified)\n",
            "2. Spanish\n",
            "3. Hindi\n",
            "\n",
            "Text: \"Artificial intel...\n",
            "\n",
            "‚è≥ Testing Step 3.5 Flash...\n",
            "  ‚úÖ 1.53s | 138.1 tok/s\n",
            "‚è≥ Testing DeepSeek V3.2...\n",
            "  ‚úÖ 2.46s | 26.5 tok/s\n",
            "‚è≥ Testing GLM-4.7...\n",
            "  ‚úÖ 13.80s | 21.7 tok/s\n",
            "‚è≥ Testing Min Max M2...\n",
            "  ‚úÖ 4.25s | 70.5 tok/s\n",
            "\n",
            "üìä Performance Summary:\n",
            "+----------------+------------+----------+---------+---------+\n",
            "| Model          |   Time (s) |   Tokens |   Tok/s | Error   |\n",
            "+================+============+==========+=========+=========+\n",
            "| Step 3.5 Flash |       1.53 |      211 |   138.1 |         |\n",
            "+----------------+------------+----------+---------+---------+\n",
            "| DeepSeek V3.2  |       2.46 |       65 |    26.5 |         |\n",
            "+----------------+------------+----------+---------+---------+\n",
            "| GLM-4.7        |      13.8  |      300 |    21.7 |         |\n",
            "+----------------+------------+----------+---------+---------+\n",
            "| Min Max M2     |       4.25 |      300 |    70.5 |         |\n",
            "+----------------+------------+----------+---------+---------+\n",
            "\n",
            "üåç Translations:\n",
            "\n",
            "--- Step 3.5 Flash ---\n",
            "Chinese: ‰∫∫Â∑•Êô∫ËÉΩÊ≠£Âú®ÊîπÂèòÊàë‰ª¨ÁöÑÂ∑•‰ΩúÂíåÁîüÊ¥ªÊñπÂºè„ÄÇ\n",
            "Spanish: La inteligencia artificial est√° transformando la forma en que trabajamos y vivimos.\n",
            "Hindi: ‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§®‡•á ‡§î‡§∞ ‡§ú‡•Ä‡§®‡•á ‡§ï‡•á ‡§§‡§∞‡•Ä‡§ï‡•á ‡§ï‡•ã ‡§¨‡§¶‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\n",
            "\n",
            "--- DeepSeek V3.2 ---\n",
            "Chinese: ‰∫∫Â∑•Êô∫ËÉΩÊ≠£Âú®ÊîπÂèòÊàë‰ª¨ÁöÑÂ∑•‰ΩúÂíåÁîüÊ¥ªÊñπÂºè„ÄÇ  \n",
            "Spanish: La inteligencia artificial est√° transformando c√≥mo trabajamos y vivimos.  \n",
            "Hindi: ‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§®‡•á ‡§î‡§∞ ‡§ú‡•Ä‡§®‡•á ‡§ï‡•á ‡§§‡§∞‡•Ä‡§ï‡•á ‡§ï‡•ã ‡§¨‡§¶‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\n",
            "\n",
            "--- GLM-4.7 ---\n",
            "\n",
            "\n",
            "--- Min Max M2 ---\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test 8: Multilingual\n",
        "multilingual_prompt = \"\"\"Translate this English text to:\n",
        "1. Chinese (Simplified)\n",
        "2. Spanish\n",
        "3. Hindi\n",
        "\n",
        "Text: \"Artificial intelligence is transforming how we work and live.\"\n",
        "\n",
        "Format as:\n",
        "Chinese: [translation]\n",
        "Spanish: [translation]\n",
        "Hindi: [translation]\"\"\"\n",
        "\n",
        "multilingual_results = compare_models(multilingual_prompt, \"Multilingual Translation\", max_tokens=300)\n",
        "display_results(multilingual_results)\n",
        "\n",
        "# Show translations\n",
        "print(\"\\nüåç Translations:\")\n",
        "for r in multilingual_results:\n",
        "    if not r[\"error\"]:\n",
        "        print(f\"\\n--- {r['model']} ---\")\n",
        "        print(r[\"response\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section7"
      },
      "source": [
        "---\n",
        "\n",
        "## üìä Section 7: Final Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "final_comparison",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a706d1-519a-41cf-e681-30e735546df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üèÜ FINAL RANKINGS\n",
            "============================================================\n",
            "+----------------+----------------+-------------+----------------+\n",
            "| Model          |   Avg Time (s) |   Avg Tok/s | Success Rate   |\n",
            "+================+================+=============+================+\n",
            "| Step 3.5 Flash |           2.02 |       210.2 | 100%           |\n",
            "+----------------+----------------+-------------+----------------+\n",
            "| Min Max M2     |           5.18 |        94.6 | 100%           |\n",
            "+----------------+----------------+-------------+----------------+\n",
            "| GLM-4.7        |          19.46 |        38.6 | 100%           |\n",
            "+----------------+----------------+-------------+----------------+\n",
            "| DeepSeek V3.2  |          23.45 |        19.9 | 100%           |\n",
            "+----------------+----------------+-------------+----------------+\n"
          ]
        }
      ],
      "source": [
        "# Aggregate all results\n",
        "all_tests = [\n",
        "    (\"Coding\", coding_results),\n",
        "    (\"Debugging\", debug_results),\n",
        "    (\"Math\", math_results),\n",
        "    (\"Logic\", logic_results),\n",
        "    (\"Creative\", creative_results),\n",
        "    (\"Marketing\", marketing_results),\n",
        "    (\"Knowledge\", knowledge_results),\n",
        "    (\"Multilingual\", multilingual_results)\n",
        "]\n",
        "\n",
        "# Calculate average metrics per model\n",
        "model_stats = {name: {\"times\": [], \"tok_rates\": [], \"errors\": 0} for name in MODELS.keys()}\n",
        "\n",
        "for test_name, results in all_tests:\n",
        "    for r in results:\n",
        "        if r[\"error\"]:\n",
        "            model_stats[r[\"model\"]][\"errors\"] += 1\n",
        "        else:\n",
        "            model_stats[r[\"model\"]][\"times\"].append(r[\"time\"])\n",
        "            model_stats[r[\"model\"]][\"tok_rates\"].append(r[\"tokens_per_sec\"])\n",
        "\n",
        "# Create summary table\n",
        "summary_data = []\n",
        "for name, stats in model_stats.items():\n",
        "    avg_time = sum(stats[\"times\"]) / len(stats[\"times\"]) if stats[\"times\"] else 0\n",
        "    avg_rate = sum(stats[\"tok_rates\"]) / len(stats[\"tok_rates\"]) if stats[\"tok_rates\"] else 0\n",
        "    success_rate = (len(all_tests) - stats[\"errors\"]) / len(all_tests) * 100\n",
        "\n",
        "    summary_data.append({\n",
        "        \"Model\": name,\n",
        "        \"Avg Time (s)\": round(avg_time, 2),\n",
        "        \"Avg Tok/s\": round(avg_rate, 1),\n",
        "        \"Success Rate\": f\"{success_rate:.0f}%\"\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "summary_df = summary_df.sort_values(\"Avg Time (s)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üèÜ FINAL RANKINGS\")\n",
        "print(\"=\"*60)\n",
        "print(tabulate(summary_df, headers=\"keys\", tablefmt=\"grid\", showindex=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "winner",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a470cd-b4f5-45e4-c811-fc04161ca00e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üèÜ WINNERS BY CATEGORY:\n",
            "\n",
            "‚ö° Fastest Overall: Step 3.5 Flash\n",
            "üöÄ Highest Throughput: Step 3.5 Flash\n",
            "‚úÖ Most Reliable: Step 3.5 Flash\n",
            "\n",
            "============================================================\n",
            "üìã RECOMMENDATION:\n",
            "============================================================\n",
            "\n",
            "| Use Case | Recommended Model |\n",
            "|----------|------------------|\n",
            "| Speed-critical apps | Step 3.5 Flash |\n",
            "| Complex reasoning | DeepSeek R1 |\n",
            "| Coding tasks | Step 3.5 Flash / DeepSeek V3 |\n",
            "| Multilingual | GLM-4 / Qwen 2.5 |\n",
            "| General purpose | DeepSeek V3 |\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Declare winners by category\n",
        "print(\"\\nüèÜ WINNERS BY CATEGORY:\\n\")\n",
        "\n",
        "categories = {\n",
        "    \"‚ö° Fastest Overall\": min(summary_data, key=lambda x: x[\"Avg Time (s)\"]),\n",
        "    \"üöÄ Highest Throughput\": max(summary_data, key=lambda x: x[\"Avg Tok/s\"]),\n",
        "    \"‚úÖ Most Reliable\": max(summary_data, key=lambda x: float(x[\"Success Rate\"].replace('%', '')))\n",
        "}\n",
        "\n",
        "for category, winner in categories.items():\n",
        "    print(f\"{category}: {winner['Model']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìã RECOMMENDATION:\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "| Use Case | Recommended Model |\n",
        "|----------|------------------|\n",
        "| Speed-critical apps | Step 3.5 Flash |\n",
        "| Complex reasoning | DeepSeek R1 |\n",
        "| Coding tasks | Step 3.5 Flash / DeepSeek V3 |\n",
        "| Multilingual | GLM-4 / Qwen 2.5 |\n",
        "| General purpose | DeepSeek V3 |\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "---\n",
        "\n",
        "## üìö Summary\n",
        "\n",
        "### Models Tested\n",
        "\n",
        "| Model | Strengths | Best For |\n",
        "|-------|-----------|----------|\n",
        "| **Step 3.5 Flash** | Speed, coding | Real-time apps |\n",
        "| **DeepSeek V3** | Balanced | General use |\n",
        "| **DeepSeek R1** | Deep reasoning | Math, logic |\n",
        "| **GLM-4** | Multilingual | Global apps |\n",
        "| **Qwen 2.5** | Consistent | Production |\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Step 3.5 Flash** - Best for speed-critical applications\n",
        "2. **DeepSeek R1** - Best for complex reasoning tasks\n",
        "3. **All models are FREE** via OpenRouter\n",
        "4. **Performance varies by task** - choose based on your use case\n",
        "\n",
        "### Quick Access (OpenRouter)\n",
        "\n",
        "```python\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=\"your-key\"\n",
        ")\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "*Built with ‚ù§Ô∏è by @BuildFastWithAI*"
      ]
    }
  ]
}