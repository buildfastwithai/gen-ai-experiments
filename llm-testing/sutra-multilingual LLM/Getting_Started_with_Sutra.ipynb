{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHPrA32lncLv"
      },
      "source": [
        "##Get Started with SUTRA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GO4guros2wM"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1YULYifEf4HnUQGqTkph_nvJ1wiF9LXFc?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa35PCRexyQW"
      },
      "source": [
        "<img src=\"https://avatars.githubusercontent.com/u/87552521?s=200&v=4\" width=\"150\">\n",
        "\n",
        "SUTRA is a family of large multi-lingual language (LMLMs) models pioneered by Two Platforms. SUTRA‚Äôs dual-transformer approach extends the power of both MoE and Dense AI language model architectures, delivering cost-efficient multilingual capabilities for over 50+ languages. It powers scalable AI applications for conversation, search, and advanced reasoning, ensuring high-performance across diverse languages, domains and applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0g78hWpWaef"
      },
      "source": [
        "## Sutra using OpenAI SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpj_9ESOq-u7"
      },
      "source": [
        "###Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9cKviacDqNa",
        "outputId": "3bf4afeb-ac0a-4e51-eef0-a9aa9a27ff53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/606.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m604.2/606.1 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m606.1/606.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP1n8Ho8q5FP"
      },
      "source": [
        "###Example Using OpenAI SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4jX3otJFKUV",
        "outputId": "0949b7e0-5ac7-4ce1-cccd-fce1ff99158e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am SUTRA, an intelligent multilingual AI model designed to assist with a variety of tasks and provide information across different topics. How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(base_url='https://api.two.ai/v2',\n",
        "                api_key=userdata.get(\"SUTRA_API_KEY\"))\n",
        "\n",
        "response = client.chat.completions.create(model='sutra-v2',\n",
        "                                        messages = [{\"role\": \"user\", \"content\": \"Who are you?\"}],\n",
        "                                        max_tokens=1024,\n",
        "                                        temperature=0)\n",
        "\n",
        "\n",
        "responce = response.choices[0].message.content\n",
        "print(responce)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUoVff7joQmc"
      },
      "source": [
        "###Example Using Diffrent Languages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeO1Mgg9uxUe"
      },
      "source": [
        "####Telugu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-GjPtamIOnA",
        "outputId": "677d3080-d4ef-4108-cfb9-d21e060f561b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‡∞í‡∞ï ‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡∞Ç‡∞≤‡±ã ‡∞í‡∞ï ‡∞ö‡∞ø‡∞®‡±ç‡∞® ‡∞™‡∞ø‡∞≤‡±ç‡∞≤‡∞µ‡∞æ‡∞°‡±Å ‡∞â‡∞Ç‡∞°‡±á‡∞µ‡∞æ‡∞°‡±Å. ‡∞Ö‡∞§‡∞®‡∞ø ‡∞™‡±á‡∞∞‡±Å ‡∞∞‡∞æ‡∞Æ‡±Å. ‡∞∞‡∞æ‡∞Æ‡±Å ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞ö‡±Å‡∞∞‡±Å‡∞ï‡±à‡∞®, ‡∞§‡±Ü‡∞≤‡∞ø‡∞µ‡±à‡∞® ‡∞™‡∞ø‡∞≤‡±ç‡∞≤‡∞µ‡∞æ‡∞°‡±Å. ‡∞ï‡∞æ‡∞®‡±Ä, ‡∞Ö‡∞§‡∞®‡∞ø‡∞ï‡∞ø ‡∞í‡∞ï ‡∞™‡±Ü‡∞¶‡±ç‡∞¶ ‡∞ï‡∞≤ ‡∞â‡∞Ç‡∞¶‡∞ø - ‡∞Ü‡∞ï‡∞æ‡∞∂‡∞Ç‡∞≤‡±ã ‡∞é‡∞ó‡∞ø‡∞∞‡±á ‡∞™‡∞ï‡±ç‡∞∑‡±Å‡∞≤‡±ç‡∞≤‡∞æ ‡∞é‡∞ó‡∞∞‡∞°‡∞Ç.\n",
            "\n",
            "‡∞í‡∞ï ‡∞∞‡±ã‡∞ú‡±Å, ‡∞∞‡∞æ‡∞Æ‡±Å ‡∞§‡∞® ‡∞∏‡±ç‡∞®‡±á‡∞π‡∞ø‡∞§‡±Å‡∞≤‡∞§‡±ã ‡∞ï‡∞≤‡∞ø‡∞∏‡∞ø ‡∞Ö‡∞°‡∞µ‡∞ø‡∞≤‡±ã‡∞ï‡∞ø ‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞æ‡∞°‡±Å. ‡∞Ö‡∞ï‡±ç‡∞ï‡∞°, ‡∞Ö‡∞§‡∞®‡±Å ‡∞í‡∞ï ‡∞™‡∞æ‡∞§ ‡∞Æ‡∞æ‡∞Ç‡∞§‡±ç‡∞∞‡∞ø‡∞ï‡±Å‡∞°‡∞ø‡∞®‡∞ø ‡∞ö‡±Ç‡∞∏‡∞æ‡∞°‡±Å. ‡∞Æ‡∞æ‡∞Ç‡∞§‡±ç‡∞∞‡∞ø‡∞ï‡±Å‡∞°‡±Å ‡∞∞‡∞æ‡∞Æ‡±Å‡∞ï‡±Å ‡∞¶‡∞ó‡±ç‡∞ó‡∞∞‡∞ó‡∞æ ‡∞µ‡∞ö‡±ç‡∞ö‡∞ø, \"‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å ‡∞é‡∞ó‡∞∞‡∞æ‡∞≤‡∞Ç‡∞ü‡±á, ‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å ‡∞à ‡∞Æ‡∞æ‡∞Ç‡∞§‡±ç‡∞∞‡∞ø‡∞ï ‡∞¨‡∞æ‡∞ü‡∞≤‡±Å ‡∞µ‡±á‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞æ‡∞≤‡∞ø\" ‡∞Ö‡∞®‡∞ø ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞æ‡∞°‡±Å. ‡∞∞‡∞æ‡∞Æ‡±Å ‡∞Ü‡∞∂‡±ç‡∞ö‡∞∞‡±ç‡∞Ø‡∞™‡±ã‡∞Ø‡∞æ‡∞°‡±Å, ‡∞ï‡∞æ‡∞®‡±Ä ‡∞Ö‡∞§‡∞®‡±Å ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞°‡±Å.\n",
            "\n",
            "‡∞Æ‡∞æ‡∞Ç‡∞§‡±ç‡∞∞‡∞ø‡∞ï‡±Å‡∞°‡±Å ‡∞∞‡∞æ‡∞Æ‡±Å‡∞ï‡±Å ‡∞ï‡±ä‡∞®‡±ç‡∞®‡∞ø ‡∞Æ‡∞æ‡∞Ç‡∞§‡±ç‡∞∞‡∞ø‡∞ï ‡∞µ‡∞∏‡±ç‡∞§‡±Å‡∞µ‡±Å‡∞≤‡∞®‡±Å ‡∞á‡∞ö‡±ç‡∞ö‡∞æ‡∞°‡±Å. \"‡∞à ‡∞µ‡∞∏‡±ç‡∞§‡±Å‡∞µ‡±Å‡∞≤‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø, ‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å ‡∞®‡±Ä ‡∞ï‡∞≤‡∞®‡±Å ‡∞®‡∞ø‡∞ú‡∞Ç ‡∞ö‡±á‡∞∏‡±Å‡∞ï‡±ã‡∞ó‡∞≤‡∞µ‡±Å\" ‡∞Ö‡∞®‡∞ø ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞æ‡∞°‡±Å. ‡∞∞‡∞æ‡∞Æ‡±Å ‡∞Ü‡∞®‡∞Ç‡∞¶‡∞Ç‡∞ó‡∞æ ‡∞µ‡∞æ‡∞ü‡∞ø‡∞®‡∞ø ‡∞§‡±Ä‡∞∏‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞°‡±Å. \n",
            "\n",
            "‡∞Ö‡∞§‡∞®‡±Å ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ï‡∞ø ‡∞§‡∞ø‡∞∞‡∞ø‡∞ó‡∞ø ‡∞µ‡∞ö‡±ç‡∞ö‡∞ø, ‡∞Æ‡∞æ‡∞Ç‡∞§‡±ç‡∞∞‡∞ø‡∞ï‡±Å‡∞°‡∞ø‡∞ö‡±ç‡∞ö‡∞ø‡∞® ‡∞µ‡∞∏‡±ç‡∞§‡±Å‡∞µ‡±Å‡∞≤‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø, ‡∞é‡∞ó‡∞∞‡∞°‡∞Ç ‡∞®‡±á‡∞∞‡±ç‡∞ö‡±Å‡∞ï‡±ã‡∞µ‡∞æ‡∞≤‡∞®‡∞ø ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞æ‡∞°‡±Å. ‡∞Æ‡±ä‡∞¶‡∞ü, ‡∞Ö‡∞§‡∞®‡±Å ‡∞µ‡∞ø‡∞´‡∞≤‡∞Æ‡∞Ø‡±ç‡∞Ø‡∞æ‡∞°‡±Å, ‡∞ï‡∞æ‡∞®‡±Ä ‡∞Ö‡∞§‡∞®‡±Å ‡∞®‡∞ø‡∞∞‡∞Ç‡∞§‡∞∞‡∞Ç ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞∏‡±ç‡∞§‡±Ç, ‡∞ö‡∞ø‡∞µ‡∞∞‡∞ï‡±Å ‡∞µ‡∞ø‡∞ú‡∞Ø‡∞µ‡∞Ç‡∞§‡∞Æ‡∞Ø‡±ç‡∞Ø‡∞æ‡∞°‡±Å. \n",
            "\n",
            "‡∞∞‡∞æ‡∞Æ‡±Å ‡∞Ü‡∞ï‡∞æ‡∞∂‡∞Ç‡∞≤‡±ã ‡∞é‡∞ó‡∞ø‡∞∞‡∞ø, ‡∞§‡∞® ‡∞∏‡±ç‡∞®‡±á‡∞π‡∞ø‡∞§‡±Å‡∞≤‡∞ï‡±Å ‡∞ö‡±Ç‡∞™‡∞ø‡∞Ç‡∞ö‡∞æ‡∞°‡±Å. ‡∞Ö‡∞Ç‡∞¶‡∞∞‡±Ç ‡∞Ü‡∞∂‡±ç‡∞ö‡∞∞‡±ç‡∞Ø‡∞™‡±ã‡∞Ø‡∞æ‡∞∞‡±Å. ‡∞∞‡∞æ‡∞Æ‡±Å ‡∞§‡∞® ‡∞ï‡∞≤‡∞®‡±Å ‡∞®‡∞ø‡∞ú‡∞Ç ‡∞ö‡±á‡∞∏‡±Å‡∞ï‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞°‡±Å. \n",
            "\n",
            "‡∞à ‡∞ï‡∞• ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞Æ‡∞®‡∞ï‡±Å ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å, ‡∞ï‡∞∑‡±ç‡∞ü‡∞™‡∞°‡∞ø‡∞§‡±á, ‡∞ï‡∞≤‡∞≤‡±Å ‡∞®‡∞ø‡∞ú‡∞Æ‡∞µ‡±Å‡∞§‡∞æ‡∞Ø‡∞ø.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(base_url='https://api.two.ai/v2',\n",
        "                api_key=userdata.get(\"SUTRA_API_KEY\"))\n",
        "\n",
        "response = client.chat.completions.create(model='sutra-v2',\n",
        "                                        messages = [{\"role\": \"user\", \"content\": \"‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞í‡∞ï ‡∞ï‡∞• ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡±Å?\"}],\n",
        "                                        max_tokens=1024,\n",
        "                                        temperature=0)\n",
        "\n",
        "\n",
        "responce = response.choices[0].message.content\n",
        "print(responce)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA75BpNCrZGM"
      },
      "source": [
        "####French"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6MRRTYOrUSh",
        "outputId": "369922cc-6c45-438e-b584-fda58d0999ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Il √©tait une fois, dans un petit village nich√© au c≈ìur des montagnes, une jeune fille nomm√©e √âlodie. √âlodie √©tait connue pour sa curiosit√© insatiable et son amour de la nature. Chaque jour, elle explorait les for√™ts environnantes, d√©couvrant des fleurs rares et √©coutant le chant des oiseaux.\n",
            "\n",
            "Un matin, alors qu'elle se promenait pr√®s d'un ruisseau scintillant, √âlodie aper√ßut une lumi√®re √©trange √©manant d'une grotte. Intrigu√©e, elle s'approcha et d√©couvrit une pierre pr√©cieuse, brillante comme mille √©toiles. En la touchant, elle sentit une √©nergie douce et chaleureuse l'envahir.\n",
            "\n",
            "Soudain, un vieux sage apparut devant elle. Il lui expliqua que cette pierre avait le pouvoir de r√©aliser un v≈ìu, mais qu'il fallait l'utiliser avec sagesse. √âlodie r√©fl√©chit longuement. Elle aurait pu demander richesse ou gloire, mais elle choisit plut√¥t de faire un v≈ìu pour prot√©ger la nature de son village, afin que les g√©n√©rations futures puissent en profiter.\n",
            "\n",
            "Le sage sourit et, d'un geste de la main, transforma la pierre en une lumi√®re √©clatante qui enveloppa le village. Depuis ce jour, la nature prosp√©ra, et les habitants apprirent √† vivre en harmonie avec leur environnement. √âlodie devint une gardienne de la for√™t, transmettant son amour pour la nature aux enfants du village.\n",
            "\n",
            "Ainsi, gr√¢ce √† son v≈ìu, √âlodie changea non seulement sa vie, mais aussi celle de toute sa communaut√©, prouvant que la v√©ritable richesse r√©side dans la pr√©servation de notre monde.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(base_url='https://api.two.ai/v2',\n",
        "                api_key=userdata.get(\"SUTRA_API_KEY\"))\n",
        "\n",
        "response = client.chat.completions.create(model='sutra-v2',\n",
        "                                        messages = [{\"role\": \"user\", \"content\": \"Une histoire en fran√ßais, s'il vous pla√Æt.\"}],\n",
        "                                        max_tokens=1024,\n",
        "                                        temperature=0)\n",
        "\n",
        "\n",
        "responce = response.choices[0].message.content\n",
        "print(responce)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AwWaP94rnAx"
      },
      "source": [
        "####Marathi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kU21Golrorz",
        "outputId": "669cd17a-9302-4ec7-9a22-09861f918685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‡§è‡§ï‡§¶‡§æ ‡§è‡§ï ‡§õ‡•ã‡§ü‡§æ ‡§ó‡§æ‡§µ ‡§π‡•ã‡§§‡§æ, ‡§ú‡§ø‡§•‡•á ‡§∏‡§∞‡•ç‡§µ ‡§≤‡•ã‡§ï ‡§è‡§ï‡§Æ‡•á‡§ï‡§æ‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§¶‡§§‡•Ä‡§≤‡§æ ‡§∏‡§¶‡•à‡§µ ‡§§‡§§‡•ç‡§™‡§∞ ‡§Ö‡§∏‡§§. ‡§§‡•ç‡§Ø‡§æ ‡§ó‡§æ‡§µ‡§æ‡§§ ‡§è‡§ï ‡§ó‡§∞‡•Ä‡§¨ ‡§∂‡•á‡§§‡§ï‡§∞‡•Ä, ‡§∞‡§æ‡§Æ‡•Ç, ‡§∞‡§æ‡§π‡§§ ‡§π‡•ã‡§§‡§æ. ‡§§‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ‡§ï‡§°‡•á ‡§è‡§ï ‡§õ‡•ã‡§ü‡•Ä‡§∂‡•Ä ‡§ú‡§Æ‡•Ä‡§® ‡§π‡•ã‡§§‡•Ä, ‡§™‡§£ ‡§§‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡•á‡§π‡§®‡§§‡•Ä‡§Æ‡•Å‡§≥‡•á ‡§§‡•ã ‡§ö‡§æ‡§Ç‡§ó‡§≤‡•á ‡§™‡•Ä‡§ï ‡§â‡§ó‡§µ‡§§ ‡§π‡•ã‡§§‡§æ.\n",
            "\n",
            "‡§è‡§ï ‡§¶‡§ø‡§µ‡§∏, ‡§∞‡§æ‡§Æ‡•Ç‡§ö‡•ç‡§Ø‡§æ ‡§∂‡•á‡§§‡§æ‡§§ ‡§è‡§ï ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§Ü‡§£‡§ø ‡§Æ‡•ã‡§†‡§æ ‡§∏‡•ã‡§®‡•á‡§∞‡•Ä ‡§´‡•Å‡§≤‡§æ‡§Ç‡§ö‡§æ ‡§ù‡§æ‡§° ‡§â‡§ó‡§µ‡§≤‡§æ. ‡§§‡•ã ‡§ù‡§æ‡§° ‡§™‡§æ‡§π‡•Ç‡§® ‡§∞‡§æ‡§Æ‡•Ç ‡§ñ‡•Ç‡§™ ‡§Ü‡§®‡§Ç‡§¶‡§ø‡§§ ‡§ù‡§æ‡§≤‡§æ. ‡§§‡•ç‡§Ø‡§æ‡§®‡•á ‡§†‡§∞‡§µ‡§≤‡•á ‡§ï‡•Ä ‡§§‡•ã ‡§Ø‡§æ ‡§ù‡§æ‡§°‡§æ‡§ö‡•Ä ‡§ï‡§æ‡§≥‡§ú‡•Ä ‡§ò‡•á‡§à‡§≤ ‡§Ü‡§£‡§ø ‡§§‡•ç‡§Ø‡§æ‡§≤‡§æ ‡§µ‡§æ‡§¢‡§µ‡•á‡§≤. ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§¶‡§ø‡§µ‡§∂‡•Ä ‡§§‡•ã ‡§ù‡§æ‡§°‡§æ‡§≤‡§æ ‡§™‡§æ‡§£‡•Ä ‡§¶‡•á‡§§ ‡§Ö‡§∏‡•á, ‡§§‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§Ü‡§ú‡•Ç‡§¨‡§æ‡§ú‡•Ç‡§≤‡§æ ‡§ó‡§µ‡§§ ‡§ï‡§æ‡§™‡§§ ‡§Ö‡§∏‡•á ‡§Ü‡§£‡§ø ‡§§‡•ç‡§Ø‡§æ‡§≤‡§æ ‡§™‡•ç‡§∞‡•á‡§Æ‡§æ‡§®‡•á ‡§¨‡•ã‡§≤‡§§ ‡§Ö‡§∏‡•á.\n",
            "\n",
            "‡§ï‡§æ‡§π‡•Ä ‡§Æ‡§π‡§ø‡§®‡•ç‡§Ø‡§æ‡§Ç‡§®‡§Ç‡§§‡§∞, ‡§§‡•ç‡§Ø‡§æ ‡§ù‡§æ‡§°‡§æ‡§µ‡§∞ ‡§Ö‡§®‡•á‡§ï ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§´‡•Å‡§≤‡§Ç ‡§â‡§Æ‡§≤‡§≤‡•Ä. ‡§ó‡§æ‡§µ‡§æ‡§§‡•Ä‡§≤ ‡§≤‡•ã‡§ï ‡§§‡•ç‡§Ø‡§æ ‡§´‡•Å‡§≤‡§æ‡§Ç‡§ö‡•Ä ‡§™‡•ç‡§∞‡§∂‡§Ç‡§∏‡§æ ‡§ï‡§∞‡•Ç ‡§≤‡§æ‡§ó‡§≤‡•á. ‡§∞‡§æ‡§Æ‡•Ç‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡•á‡§π‡§®‡§§‡•Ä‡§Æ‡•Å‡§≥‡•á ‡§ù‡§æ‡§°‡§æ‡§®‡•á ‡§è‡§ï ‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ ‡§∏‡•å‡§Ç‡§¶‡§∞‡•ç‡§Ø ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡•á‡§≤‡•á ‡§π‡•ã‡§§‡•á. ‡§≤‡•ã‡§ï ‡§§‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§∂‡•á‡§§‡§æ‡§§ ‡§Ø‡•á‡§ä‡§® ‡§§‡•ç‡§Ø‡§æ ‡§´‡•Å‡§≤‡§æ‡§Ç‡§ö‡§æ ‡§Ü‡§®‡§Ç‡§¶ ‡§ò‡•á‡§§ ‡§π‡•ã‡§§‡•á.\n",
            "\n",
            "‡§è‡§ï ‡§¶‡§ø‡§µ‡§∏, ‡§ó‡§æ‡§µ‡§æ‡§§ ‡§è‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞‡•Ä ‡§Ü‡§≤‡§æ. ‡§§‡•ç‡§Ø‡§æ‡§®‡•á ‡§§‡•ç‡§Ø‡§æ ‡§´‡•Å‡§≤‡§æ‡§Ç‡§ö‡•á ‡§∏‡•å‡§Ç‡§¶‡§∞‡•ç‡§Ø ‡§™‡§æ‡§π‡§ø‡§≤‡•á ‡§Ü‡§£‡§ø ‡§∞‡§æ‡§Æ‡•Ç‡§≤‡§æ ‡§µ‡§ø‡§ö‡§æ‡§∞‡§≤‡•á, \"‡§π‡•á ‡§´‡•Å‡§≤ ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§µ‡§ø‡§ï‡§£‡§æ‡§∞ ‡§ï‡§æ?\" ‡§∞‡§æ‡§Æ‡•Ç‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§≤‡•á, \"‡§π‡•á ‡§´‡•Å‡§≤ ‡§Æ‡§æ‡§ù‡•ç‡§Ø‡§æ ‡§Æ‡•á‡§π‡§®‡§§‡•Ä‡§ö‡•á ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï ‡§Ü‡§π‡•á, ‡§Æ‡•Ä ‡§§‡•á ‡§µ‡§ø‡§ï‡§£‡§æ‡§∞ ‡§®‡§æ‡§π‡•Ä.\" ‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞‡•Ä‡§®‡•á ‡§§‡•ç‡§Ø‡§æ‡§≤‡§æ ‡§™‡•à‡§∏‡•á ‡§¶‡•á‡§£‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§ë‡§´‡§∞ ‡§¶‡§ø‡§≤‡•Ä, ‡§™‡§£ ‡§∞‡§æ‡§Æ‡•Ç‡§®‡•á ‡§®‡§ï‡§æ‡§∞ ‡§¶‡§ø‡§≤‡§æ.\n",
            "\n",
            "‡§∞‡§æ‡§Æ‡•Ç‡§ö‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡•á‡§Æ‡§æ‡§®‡•á ‡§Ü‡§£‡§ø ‡§Æ‡•á‡§π‡§®‡§§‡•Ä‡§®‡•á ‡§§‡•ç‡§Ø‡§æ ‡§ù‡§æ‡§°‡§æ‡§®‡•á ‡§ó‡§æ‡§µ‡§æ‡§§ ‡§è‡§ï ‡§®‡§µ‡•Ä‡§® ‡§Ü‡§∂‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡•á‡§≤‡•Ä. ‡§≤‡•ã‡§ï‡§æ‡§Ç‡§®‡•Ä ‡§§‡•ç‡§Ø‡§æ‡§≤‡§æ ‡§™‡•ç‡§∞‡•á‡§∞‡§£‡§æ ‡§Æ‡§æ‡§®‡§≤‡•Ä ‡§Ü‡§£‡§ø ‡§§‡•ç‡§Ø‡§æ‡§Ç‡§®‡•Ä‡§π‡•Ä ‡§Ü‡§™‡§≤‡•ç‡§Ø‡§æ ‡§ï‡§æ‡§Æ‡§æ‡§§ ‡§Ö‡§ß‡§ø‡§ï ‡§Æ‡•á‡§π‡§®‡§§ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§ö‡§æ ‡§∏‡§Ç‡§ï‡§≤‡•ç‡§™ ‡§ï‡•á‡§≤‡§æ. ‡§∞‡§æ‡§Æ‡•Ç‡§ö‡•ç‡§Ø‡§æ ‡§ï‡§•‡§æ ‡§ó‡§æ‡§µ‡§æ‡§§ ‡§∏‡§∞‡•ç‡§µ‡§§‡•ç‡§∞ ‡§™‡§∏‡§∞‡§≤‡•Ä ‡§Ü‡§£‡§ø ‡§§‡•ã ‡§è‡§ï ‡§Ü‡§¶‡§∞‡•ç‡§∂ ‡§¨‡§®‡§≤‡§æ.\n",
            "\n",
            "‡§Ø‡§æ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡•á, ‡§∞‡§æ‡§Æ‡•Ç‡§®‡•á ‡§¶‡§æ‡§ñ‡§µ‡§≤‡•á ‡§ï‡•Ä ‡§™‡•ç‡§∞‡•á‡§Æ, ‡§Æ‡•á‡§π‡§®‡§§ ‡§Ü‡§£‡§ø ‡§∏‡§Æ‡§∞‡•ç‡§™‡§£‡§æ‡§Æ‡•Å‡§≥‡•á ‡§ï‡•ã‡§£‡§§‡•Ä‡§π‡•Ä ‡§ó‡•ã‡§∑‡•ç‡§ü ‡§∏‡§æ‡§ß‡§§‡§æ ‡§Ø‡•á‡§§‡•á.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(base_url='https://api.two.ai/v2',\n",
        "                api_key=userdata.get(\"SUTRA_API_KEY\"))\n",
        "\n",
        "response = client.chat.completions.create(model='sutra-v2',\n",
        "                                        messages = [{\"role\": \"user\", \"content\": \"‡§ï‡•É‡§™‡§Ø‡§æ ‡§Æ‡§∞‡§æ‡§†‡•Ä‡§§ ‡§è‡§ï ‡§ï‡§•‡§æ ‡§∏‡§æ‡§Ç‡§ó‡§æ\"}],\n",
        "                                        max_tokens=1024,\n",
        "                                        temperature=0)\n",
        "\n",
        "\n",
        "responce = response.choices[0].message.content\n",
        "print(responce)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kThbptYWWcB"
      },
      "source": [
        "## Sutra using Langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjJ7TWpQp8Zr"
      },
      "source": [
        "###install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbvOcoZfWWK3",
        "outputId": "9ccd3737-7d9b-4b9f-b6ee-7ee5841d81c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain_openai langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNo8k_shqAgb"
      },
      "source": [
        "###Example Using Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZFgU-PiITE7",
        "outputId": "cdf044c7-61d7-48af-c602-5fb38d01ced8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‡§Æ‡•à‡§Ç ‡§†‡•Ä‡§ï ‡§π‡•Ç‡§Å, ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç? ‡§ï‡•ã‡§à ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§µ‡§ø‡§∑‡§Ø ‡§π‡•à ‡§ú‡§ø‡§∏ ‡§™‡§∞ ‡§Ü‡§™ ‡§ö‡§∞‡•ç‡§ö‡§æ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á?\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "chat = ChatOpenAI(\n",
        "    api_key=userdata.get(\"SUTRA_API_KEY\"),\n",
        "    base_url=\"https://api.two.ai/v2\",\n",
        "    model=\"sutra-v2\"\n",
        ")\n",
        "\n",
        "# Create a conversation\n",
        "messages = [HumanMessage(content=\"‡§ï‡•à‡§∏‡•á ‡§π‡•ã?\")]\n",
        "\n",
        "# Get response\n",
        "response = chat.invoke(messages)\n",
        "\n",
        "# Print response content\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRh5kY8nr3Nh"
      },
      "source": [
        "###Test With Multiple Languages using Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QshNHf1_r7Ya",
        "outputId": "811164d5-7fe9-4c15-b7c5-62585e3ea094"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "chat = ChatOpenAI(\n",
        "    api_key=userdata.get(\"SUTRA_API_KEY\"),\n",
        "    base_url=\"https://api.two.ai/v2\",\n",
        "    model=\"sutra-v2\",\n",
        "\n",
        ")\n",
        "\n",
        "# List of messages in different languages\n",
        "messages_list = [\n",
        "    HumanMessage(content=\"‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞í‡∞ï ‡∞ï‡∞• ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡±Å?\"),  # Telugu: \"Tell a story in Telugu\"\n",
        "    HumanMessage(content=\"Une histoire en fran√ßais, s'il vous pla√Æt.\"),  # French: \"A story in French, please.\"\n",
        "    HumanMessage(content=\"Por favor, cu√©ntame una historia en espa√±ol.\"),  # Spanish: \"Please tell me a story in Spanish.\"\n",
        "    HumanMessage(content=\"‡§ï‡•É‡§™‡§Ø‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§ï‡§π‡§æ‡§®‡•Ä ‡§∏‡•Å‡§®‡§æ‡§á‡§è‡•§\"),  # Hindi: \"Please tell a story in Hindi.\"\n",
        "    HumanMessage(content=\"Bitte erz√§hle mir eine Geschichte auf Deutsch.\")  # German: \"Please tell me a story in German.\"\n",
        "]\n",
        "\n",
        "# Loop through each language request\n",
        "for msg in messages_list:\n",
        "    response = chat.invoke([msg])\n",
        "    print(f\"\\nPrompt: {msg.content}\")\n",
        "    print(f\"Response: {response.content}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYOG_JzstcHi"
      },
      "source": [
        "###Building a Simple Chatbot with Langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS5jNxALtYxO",
        "outputId": "dd91b865-4bb4-4613-b4d2-299bbcfce91b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "chat = ChatOpenAI(\n",
        "    api_key=userdata.get(\"SUTRA_API_KEY\"),\n",
        "    base_url=\"https://api.two.ai/v2\",\n",
        "    model=\"sutra-v2\"\n",
        ")\n",
        "\n",
        "# Start the chatbot conversation loop\n",
        "print(\"Chatbot: Hello! Type 'exit' to end the conversation.\\n\")\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")  # Get user input\n",
        "\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Chatbot: Goodbye! üëã\")\n",
        "        break\n",
        "\n",
        "    # Add user message to chat history\n",
        "    chat_history.append(HumanMessage(content=user_input))\n",
        "\n",
        "    # Get response from AI\n",
        "    response = chat.invoke(chat_history)\n",
        "\n",
        "    # Print AI response\n",
        "    print(\"Chatbot:\", response.content)\n",
        "\n",
        "    # Add AI response to chat history\n",
        "    chat_history.append(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx9jgs3f8TbA"
      },
      "source": [
        "##LlamaIndex with the SUTRA model for Document Querying"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw2dnzLu8bkr"
      },
      "source": [
        "####Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahZUEEUj7eyb",
        "outputId": "e9e4e8e4-3f0f-4790-cef1-0f9c9e65396d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m251.3/251.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU llama-index langchain_openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFAPXG_h8fE2"
      },
      "source": [
        "####Setup API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8MFbxcTv78wz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDXinJnF8jCP"
      },
      "source": [
        "###Example Using LlamaIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5eIhtbH7i4_",
        "outputId": "59bfef92-28c3-44aa-f952-12216400a9a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SUTRA supports over 50 languages.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.core import Settings\n",
        "from langchain_openai import ChatOpenAI\n",
        "from llama_index.core import Document\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "chat = ChatOpenAI(\n",
        "    api_key=userdata.get(\"SUTRA_API_KEY\"),\n",
        "    base_url=\"https://api.two.ai/v2\",\n",
        "    model=\"sutra-v2\"\n",
        ")\n",
        "\n",
        "\n",
        "# Sample text\n",
        "text = \"\"\"\n",
        "SUTRA is a family of large multi-lingual language (LMLMs) models pioneered by Two Platforms.\n",
        "SUTRA‚Äôs dual-transformer approach extends the power of both MoE and Dense AI language model architectures,\n",
        "delivering cost-efficient multilingual capabilities for over 50+ languages. It powers scalable AI applications for conversation, search,\n",
        "and advanced reasoning, ensuring high-performance across diverse languages, domains and applications.\n",
        "\"\"\"\n",
        "\n",
        "# Create a document\n",
        "doc = Document(text=text)\n",
        "\n",
        "# Build index\n",
        "index = VectorStoreIndex.from_documents([doc])\n",
        "\n",
        "# Query\n",
        "response = index.as_query_engine().query(\"How many languages does SUTRA support?\")\n",
        "print(response)  # Output: \"SUTRA supports 50+ languages.\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
