{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "y0gqCQWgs0eI",
        "koPNP0hQtpjP",
        "M4naKqaVtupt",
        "xrA889Ifs8s1",
        "_6TJLtmOwNbp"
      ],
      "authorship_tag": "ABX9TyPQKmFrlvnfBH4GKcSOZYop",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AtharvaNawadkar/gen-ai-experiments/blob/patch-1/ScrapeGraphAI_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "urhxlxogbN2o"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install scrapegraphai --upgrade\n",
        "!apt install chromium-chromedriver\n",
        "!pip install nest_asyncio\n",
        "!pip install playwright\n",
        "!playwright install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "awVwlhvIbUOE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "BCTveuLfbUsS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OpenAI Implementation**"
      ],
      "metadata": {
        "id": "y0gqCQWgs0eI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the configuration for the graph for OpenAI"
      ],
      "metadata": {
        "id": "xTu06ptxBADG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_config_openai = {\n",
        "    \"llm\": {\n",
        "        \"api_key\": OPENAI_API_KEY,\n",
        "        \"model\": \"gpt-3.5-turbo\",\n",
        "        \"temperature\":0,\n",
        "    },\n",
        "    \"verbose\":True,\n",
        "}"
      ],
      "metadata": {
        "id": "lHtItvUabgi1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**`SmartScraperGraph`**\n",
        "\n",
        "\n",
        "\n",
        "> **SmartScraperGraph** is a class representing one of the default scraping pipelines. It uses a direct graph implementation where each node has its own function, from retrieving html from a website to extracting relevant information based on your query and generate a coherent answer.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "koPNP0hQtpjP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the SmartScraperGraph instance and run it"
      ],
      "metadata": {
        "id": "6FLWBvu0BEAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scrapegraphai.graphs import SmartScraperGraph\n",
        "\n",
        "\n",
        "smart_scraper_graph = SmartScraperGraph(\n",
        "    prompt=\"List me all the apps with their descriptions.\",\n",
        "    # also accepts a string with the already downloaded HTML code\n",
        "    source=\"https://buildfastwithai.com/apps\",\n",
        "    config=graph_config_openai\n",
        ")\n",
        "\n",
        "result = smart_scraper_graph.run()"
      ],
      "metadata": {
        "id": "ZEsvkWCBbiFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edf4ade4-1adb-44e1-ee76-3f46ae733ec9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--- Executing Fetch Node ---\n",
            "--- Executing Parse Node ---\n",
            "--- Executing RAG Node ---\n",
            "--- (updated chunks metadata) ---\n",
            "--- (tokens compressed and vector stored) ---\n",
            "--- Executing GenerateAnswer Node ---\n",
            "\n",
            "\n",
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 787.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "print(json.dumps(result,indent=2))"
      ],
      "metadata": {
        "id": "sf_93pc-bskp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ba47c83-3524-4f7f-83e8-9659be303228"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"apps\": [\n",
            "    {\n",
            "      \"name\": \"Chat with PDF\",\n",
            "      \"description\": \"Chat with your PDFs. Free!!!\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Gita GPT\",\n",
            "      \"description\": \"Chat with lord krishna\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Youtube Bot\",\n",
            "      \"description\": \"Talk to youtube videos\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Character AI\",\n",
            "      \"description\": \"Talk to your favourite characters\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"GPT Data Analyst\",\n",
            "      \"description\": \"Talk to your data\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Interview Bot\",\n",
            "      \"description\": \"Get interview questions answered\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`SearchGraph`**\n",
        "\n",
        "\n",
        "> This graph **transforms** the user prompt in a **internet search query**, fetch the relevant URLs, and start the scraping process. Similar to the **SmartScraperGraph** but with the addition of the **SearchInternetNode** node.\n",
        "\n"
      ],
      "metadata": {
        "id": "M4naKqaVtupt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scrapegraphai.graphs import SearchGraph\n",
        "\n",
        "search_graph = SearchGraph(\n",
        "    prompt=\"List me top 10 LMSYS LLMs.\",\n",
        "    config=graph_config_openai\n",
        ")\n",
        "\n",
        "result = search_graph.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6Wjonhut1os",
        "outputId": "cf616850-3700-4869-cd96-cb90e91f5ac3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--- Executing SearchInternet Node ---\n",
            "Search Query: top 10 LMSYS LLMs\n",
            "--- Executing GraphIterator Node with batchsize 16 ---\n",
            "\n",
            "\n",
            "processing graph instances:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A--- Executing Fetch Node ---\n",
            "--- Executing Fetch Node ---\n",
            "--- Executing Fetch Node ---\n",
            "--- Executing Parse Node ---\n",
            "--- Executing RAG Node ---\n",
            "--- (updated chunks metadata) ---\n",
            "--- (tokens compressed and vector stored) ---\n",
            "--- Executing GenerateAnswer Node ---\n",
            "\n",
            "\n",
            "\n",
            "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 1343.68it/s]\n",
            "\n",
            "\n",
            "processing graph instances:  33%|███▎      | 1/3 [00:19<00:38, 19.30s/it]\u001b[A\u001b[A--- Executing Parse Node ---\n",
            "--- Executing Parse Node ---\n",
            "--- Executing RAG Node ---\n",
            "--- (updated chunks metadata) ---\n",
            "--- Executing RAG Node ---\n",
            "--- (updated chunks metadata) ---\n",
            "--- (tokens compressed and vector stored) ---\n",
            "--- Executing GenerateAnswer Node ---\n",
            "\n",
            "\n",
            "\n",
            "Processing chunks: 100%|██████████| 4/4 [00:00<00:00, 3430.92it/s]\n",
            "--- (tokens compressed and vector stored) ---\n",
            "--- Executing GenerateAnswer Node ---\n",
            "\n",
            "\n",
            "\n",
            "Processing chunks: 100%|██████████| 4/4 [00:00<00:00, 2862.52it/s]\n",
            "\n",
            "\n",
            "processing graph instances:  67%|██████▋   | 2/3 [01:10<00:37, 37.89s/it]\u001b[A\u001b[A\n",
            "\n",
            "processing graph instances: 100%|██████████| 3/3 [01:12<00:00, 24.16s/it]\n",
            "--- Executing MergeAnswers Node ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(result,indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pir3VMAur1h",
        "outputId": "3fca242e-c25b-48a5-b8c1-394ac7695d2b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Top 10 LMSYS LLMs\": [\n",
            "    {\n",
            "      \"Name\": \"GPT-4 Turbo\",\n",
            "      \"Organization\": \"OpenAI\",\n",
            "      \"Knowledge Cutoff\": \"December 2023\",\n",
            "      \"License\": \"Proprietary (owned by OpenAI)\",\n",
            "      \"How to Access\": \"ChatGPT Plus subscribers for $20 per month, update through Microsoft\\u2019s Copilot\",\n",
            "      \"Parameters Trained\": \"Estimated around 175 billion\",\n",
            "      \"Key Features\": [\n",
            "        \"Faster and more efficient\",\n",
            "        \"Better at understanding context\",\n",
            "        \"Versatile in tasks\",\n",
            "        \"Focus on safety and ethics\",\n",
            "        \"Learns from users\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Name\": \"Claude 3 Opus\",\n",
            "      \"Organization\": \"Anthropic\",\n",
            "      \"Knowledge Cutoff\": \"August 2023\",\n",
            "      \"License\": \"Proprietary\",\n",
            "      \"How to Access\": \"Talk to Claude 3 Opus for $20/month, access through Anthropic\\u2019s API\",\n",
            "      \"Parameters Trained\": \"Estimated to be within the same range as other large language models\",\n",
            "      \"Key Features\": [\n",
            "        \"Enhanced reasoning capabilities\",\n",
            "        \"Multilingual support\",\n",
            "        \"Improved contextual understanding\",\n",
            "        \"Emphasis on safety and ethics\",\n",
            "        \"Customizable behavior\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Name\": \"Gemini 1.5 Pro API-0409-Preview\",\n",
            "      \"Organization\": \"Google AI\",\n",
            "      \"Knowledge Cutoff\": \"November 2023\",\n",
            "      \"License\": \"Likely under a proprietary license owned by Google\",\n",
            "      \"How to Access\": \"Under preview mode on Google AI Lab\",\n",
            "      \"Parameters Trained\": \"Expected to exceed the trillion parameter mark\",\n",
            "      \"Key Features\": [\n",
            "        \"Multi-Modality\",\n",
            "        \"Enhanced Reasoning and Problem-Solving\",\n",
            "        \"Improved Contextual Understanding\",\n",
            "        \"Efficiency and Scalability\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Name\": \"Llama 3 70b Instruct\",\n",
            "      \"Organization\": \"Meta AI\",\n",
            "      \"Knowledge Cutoff\": \"December 2023\",\n",
            "      \"License\": \"Open-source\",\n",
            "      \"How to Access\": \"Available for free use through Meta AI\\u2019s GitHub repository\",\n",
            "      \"Parameters Trained\": \"70 billion\",\n",
            "      \"Key Features\": [\n",
            "        \"Conversational AI model\",\n",
            "        \"Optimized for efficient inference\",\n",
            "        \"Flexibility for specific tasks and domains\",\n",
            "        \"Open-sourced\",\n",
            "        \"Encourages community involvement\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Name\": \"Command R+\",\n",
            "      \"Organization\": \"Cohere\",\n",
            "      \"Knowledge Cutoff\": \"May 2024\",\n",
            "      \"License\": \"Proprietary\",\n",
            "      \"How to Access\": \"Through Cohere\\u2019s API and enterprise solutions\",\n",
            "      \"Parameters Trained\": \"Estimated 20 billion\",\n",
            "      \"Key Features\": [\n",
            "        \"Fast response times and efficient memory usage\",\n",
            "        \"Deep comprehension and sophisticated responses\",\n",
            "        \"Diverse range of tasks handling\",\n",
            "        \"Commitment to ethical guidelines\",\n",
            "        \"Adaptable and evolving\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Name\": \"Mistral-Large-2402\",\n",
            "      \"Organization\": \"Mistral AI\",\n",
            "      \"License\": \"Proprietary\",\n",
            "      \"How to Access\": \"Available through Azure AI Studio and Azure Machine Learning\",\n",
            "      \"Key Features\": [\n",
            "        \"Multilingual Proficiency\",\n",
            "        \"Extended Context Window\",\n",
            "        \"Instruction Following\",\n",
            "        \"Function Calling\",\n",
            "        \"Performance\",\n",
            "        \"Partnership with Microsoft\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Name\": \"Reka-Core\",\n",
            "      \"Organization\": \"Reka AI\",\n",
            "      \"Knowledge Cutoff\": \"2023\",\n",
            "      \"License\": \"Proprietary\",\n",
            "      \"How to Access\": \"Reka Playground\",\n",
            "      \"Parameters Trained\": \"> 21 billion\",\n",
            "      \"Key Features\": [\n",
            "        \"Multimodal understanding\",\n",
            "        \"128K context window\",\n",
            "        \"Reasoning abilities\",\n",
            "        \"Coding and agentic workflow\",\n",
            "        \"Multilingual support\",\n",
            "        \"Deployment Flexibility\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Name\": \"Qwen1.5-110B-Chat\",\n",
            "      \"Organization\": \"Qwen team, Alibaba Cloud\",\n",
            "      \"Knowledge Cutoff\": \"2024\",\n",
            "      \"License\": \"Open source\",\n",
            "      \"How to Access\": \"HuggingFace platform\",\n",
            "      \"Parameters Trained\": \"Over 100 billion\",\n",
            "      \"Key Features\": [\n",
            "        \"Multilingual support\",\n",
            "        \"Benchmark model quality\",\n",
            "        \"Collaboration and Framework Support\",\n",
            "        \"Performance Enhancements\",\n",
            "        \"Integration with External Systems\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Name\": \"Zephyr-ORPO-141b-A35b-v0.1\",\n",
            "      \"Key Features\": [\n",
            "        \"Cutting-edge advancement in AI language models\",\n",
            "        \"Leverages the innovative ORPO algorithm for training\",\n",
            "        \"Performance in various benchmarks showcases capabilities\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Name\": \"Starling-LM-7B-beta\",\n",
            "      \"Organization\": \"Nexusflow\",\n",
            "      \"License\": \"Open Source\",\n",
            "      \"Parameters Trained\": \"7 billion\",\n",
            "      \"How to access\": \"Access the model directly with the Hugging Face Transformers library.\",\n",
            "      \"Top Key Features\": {\n",
            "        \"A Finetuned Model\": \"The model is trained from an open source language model, Openchat-3.5-0106, with a new reward model Nexusflow/Starling-RM-34B and policy optimization method Finetuning Language Models from Human Preferences (PPO).\",\n",
            "        \"High quality dataset\": \"The model has been trained on the Nectar dataset comprising of 183K chat prompts with responses from various models, facilitating research into RLHF mechanisms with mitigated positional bias.\",\n",
            "        \"RLAIF\": \"The model learned through Reinforcement Learning from AI Feedback (RLAIF).\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"Title\": \"The best large language models (LLMs) in 2024\",\n",
            "      \"Developer\": \"OpenAI\",\n",
            "      \"Popular apps that use it\": \"Microsoft, Duolingo, Stripe, Zapier, Dropbox, ChatGPT\",\n",
            "      \"Access\": \"API\"\n",
            "    },\n",
            "    {\n",
            "      \"Link\": \"https://ai.google.dev/gemma/\"\n",
            "    },\n",
            "    {\n",
            "      \"Link\": \"https://lmsys.org/blog/2023-03-30-vicuna/\"\n",
            "    },\n",
            "    {\n",
            "      \"Link\": \"https://arena.lmsys.org\"\n",
            "    },\n",
            "    {\n",
            "      \"Link\": \"https://lmsys.org/\"\n",
            "    },\n",
            "    {\n",
            "      \"Link\": \"https://www.anthropic.com\"\n",
            "    },\n",
            "    {\n",
            "      \"Link\": \"https://stability.ai/stable-lm\"\n",
            "    },\n",
            "    {\n",
            "      \"Link\": \"https://cohere.com/coral\"\n",
            "    },\n",
            "    {\n",
            "      \"Link\": \"https://falconllm.tii.ae\"\n",
            "    },\n",
            "    {\n",
            "      \"Link\": \"https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm\"\n",
            "    },\n",
            "    {\n",
            "      \"Title\": \"Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings\",\n",
            "      \"Date\": \"May 03, 2023\",\n",
            "      \"Authors\": [\n",
            "        \"Lianmin Zheng\",\n",
            "        \"Ying Sheng\",\n",
            "        \"Wei-Lin Chiang\",\n",
            "        \"Hao Zhang\",\n",
            "        \"Joseph E. Gonzalez\",\n",
            "        \"Ion Stoica\"\n",
            "      ],\n",
            "      \"Description\": \"Chatbot Arena is a benchmark platform for large language models (LLMs) that features anonymous, randomized battles in a crowdsourced manner. The platform uses the Elo rating system for ranking models based on user voting.\",\n",
            "      \"Link\": \"https://arena.lmsys.org\",\n",
            "      \"Leaderboard\": \"https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gemini Implementation**"
      ],
      "metadata": {
        "id": "xrA889Ifs8s1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the configuration for the graph for Gemini"
      ],
      "metadata": {
        "id": "5JTetR-6BWms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_config_gemini = {\n",
        "    \"llm\": {\n",
        "        \"api_key\": GEMINI_API_KEY,\n",
        "        \"model\": \"gemini-pro\",\n",
        "    },\n",
        "    \"verbose\":True\n",
        "}"
      ],
      "metadata": {
        "id": "RHdo0yxHtCqA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`SmartScraperGrapher`**"
      ],
      "metadata": {
        "id": "_6TJLtmOwNbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rest is same."
      ],
      "metadata": {
        "id": "BM01tFGDBZqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scrapegraphai.graphs import SmartScraperGraph\n",
        "\n",
        "smart_scraper_graph = SmartScraperGraph(\n",
        "    prompt=\"List me all the apps with their descriptions.\",\n",
        "    # also accepts a string with the already downloaded HTML code\n",
        "    source=\"https://buildfastwithai.com/apps\",\n",
        "    config=graph_config\n",
        ")"
      ],
      "metadata": {
        "id": "NIisdGGstOns"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = smart_scraper_graph.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMIkS5I0tQgJ",
        "outputId": "aae0b06f-cfac-4f71-cef6-f15b705b2874"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--- Executing Fetch Node ---\n",
            "--- Executing Parse Node ---\n",
            "--- Executing RAG Node ---\n",
            "--- (updated chunks metadata) ---\n",
            "--- (tokens compressed and vector stored) ---\n",
            "--- Executing GenerateAnswer Node ---\n",
            "Processing chunks: 100%|██████████| 1/1 [00:00<00:00, 176.60it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(result, indent = 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG9FPQXBtRKF",
        "outputId": "157f3120-448a-4c30-cb84-a7b30e077622"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"apps\": [\n",
            "    {\n",
            "      \"name\": \"Chat with PDF\",\n",
            "      \"description\": \"Chat with your PDFs. Free!!!\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Gita GPT\",\n",
            "      \"description\": \"Chat with lord krishna\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Youtube Bot\",\n",
            "      \"description\": \"Talk to youtube videos\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Character AI\",\n",
            "      \"description\": \"Talk to your favourite characters\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"GPT Data Analyst\",\n",
            "      \"description\": \"Talk to your data\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Interview Bot\",\n",
            "      \"description\": \"Get interview questions answered\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}