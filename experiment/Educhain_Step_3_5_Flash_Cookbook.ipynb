{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "<img src=\"https://github.com/Shubhwithai/GRE_Geometry_quiz/blob/main/Group%2042.png?raw=true\" width=\"\" height=\"50\">\n",
        "\n",
        "Educhain is a powerful Python package that leverages Generative AI to create\n",
        "engaging and personalized educational content. From generating multiple-choice questions to crafting comprehensive lesson plans, Educhain makes it easy to apply AI in various educational scenarios.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/12RnZsBOPW4jOKytJnNmDUexBTYV4Y0Mk?usp=sharing)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "overview"
      },
      "source": [
        "# ğŸ“š Educhain + Step 3.5 Flash: AI-Powered Educational Content\n",
        "\n",
        "Generate **quizzes, MCQs, lesson plans, and educational content** using **Educhain** with **Step 3.5 Flash** (196B MoE model).\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "| Section | Topics |\n",
        "|---------|--------|\n",
        "| **Getting Started** | Installation, setup, first questions |\n",
        "| **MCQ Generation** | Topic-based, difficulty levels, bulk |\n",
        "| **Question Types** | MCQ, True/False, Fill-in-blank, Short answer |\n",
        "| **Custom Prompts** | Templates, domain-specific |\n",
        "| **Lesson Plans** | Automated curriculum generation |\n",
        "| **Data Sources** | Generate from URLs, PDFs |\n",
        "\n",
        "### Why Step 3.5 Flash for Education?\n",
        "\n",
        "| Feature | Benefit |\n",
        "|---------|--------|\n",
        "| **256K context** | Handle long educational texts |\n",
        "| **Deep reasoning** | Quality questions with good distractors |\n",
        "| **FREE via OpenRouter** | No cost for experimentation |\n",
        "| **Multi-language** | Generate content in any language |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section1"
      },
      "source": [
        "## ğŸ“¦ Section 1: Installation & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510bf3a1-a42b-4414-ec4a-8e0f92b5992f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m485.2/485.2 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m385.7/385.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "google-adk 1.23.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.23.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q educhain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "setup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "206ec3b9-207b-45b0-f73c-38fa11ade524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Educhain initialized with Step 3.5 Flash!\n",
            "ğŸ“ Model: stepfun/step-3.5-flash:free\n",
            "ğŸŒ Provider: OpenRouter\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from educhain import Educhain, LLMConfig\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Configure Step 3.5 Flash via OpenRouter\n",
        "step_flash = ChatOpenAI(\n",
        "    model=\"stepfun/step-3.5-flash:free\",\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=userdata.get(\"OPENROUTER_API_KEY\"),\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# Create Educhain config with Step 3.5 Flash\n",
        "step_config = LLMConfig(custom_model=step_flash)\n",
        "\n",
        "# Initialize Educhain client\n",
        "client = Educhain(step_config)\n",
        "\n",
        "print(\"âœ… Educhain initialized with Step 3.5 Flash!\")\n",
        "print(\"ğŸ“ Model: stepfun/step-3.5-flash:free\")\n",
        "print(\"ğŸŒ Provider: OpenRouter\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section2"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ¯ Section 2: Your First Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "first_questions",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f5a354a-00cd-4c01-ebe2-a817765467fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Generated Questions:\n",
            "\n",
            "Q1: What is Artificial Intelligence primarily concerned with?\n",
            "   A. Creating systems that can perform tasks requiring human intelligence\n",
            "   B. Building robots only\n",
            "   C. Developing computer hardware\n",
            "   D. Programming in Python\n",
            "   âœ… Answer: Creating systems that can perform tasks requiring human intelligence\n",
            "\n",
            "Q2: Which of the following is a type of machine learning where the model is trained on labeled data?\n",
            "   A. Unsupervised learning\n",
            "   B. Reinforcement learning\n",
            "   C. Supervised learning\n",
            "   D. Deep learning\n",
            "   âœ… Answer: Supervised learning\n",
            "\n",
            "Q3: What is a common ethical concern in AI development?\n",
            "   A. Efficiency of algorithms\n",
            "   B. Bias in AI systems\n",
            "   C. Speed of processing\n",
            "   D. Cost of implementation\n",
            "   âœ… Answer: Bias in AI systems\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate simple MCQ questions\n",
        "questions = client.qna_engine.generate_questions(\n",
        "    topic=\"Artificial Intelligence\",\n",
        "    num=3\n",
        ")\n",
        "\n",
        "print(\"ğŸ“ Generated Questions:\\n\")\n",
        "for i, q in enumerate(questions.questions, 1):\n",
        "    print(f\"Q{i}: {q.question}\")\n",
        "    for j, opt in enumerate(q.options):\n",
        "        print(f\"   {chr(65+j)}. {opt}\")\n",
        "    print(f\"   âœ… Answer: {q.answer}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "json_output"
      },
      "outputs": [],
      "source": [
        "# View as JSON\n",
        "import json\n",
        "\n",
        "questions_dict = questions.model_dump()\n",
        "print(\"ğŸ“Š JSON Output:\")\n",
        "print(json.dumps(questions_dict, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section3"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“‹ Section 3: MCQ Generation Master Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "basic_mcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a307bb0c-ffab-495c-ad3f-e3577fdd50b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Generated 5 MCQs on Machine Learning\n",
            "\n",
            "\n",
            "--- Question 1 ---\n",
            "â“ What is the primary goal of supervised learning?\n",
            "âœ… Answer: To learn a mapping from inputs to outputs\n",
            "\n",
            "--- Question 2 ---\n",
            "â“ Which of the following is a classification algorithm?\n",
            "âœ… Answer: Decision Tree\n",
            "\n",
            "--- Question 3 ---\n",
            "â“ What does the term 'overfitting' refer to in machine learning?\n",
            "âœ… Answer: When the model performs well on training data but poorly on unseen data\n",
            "\n",
            "--- Question 4 ---\n",
            "â“ Which metric is used to evaluate the performance of a binary classifier by considering both precision and recall?\n",
            "âœ… Answer: F1 Score\n",
            "\n",
            "--- Question 5 ---\n",
            "â“ In machine learning, what is the purpose of a validation set?\n",
            "âœ… Answer: To tune hyperparameters and select models\n"
          ]
        }
      ],
      "source": [
        "# Basic MCQ with topic\n",
        "basic_mcq = client.qna_engine.generate_questions(\n",
        "    topic=\"Machine Learning Fundamentals\",\n",
        "    num=5\n",
        ")\n",
        "\n",
        "print(f\"âœ… Generated {len(basic_mcq.questions)} MCQs on Machine Learning\\n\")\n",
        "\n",
        "for i, q in enumerate(basic_mcq.questions, 1):\n",
        "    print(f\"\\n--- Question {i} ---\")\n",
        "    print(f\"â“ {q.question}\")\n",
        "    print(f\"âœ… Answer: {q.answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "difficulty_levels"
      },
      "outputs": [],
      "source": [
        "# MCQs with difficulty levels\n",
        "easy_questions = client.qna_engine.generate_questions(\n",
        "    topic=\"Python Programming\",\n",
        "    num=3,\n",
        "    custom_instructions=\"Generate EASY beginner-level questions. Focus on basic syntax and concepts.\"\n",
        ")\n",
        "\n",
        "hard_questions = client.qna_engine.generate_questions(\n",
        "    topic=\"Python Programming\",\n",
        "    num=3,\n",
        "    custom_instructions=\"Generate HARD advanced-level questions. Focus on decorators, metaclasses, and advanced concepts.\"\n",
        ")\n",
        "\n",
        "print(\"ğŸŸ¢ EASY Questions:\")\n",
        "for q in easy_questions.questions:\n",
        "    print(f\"  â€¢ {q.question}\")\n",
        "\n",
        "print(\"\\nğŸ”´ HARD Questions:\")\n",
        "for q in hard_questions.questions:\n",
        "    print(f\"  â€¢ {q.question}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "domain_specific",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f7d6a6f-39c2-4929-fcc1-962bfccc5f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“š Science: Photosynthesis in Plants\n",
            "   Q: Which molecule is primarily responsible for absorbing light during photosynthesi...\n",
            "   A: Chlorophyll\n",
            "   Q: In which part of the chloroplast do the light-dependent reactions take place?...\n",
            "   A: Thylakoid membranes\n",
            "\n",
            "ğŸ“š History: World War II\n",
            "   Q: In which year did World War II begin?...\n",
            "   A: 1939\n",
            "   Q: What was the code name for the Allied invasion of Normandy on D-Day?...\n",
            "   A: Operation Overlord\n",
            "\n",
            "ğŸ“š Math: Quadratic Equations\n",
            "   Q: What are the roots of the equation x^2 - 5x + 6 = 0?...\n",
            "   A: x=2, x=3\n",
            "   Q: For the quadratic equation 2x^2 + 4x + 1 = 0, what is the discriminant?...\n",
            "   A: 8\n",
            "\n",
            "ğŸ“š Programming: RESTful APIs\n",
            "   Q: Which HTTP method is used to update an existing resource in a RESTful API?...\n",
            "   A: PUT\n",
            "   Q: What does REST stand for in RESTful APIs?...\n",
            "   A: Representational State Transfer\n"
          ]
        }
      ],
      "source": [
        "# Domain-specific MCQs\n",
        "domains = {\n",
        "    \"Science\": \"Photosynthesis in Plants\",\n",
        "    \"History\": \"World War II\",\n",
        "    \"Math\": \"Quadratic Equations\",\n",
        "    \"Programming\": \"RESTful APIs\"\n",
        "}\n",
        "\n",
        "for domain, topic in domains.items():\n",
        "    questions = client.qna_engine.generate_questions(\n",
        "        topic=topic,\n",
        "        num=2\n",
        "    )\n",
        "    print(f\"\\nğŸ“š {domain}: {topic}\")\n",
        "    for q in questions.questions:\n",
        "        print(f\"   Q: {q.question[:80]}...\")\n",
        "        print(f\"   A: {q.answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section4"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ”¤ Section 4: Different Question Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "true_false",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b897b8-0ae8-4fbe-ccfe-5e678f0e5516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ…âŒ True/False Questions:\n",
            "\n",
            "1. Human activities, such as burning fossil fuels, are the main driver of current climate change.\n",
            "   Answer: True\n",
            "\n",
            "2. Climate change and ozone layer depletion are the same environmental issue.\n",
            "   Answer: False\n",
            "\n",
            "3. Carbon dioxide (CO2) is not a greenhouse gas.\n",
            "   Answer: False\n",
            "\n",
            "4. Rising global temperatures are causing sea levels to rise due to thermal expansion and melting ice.\n",
            "   Answer: True\n",
            "\n",
            "5. Climate change has no effect on the frequency or intensity of extreme weather events.\n",
            "   Answer: False\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# True/False Questions\n",
        "tf_questions = client.qna_engine.generate_questions(\n",
        "    topic=\"Climate Change\",\n",
        "    num=5,\n",
        "    custom_instructions=\"\"\"Generate True/False questions only.\n",
        "    Each question should have only two options: True and False.\n",
        "    Make statements that are clearly true or false.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"âœ…âŒ True/False Questions:\\n\")\n",
        "for i, q in enumerate(tf_questions.questions, 1):\n",
        "    print(f\"{i}. {q.question}\")\n",
        "    print(f\"   Answer: {q.answer}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fill_blank",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6abac996-2026-4ea9-8131-9ad93b033155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Fill in the Blank:\n",
            "\n",
            "1. The _____ is the largest bone in the human body.\n",
            "   Answer: femur\n",
            "\n",
            "2. The _____ organ pumps blood throughout the circulatory system.\n",
            "   Answer: heart\n",
            "\n",
            "3. The _____ is the part of the brain that controls balance and coordination.\n",
            "   Answer: cerebellum\n",
            "\n",
            "4. The _____ are the tiny air sacs in the lungs where gas exchange occurs.\n",
            "   Answer: alveoli\n",
            "\n",
            "5. The _____ gland is often called the 'master gland' because it controls other glands.\n",
            "   Answer: pituitary\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Fill in the Blank Questions\n",
        "fill_blank = client.qna_engine.generate_questions(\n",
        "    topic=\"Human Anatomy\",\n",
        "    num=5,\n",
        "    custom_instructions=\"\"\"Generate fill-in-the-blank questions.\n",
        "    Use _____ to indicate the blank.\n",
        "    The answer should complete the sentence correctly.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"ğŸ“ Fill in the Blank:\\n\")\n",
        "for i, q in enumerate(fill_blank.questions, 1):\n",
        "    print(f\"{i}. {q.question}\")\n",
        "    print(f\"   Answer: {q.answer}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "short_answer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac6a85c-5613-4912-845b-f5bc20e142e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœï¸ Short Answer Questions:\n",
            "\n",
            "1. What is the primary purpose of cross-validation in machine learning?\n",
            "   Expected: B) To evaluate model performance on unseen data\n",
            "\n",
            "2. Which technique is used to prevent overfitting by adding a penalty for large coefficients in linear models?\n",
            "   Expected: C) Both A and B\n",
            "\n",
            "3. What does a high AUC-ROC value indicate about a classification model?\n",
            "   Expected: B) The model has good separation between classes\n",
            "\n",
            "4. What is the role of the 'learning rate' in gradient descent?\n",
            "   Expected: A) It controls the step size for updating weights\n",
            "\n",
            "5. Which of the following is an example of unsupervised learning?\n",
            "   Expected: B) Customer segmentation\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Short Answer Questions\n",
        "short_answer = client.qna_engine.generate_questions(\n",
        "    topic=\"Data Science\",\n",
        "    num=5,\n",
        "    custom_instructions=\"\"\"Generate short answer questions that require 1-2 sentence responses.\n",
        "    Questions should test understanding, not just recall.\n",
        "    Include the expected answer.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"âœï¸ Short Answer Questions:\\n\")\n",
        "for i, q in enumerate(short_answer.questions, 1):\n",
        "    print(f\"{i}. {q.question}\")\n",
        "    print(f\"   Expected: {q.answer}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section5"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ¨ Section 5: Custom Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "blooms_taxonomy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5684c0d-343b-4ded-a852-5cc40edbe805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Bloom's Taxonomy Questions:\n",
            "\n",
            "â“ Bloom's Level: Remember - What is the term for one complete pass through the entire training dataset in neural network training?\n",
            "âœ… epoch\n",
            "\n",
            "â“ Bloom's Level: Understand - What is the main purpose of using a loss function in neural networks?\n",
            "âœ… To quantify the error between predictions and true values\n",
            "\n",
            "â“ Bloom's Level: Apply - Which neural network type is best suited for image recognition tasks?\n",
            "âœ… Convolutional Neural Network (CNN)\n",
            "\n",
            "â“ Bloom's Level: Analyze - In a neural network, what is the role of the activation function in the context of gradient propagation?\n",
            "âœ… It introduces non-linearity, affecting gradient flow\n",
            "\n",
            "â“ Bloom's Level: Evaluate - For training a neural network on a large dataset with limited computational resources, which strategy would you evaluate as most efficient?\n",
            "âœ… Employing batch normalization and a moderate network depth\n",
            "\n",
            "â“ Bloom's Level: Create - To address the challenge of few-shot learning in neural networks, which innovative architecture could be proposed?\n",
            "âœ… A meta-learning framework like MAML\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Bloom's Taxonomy Questions\n",
        "blooms_questions = client.qna_engine.generate_questions(\n",
        "    topic=\"Neural Networks\",\n",
        "    num=6,\n",
        "    custom_instructions=\"\"\"Generate exactly 6 questions, one for each level of Bloom's Taxonomy:\n",
        "    1. Remember (recall facts)\n",
        "    2. Understand (explain concepts)\n",
        "    3. Apply (use in new situations)\n",
        "    4. Analyze (break down components)\n",
        "    5. Evaluate (make judgments)\n",
        "    6. Create (produce new ideas)\n",
        "\n",
        "    Label each question with its Bloom's level.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"ğŸ“ Bloom's Taxonomy Questions:\\n\")\n",
        "for q in blooms_questions.questions:\n",
        "    print(f\"â“ {q.question}\")\n",
        "    print(f\"âœ… {q.answer}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "socratic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbd634e-8978-4cd8-e71b-2dcc165d8d02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¤” Socratic Questions:\n",
            "\n",
            "1. Which question best challenges the assumption that AI systems are inherently neutral?\n",
            "\n",
            "2. Which of the following questions challenges the viewpoint that AI development should prioritize efficiency above all else?\n",
            "\n",
            "3. Which question is most effective for exploring the ethical implications of AI in criminal justice?\n",
            "\n",
            "4. When a company claims its AI is 'unbiased', which question is essential to ask?\n",
            "\n",
            "5. What makes a question about AI ethics particularly Socratic?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Socratic Questioning\n",
        "socratic = client.qna_engine.generate_questions(\n",
        "    topic=\"Ethics in Artificial Intelligence\",\n",
        "    num=5,\n",
        "    custom_instructions=\"\"\"Generate Socratic-style questions that:\n",
        "    1. Probe assumptions\n",
        "    2. Question viewpoints\n",
        "    3. Explore implications\n",
        "    4. Challenge evidence\n",
        "    5. Meta-question about the question\n",
        "\n",
        "    These should encourage deep thinking, not have single correct answers.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"ğŸ¤” Socratic Questions:\\n\")\n",
        "for i, q in enumerate(socratic.questions, 1):\n",
        "    print(f\"{i}. {q.question}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "k12_template",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5762ae4-5133-4426-9d27-8a5093b2a379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’ Elementary School Questions:\n",
            "  â€¢ Which planet is called the Red Planet?\n",
            "  â€¢ What is the big star that all planets go around?\n",
            "\n",
            "ğŸ“ High School Questions:\n",
            "  â€¢ Based on the International Astronomical Union (IAU) definition, which of the following is a key criterion that distinguishes a planet from a dwarf planet?\n",
            "  â€¢ If a planet has an elliptical orbit with high eccentricity, which of the following is most likely true about its orbital period compared to a planet with a circular orbit at the same semi-major axis?\n"
          ]
        }
      ],
      "source": [
        "# K-12 Grade-Specific Template\n",
        "def generate_grade_questions(topic, grade_level, num=5):\n",
        "    \"\"\"Generate questions appropriate for specific grade level.\"\"\"\n",
        "\n",
        "    grade_instructions = {\n",
        "        \"elementary\": \"Use simple words. Short sentences. Fun examples. Age 6-10.\",\n",
        "        \"middle\": \"More complex concepts. Real-world examples. Age 11-14.\",\n",
        "        \"high\": \"Advanced concepts. Critical thinking required. Age 15-18.\"\n",
        "    }\n",
        "\n",
        "    return client.qna_engine.generate_questions(\n",
        "        topic=topic,\n",
        "        num=num,\n",
        "        custom_instructions=f\"\"\"Generate questions for {grade_level} school students.\n",
        "        Guidelines: {grade_instructions.get(grade_level, grade_instructions['middle'])}\n",
        "        Make questions age-appropriate and engaging.\"\"\"\n",
        "    )\n",
        "\n",
        "# Test different grade levels\n",
        "print(\"ğŸ’ Elementary School Questions:\")\n",
        "elem = generate_grade_questions(\"Solar System\", \"elementary\", 2)\n",
        "for q in elem.questions:\n",
        "    print(f\"  â€¢ {q.question}\")\n",
        "\n",
        "print(\"\\nğŸ“ High School Questions:\")\n",
        "high = generate_grade_questions(\"Solar System\", \"high\", 2)\n",
        "for q in high.questions:\n",
        "    print(f\"  â€¢ {q.question}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section6"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“– Section 6: Lesson Plan Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "basic_lesson"
      },
      "outputs": [],
      "source": [
        "# Generate a basic lesson plan\n",
        "content_engine = client.content_engine\n",
        "\n",
        "lesson = content_engine.generate_lesson_plan(\n",
        "    topic=\"Introduction to Machine Learning\"\n",
        ")\n",
        "\n",
        "print(\"ğŸ“š Lesson Plan: Introduction to Machine Learning\")\n",
        "print(\"=\" * 50)\n",
        "print(lesson)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "detailed_lesson"
      },
      "outputs": [],
      "source": [
        "# Detailed lesson plan with parameters\n",
        "detailed_lesson = content_engine.generate_lesson_plan(\n",
        "    topic=\"Python Functions and Decorators\",\n",
        "    grade_level=\"High School / College\",\n",
        "    duration=\"60 minutes\",\n",
        "    custom_instructions=\"\"\"Include:\n",
        "    1. Learning objectives (3-4)\n",
        "    2. Prerequisites\n",
        "    3. Materials needed\n",
        "    4. Introduction/Hook (5 min)\n",
        "    5. Main content with coding examples (40 min)\n",
        "    6. Hands-on activity (10 min)\n",
        "    7. Assessment questions (5 min)\n",
        "\n",
        "    Make it interactive with real coding examples.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"ğŸ“ Detailed Lesson Plan\")\n",
        "print(\"=\" * 50)\n",
        "print(detailed_lesson)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "subject_lessons"
      },
      "outputs": [],
      "source": [
        "# Generate lessons for different subjects\n",
        "subjects = [\n",
        "    (\"Photosynthesis\", \"Middle School\", \"45 minutes\"),\n",
        "    (\"French Revolution\", \"High School\", \"50 minutes\"),\n",
        "    (\"Algebra Basics\", \"Middle School\", \"40 minutes\")\n",
        "]\n",
        "\n",
        "for topic, grade, duration in subjects:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"ğŸ“š {topic} | {grade} | {duration}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    lesson = content_engine.generate_lesson_plan(\n",
        "        topic=topic,\n",
        "        grade_level=grade,\n",
        "        duration=duration\n",
        "    )\n",
        "    # Print first 500 chars\n",
        "    print(str(lesson)[:500] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section7"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸŒ Section 7: Generate from Data Sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "from_url",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a4657f-ffa4-4f8b-ec37-d133eebbf7c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸŒ Questions from Wikipedia (AI Article):\n",
            "\n",
            "1. What is the main function of a user-agent header in HTTP requests?\n",
            "   âœ… To indicate the software making the request\n",
            "\n",
            "2. According to standard web practices, what should a bot's user-agent string include?\n",
            "   âœ… Bot name, version, and contact information\n",
            "\n",
            "3. Where is the robots.txt file typically placed on a website?\n",
            "   âœ… At the root of the domain\n",
            "\n",
            "4. What does 'respecting the robots.txt file' mean for a web crawler?\n",
            "   âœ… Following the Disallow and Allow directives\n",
            "\n",
            "5. Why is it particularly important for bots accessing Wikimedia projects to set a proper user-agent?\n",
            "   âœ… To comply with Wikimedia's bot policy which requires identification for monitoring and management\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate questions from a URL\n",
        "url_questions = client.qna_engine.generate_questions_from_data(\n",
        "    source=\"https://en.wikipedia.org/wiki/Artificial_intelligence\",\n",
        "    source_type=\"url\",\n",
        "    num=5\n",
        ")\n",
        "\n",
        "print(\"ğŸŒ Questions from Wikipedia (AI Article):\\n\")\n",
        "for i, q in enumerate(url_questions.questions, 1):\n",
        "    print(f\"{i}. {q.question}\")\n",
        "    print(f\"   âœ… {q.answer}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "from_text",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7388d7a-45ed-4aa6-fdaa-efe68888448a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“„ Questions from Custom Text:\n",
            "\n",
            "1. What is the total number of parameters in Step 3.5 Flash?\n",
            "   âœ… 196 billion\n",
            "\n",
            "2. What is the size of the context window for Step 3.5 Flash?\n",
            "   âœ… 256K tokens\n",
            "\n",
            "3. Which architecture does Step 3.5 Flash use?\n",
            "   âœ… Sparse Mixture of Experts (MoE)\n",
            "\n",
            "4. How many experts are selected per token in the MoE routing of Step 3.5 Flash?\n",
            "   âœ… Top-8\n",
            "\n",
            "5. Approximately how many parameters are active per token in Step 3.5 Flash?\n",
            "   âœ… ~11 billion\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate questions from custom text\n",
        "custom_text = \"\"\"\n",
        "Step 3.5 Flash is StepFun's most capable open-source foundation model.\n",
        "It uses a Sparse Mixture of Experts (MoE) architecture with 196 billion\n",
        "total parameters but only ~11 billion active parameters per token.\n",
        "\n",
        "Key specifications:\n",
        "- Context window: 256K tokens\n",
        "- 45-layer Transformer with 4,096 hidden dimension\n",
        "- 288 routed experts per layer plus 1 shared expert\n",
        "- Top-8 expert selection per token\n",
        "- Apache 2.0 license\n",
        "\n",
        "The model achieves 74.4% on SWE-bench Verified for coding tasks\n",
        "and generates tokens at 100-350 tokens per second.\n",
        "\"\"\"\n",
        "\n",
        "text_questions = client.qna_engine.generate_questions_from_data(\n",
        "    source=custom_text,\n",
        "    source_type=\"text\",\n",
        "    num=5\n",
        ")\n",
        "\n",
        "print(\"ğŸ“„ Questions from Custom Text:\\n\")\n",
        "for i, q in enumerate(text_questions.questions, 1):\n",
        "    print(f\"{i}. {q.question}\")\n",
        "    print(f\"   âœ… {q.answer}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“š Summary\n",
        "\n",
        "### What We Built\n",
        "\n",
        "| Feature | Description |\n",
        "|---------|-------------|\n",
        "| **MCQ Generation** | Topic-based, difficulty levels |\n",
        "| **Question Types** | MCQ, T/F, Fill-blank, Short answer |\n",
        "| **Custom Templates** | Bloom's, Socratic, K-12 |\n",
        "| **Lesson Plans** | Automated curriculum |\n",
        "| **Data Sources** | URL, Text, PDF support |\n",
        "\n",
        "\n",
        "### Key Configuration\n",
        "\n",
        "```python\n",
        "from langchain_openai import ChatOpenAI\n",
        "from educhain import Educhain, LLMConfig\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"stepfun/step-3.5-flash:free\",\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=\"your-key\"\n",
        ")\n",
        "\n",
        "client = Educhain(LLMConfig(custom_model=llm))\n",
        "```\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. Generate questions from PDFs\n",
        "2. Create YouTube video quizzes\n",
        "3. Build complete course assessments\n",
        "4. Integrate with LMS platforms\n",
        "\n",
        "---\n",
        "\n",
        "*Built with â¤ï¸ by @BuildFastWithAI & Educhain Team*"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q7gX4DkABFrV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}