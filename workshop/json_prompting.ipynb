{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Gen AI Experiments](https://img.shields.io/badge/Gen%20AI%20Experiments-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://github.com/buildfastwithai/gen-ai-experiments)\n",
        "[![Gen AI Experiments GitHub](https://img.shields.io/github/stars/buildfastwithai/gen-ai-experiments?style=for-the-badge&logo=github&color=gold)](http://github.com/buildfastwithai/gen-ai-experiments)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1JX4fiR5FnpiZBaiGdYRMJm_3lythuUEn?usp=sharing)\n",
        "\n",
        "## Master Generative AI in 8 Weeks\n",
        "\n",
        "**What You'll Learn:**\n",
        "- Cutting-edge Generative AI tools & frameworks\n",
        "- 6 weeks of hands-on, project-based learning\n",
        "- Weekly live mentorship\n",
        "- No prior coding experience required\n",
        "- Access to an innovation-driven community\n",
        "\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "\n",
        "ðŸ‘‰ [Start Your Journey](https://www.buildfastwithai.com/genai-course)"
      ],
      "metadata": {
        "id": "KbTSghlv7U2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JSON Prompting"
      ],
      "metadata": {
        "id": "r2bkCZ3r7dam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "JSON Prompting is a technique where the user explicitly instructs a Large Language Model (LLM) to output its response in **JavaScript Object Notation (JSON)** format, rather than unstructured text.\n",
        "\n",
        "### Core Intuition\n",
        "LLMs are trained on vast amounts of code. By requesting JSON, we trigger the model's \"coding\" capabilities. This shifts the model from a \"creative writing\" mode to a \"structured logic\" mode. Code requires precision and strict syntax; therefore, asking for code-like output forces the model to be more precise and logical.\n",
        "\n",
        "### Why It Works\n",
        "1.  **Ambiguity Reduction**: Natural language is inherently ambiguous. JSON keys (e.g., `\"sentiment\": \"positive\"`) force specific classification.\n",
        "2.  **Parsability**: JSON outputs can be immediately parsed by software (Python, JS) without complex text processing.\n",
        "3.  **Schema Enforcement**: It forces the model to consider every field requested, reducing the chance of missing information."
      ],
      "metadata": {
        "id": "dtWS9m9Y6pK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup of OpenAI Chat Model"
      ],
      "metadata": {
        "id": "avTF3ZNPuasb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b_hp_7gwuDgQ",
        "outputId": "d4fce5b6-b3f8-4704-efc7-e9fee9169100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.13.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "t4IEFWdvuLbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWWWcV1ntxsG"
      },
      "source": [
        "# Text Generation: Normal Prompt vs. JSON Prompt\n",
        "\n",
        "Here we compare asking for a story with a standard sentence versus a structured JSON input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-Z0vfiQtxsN"
      },
      "outputs": [],
      "source": [
        "# 1. Normal Text Prompt\n",
        "# Simple, standard instruction.\n",
        "normal_prompt = \"Write a short story (100-200 words) about a joyful reunion at airport\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-5.2\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": normal_prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"--- Normal Prompt Output ---\")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tZVq3DRtxsV"
      },
      "outputs": [],
      "source": [
        "# 2. JSON Prompt\n",
        "# specific details packed into a JSON structure for the model to interpret.\n",
        "json_prompt = \"\"\"\n",
        "{\n",
        "  \"task\": \"write_story\",\n",
        "  \"genre\": \"emotional\",\n",
        "  \"topic\": \"reunion\",\n",
        "  \"word_count_range\": \"100-200\",\n",
        "  \"tone\": \"heartwarming\",\n",
        "  \"key_elements\": [\"airport arrival\", \"tears of joy\", \"long separation\"]\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "response_json = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a creative writer. Use the provided JSON configuration to write the story.\"},\n",
        "        {\"role\": \"user\", \"content\": json_prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"--- JSON Prompt Output ---\")\n",
        "print(response_json.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5D8glo8txsY"
      },
      "source": [
        "# Image Generation: Normal Prompt vs. JSON Prompt\n",
        "\n",
        "Comparing a loose description with a structured JSON definition for image creation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import base64\n",
        "from IPython.display import display, Image\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "def generate_image(prompt):\n",
        "  result = client.images.generate(\n",
        "      model=\"gpt-image-1.5\",\n",
        "      prompt=prompt\n",
        "  )\n",
        "\n",
        "  # Get base64 string\n",
        "  image_base64 = result.data[0].b64_json\n",
        "\n",
        "  # Decode to bytes\n",
        "  image_bytes = base64.b64decode(image_base64)\n",
        "\n",
        "  # Display directly (no saving)\n",
        "  display(Image(data=image_bytes))\n"
      ],
      "metadata": {
        "id": "hIGoinBWu_n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7noZwY7ytxsc"
      },
      "outputs": [],
      "source": [
        "# 3. Normal Scenery Prompt\n",
        "normal_image_prompt = \"A beautiful scenery with people, nature, suns, etc.\"\n",
        "\n",
        "print(f\"Generating image for: '{normal_image_prompt}'\")\n",
        "generate_image(normal_image_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhTxqBKitxse"
      },
      "outputs": [],
      "source": [
        "# 4. Detailed JSON Prompt\n",
        "# We use an LLM to 'read' the JSON and convert it into a high-fidelity image prompt first.\n",
        "json_image_config = \"\"\"\n",
        "{\n",
        "  \"scene\": \"A utopian solar punk village\",\n",
        "  \"people\": \"diverse group enjoying a picnic on lush grass\",\n",
        "  \"nature\": \"cascading waterfalls, giant flowers, vibrant trees\",\n",
        "  \"lighting\": \"double suns setting, golden hour glow\",\n",
        "  \"style\": \"Studio Ghibli inspired, high resolution, detailed\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "print(\"optimized_prompt\")\n",
        "\n",
        "print(\"\\n--- Generating Image ---\")\n",
        "generate_image(json_image_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Summary\n",
        "\n",
        "**Key Takeaway**: JSON Prompting is the bridge between chatty AI and reliable software engineering.\n",
        "\n",
        "**Benefits Recap**:\n",
        "- Logic enforcement via structure\n",
        "- Programmatic integration\n",
        "- Consistency in creative tasks\n",
        "\n",
        "**Final Thought**: Stop prompting for text. Start prompting for data."
      ],
      "metadata": {
        "id": "gbADgRSq7SE3"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}